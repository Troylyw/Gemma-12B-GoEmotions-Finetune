
EnvironmentNameNotFound: Could not find conda environment: nanogpt-env
You can list all discoverable environments with `conda info --envs`.


Master Node: nid008201
0: The following values were not passed to `accelerate launch` and had defaults used instead:
0: 		More than one GPU was found, enabling multi-GPU training.
0: 		If this was unintended please pass in `--num_processes=1`.
0: 	`--mixed_precision` was set to a value of `'no'`
0: 	`--dynamo_backend` was set to a value of `'no'`
0: To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
1: The following values were not passed to `accelerate launch` and had defaults used instead:
1: 		More than one GPU was found, enabling multi-GPU training.
1: 		If this was unintended please pass in `--num_processes=1`.
1: 	`--mixed_precision` was set to a value of `'no'`
1: 	`--dynamo_backend` was set to a value of `'no'`
1: To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
1: [Rank 4] Loading model from ./gemma-3-12b-it-local onto cuda:0...
1: Forcing 'sdpa' attention implementation.
0: [Rank 0] Loading model from ./gemma-3-12b-it-local onto cuda:0...
0: Forcing 'sdpa' attention implementation.
1: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:13<00:55, 13.77s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:14<00:56, 14.24s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:14<00:56, 14.21s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:14<00:56, 14.19s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:22<00:32, 10.96s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:23<00:33, 11.33s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:23<00:33, 11.23s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:23<00:33, 11.25s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:32<00:20, 10.39s/it]Loading checkpoint shards:  60%|████
0: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:13<00:53, 13.30s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:13<00:55, 13.76s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:13<00:55, 13.76s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:13<00:55, 13.76s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:22<00:32, 11.00s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:23<00:34, 11.35s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:23<00:33, 11.27s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:23<00:33, 11.27s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:32<00:20, 10.50s/it]Loading checkpoint shards:  60%|████
1: █    | 3/5 [00:33<00:21, 10.55s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:33<00:21, 10.56s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:33<00:21, 10.61s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:42<00:10, 10.23s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:43<00:10, 10.38s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:43<00:10, 10.37s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:43<00:10, 10.46s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:51<00:00,  9.46s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:51<00:00, 10.21s/it]
1: Loading checkpoint shards: 100%|██████████| 5/5 [00:51<00:00,  9.66s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:51<00:00, 10.28s/it]
1: Loading checkpoint shards: 100%|██████████| 5/5 [00:51<00:00,  9.64s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:51<00:00,  9.59s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:51<00:00, 10.28s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:51<00:00, 10.28s/it]
1: 
0: █    | 3/5 [00:33<00:21, 10.69s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:33<00:21, 10.64s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:33<00:21, 10.64s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:43<00:10, 10.51s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:43<00:10, 10.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:43<00:10, 10.60s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:43<00:10, 10.60s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:52<00:00,  9.89s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:52<00:00, 10.41s/it]
0: Loading checkpoint shards: 100%|██████████| 5/5 [00:52<00:00,  9.92s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:52<00:00,  9.92s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:52<00:00,  9.94s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:52<00:00, 10.49s/it]
0: Loading checkpoint shards: 100%|██████████| 5/5 [00:52<00:00, 10.49s/it]
0: Loading checkpoint shards: 100%|██████████| 5/5 [00:52<00:00, 10.49s/it]
1: Model loaded on cuda:0. DType: torch.bfloat16
0: Model loaded on cuda:0. DType: torch.bfloat16
0: Loading datasets: twitter_training.csv and twitter_validation.csv...
0: Loaded twitter_training.csv: 73996 rows (Dropped 686 bad rows)
0: Loaded twitter_validation.csv: 1000 rows (Dropped 0 bad rows)
0: Training samples: 73996
0: Evaluation/Test samples: 1000
0: Adding EOS to train dataset:   0%|          | 0/73996 [00:00<?, ? examples/s]Adding EOS to train dataset:   4%|▎         | 2711/73996 [00:00<00:02, 26989.50 examples/s]Adding EOS to train dataset:   8%|▊         | 5819/73996 [00:00<00:02, 29388.07 examples/s]Adding EOS to train dataset:  12%|█▏        | 9000/73996 [00:00<00:02, 30378.25 examples/s]Adding EOS to train dataset:  16%|█▋        | 12179/73996 [00:00<00:01, 30933.16 examples/s]Adding EOS to train dataset:  21%|██        | 15402/73996 [00:00<00:01, 31394.93 examples/s]Adding EOS to train dataset:  25%|██▌       | 18628/73996 [00:00<00:01, 31670.16 examples/s]Adding EOS to train dataset:  32%|███▏      | 23319/73996 [00:00<00:01, 31499.69 examples/s]Adding EOS to train dataset:  36%|███▌      | 26503/73996 [00:00<00:01, 31596.64 examples/s]Adding EOS to train dataset:  40%|████      | 29667/73996 [00:00<00:01, 31607.22 examples/s]Adding EOS to train dataset:  44%|████▍     | 32912/739
0: 96 [00:01<00:01, 31851.40 examples/s]Adding EOS to train dataset:  51%|█████     | 37658/73996 [00:01<00:01, 31767.32 examples/s]Adding EOS to train dataset:  57%|█████▋    | 42361/73996 [00:01<00:01, 31616.16 examples/s]Adding EOS to train dataset:  62%|██████▏   | 45541/73996 [00:01<00:00, 31659.76 examples/s]Adding EOS to train dataset:  66%|██████▌   | 48722/73996 [00:01<00:00, 31696.73 examples/s]Adding EOS to train dataset:  70%|███████   | 51910/73996 [00:01<00:00, 31745.82 examples/s]Adding EOS to train dataset:  77%|███████▋  | 56725/73996 [00:01<00:00, 31874.99 examples/s]Adding EOS to train dataset:  81%|████████  | 59926/73996 [00:01<00:00, 31906.82 examples/s]Adding EOS to train dataset:  87%|████████▋ | 64681/73996 [00:02<00:00, 31830.63 examples/s]Adding EOS to train dataset:  94%|█████████▍| 69417/73996 [00:02<00:00, 31739.24 examples/s]Adding EOS to t
0: rain dataset:  98%|█████████▊| 72637/73996 [00:02<00:00, 31850.61 examples/s]Adding EOS to train dataset: 100%|██████████| 73996/73996 [00:02<00:00, 31498.59 examples/s]
0: Tokenizing train dataset:   0%|          | 0/73996 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 464/73996 [00:00<00:15, 4611.28 examples/s]Tokenizing train dataset:   1%|▏         | 953/73996 [00:00<00:15, 4766.83 examples/s]Tokenizing train dataset:   2%|▏         | 1604/73996 [00:00<00:15, 4524.96 examples/s]Tokenizing train dataset:   3%|▎         | 2279/73996 [00:00<00:15, 4508.72 examples/s]Tokenizing train dataset:   4%|▍         | 2818/73996 [00:00<00:14, 4766.78 examples/s]Tokenizing train dataset:   5%|▍         | 3558/73996 [00:00<00:14, 4828.88 examples/s]Tokenizing train dataset:   6%|▌         | 4296/73996 [00:00<00:14, 4860.26 examples/s]Tokenizing train dataset:   7%|▋         | 4822/73996 [00:01<00:13, 4958.48 examples/s]Tokenizing train dataset:   7%|▋         | 5499/73996 [00:01<00:14, 4784.83 examples/s]Tokenizing train dataset:   8%|▊         | 5995/73996 [00:01<00:14, 4827.47 examples/s]Tokenizing train dataset:   9%|▉         | 6668/73
0: 996 [00:01<00:14, 4705.53 examples/s]Tokenizing train dataset:  10%|▉         | 7363/73996 [00:01<00:14, 4678.32 examples/s]Tokenizing train dataset:  11%|█         | 7887/73996 [00:01<00:13, 4811.53 examples/s]Tokenizing train dataset:  12%|█▏        | 8597/73996 [00:01<00:13, 4784.15 examples/s]Tokenizing train dataset:  13%|█▎        | 9291/73996 [00:01<00:13, 4727.84 examples/s]Tokenizing train dataset:  13%|█▎        | 9819/73996 [00:02<00:13, 4856.81 examples/s]Tokenizing train dataset:  14%|█▍        | 10526/73996 [00:02<00:13, 4797.09 examples/s]Tokenizing train dataset:  15%|█▌        | 11270/73996 [00:02<00:13, 4775.60 examples/s]Tokenizing train dataset:  16%|█▌        | 11802/73996 [00:02<00:12, 4901.74 examples/s]Tokenizing train dataset:  17%|█▋        | 12548/73996 [00:02<00:12, 4884.56 examples/s]Tokenizing train dataset:  18%|█▊        | 13270/73996 [00:02<00:12, 4850.04 examples/s]Tokenizing train dataset:  19%|█▊        | 13794/73996 [00:02
0: <00:12, 4939.10 examples/s]Tokenizing train dataset:  20%|█▉        | 14563/73996 [00:03<00:12, 4931.49 examples/s]Tokenizing train dataset:  21%|██        | 15298/73996 [00:03<00:11, 4919.47 examples/s]Tokenizing train dataset:  21%|██▏       | 15869/73996 [00:03<00:11, 5100.90 examples/s]Tokenizing train dataset:  22%|██▏       | 16626/73996 [00:03<00:11, 5079.02 examples/s]Tokenizing train dataset:  23%|██▎       | 17383/73996 [00:03<00:11, 5065.97 examples/s]Tokenizing train dataset:  24%|██▍       | 17932/73996 [00:03<00:10, 5161.24 examples/s]Tokenizing train dataset:  25%|██▌       | 18680/73996 [00:03<00:10, 5100.24 examples/s]Tokenizing train dataset:  26%|██▌       | 19392/73996 [00:03<00:10, 4981.03 examples/s]Tokenizing train dataset:  27%|██▋       | 19912/73996 [00:04<00:10, 5031.51 examples/s]Tokenizing train dataset:  28%|██▊       | 20628/73996 [00:04<00:10, 4939.83 examples/s]Tokenizing train dataset:  29%|██▉       | 2
0: 1311/73996 [00:04<00:10, 4812.16 examples/s]Tokenizing train dataset:  30%|██▉       | 21831/73996 [00:04<00:10, 4900.95 examples/s]Tokenizing train dataset:  30%|███       | 22566/73996 [00:04<00:10, 4898.26 examples/s]Tokenizing train dataset:  31%|███▏      | 23279/73996 [00:04<00:10, 4850.05 examples/s]Tokenizing train dataset:  32%|███▏      | 23767/73996 [00:04<00:10, 4854.69 examples/s]Tokenizing train dataset:  33%|███▎      | 24347/73996 [00:05<00:15, 3277.42 examples/s]Tokenizing train dataset:  34%|███▎      | 24855/73996 [00:05<00:13, 3614.37 examples/s]Tokenizing train dataset:  35%|███▍      | 25531/73996 [00:05<00:12, 3867.20 examples/s]Tokenizing train dataset:  35%|███▌      | 26000/73996 [00:05<00:11, 4012.62 examples/s]Tokenizing train dataset:  36%|███▌      | 26531/73996 [00:05<00:11, 4314.05 examples/s]Tokenizing train dataset:  36%|███▋      | 27000/73996 [00:05<00:10, 4355.78 examples/s]Tokenizing tr
0: ain dataset:  37%|███▋      | 27538/73996 [00:05<00:10, 4620.97 examples/s]Tokenizing train dataset:  38%|███▊      | 28271/73996 [00:06<00:09, 4706.07 examples/s]Tokenizing train dataset:  39%|███▉      | 28824/73996 [00:06<00:09, 4912.83 examples/s]Tokenizing train dataset:  40%|███▉      | 29556/73996 [00:06<00:09, 4899.27 examples/s]Tokenizing train dataset:  41%|████      | 30293/73996 [00:06<00:08, 4901.43 examples/s]Tokenizing train dataset:  42%|████▏     | 30830/73996 [00:06<00:08, 5010.62 examples/s]Tokenizing train dataset:  43%|████▎     | 31564/73996 [00:06<00:08, 4964.65 examples/s]Tokenizing train dataset:  44%|████▎     | 32290/73996 [00:06<00:08, 4921.14 examples/s]Tokenizing train dataset:  44%|████▍     | 32808/73996 [00:06<00:08, 4977.82 examples/s]Tokenizing train dataset:  45%|████▌     | 33535/73996 [00:07<00:08, 4856.29 examples/s]Tokenizing train dataset:  46%|████▋     | 3426
0: 2/73996 [00:07<00:08, 4791.77 examples/s]Tokenizing train dataset:  47%|████▋     | 34797/73996 [00:07<00:07, 4921.13 examples/s]Tokenizing train dataset:  48%|████▊     | 35510/73996 [00:07<00:08, 4809.82 examples/s]Tokenizing train dataset:  49%|████▊     | 36000/73996 [00:07<00:08, 4696.81 examples/s]Tokenizing train dataset:  49%|████▉     | 36516/73996 [00:07<00:07, 4808.75 examples/s]Tokenizing train dataset:  50%|█████     | 37251/73996 [00:07<00:07, 4750.39 examples/s]Tokenizing train dataset:  51%|█████     | 37772/73996 [00:07<00:07, 4860.46 examples/s]Tokenizing train dataset:  52%|█████▏    | 38518/73996 [00:08<00:07, 4800.84 examples/s]Tokenizing train dataset:  53%|█████▎    | 39259/73996 [00:08<00:07, 4745.46 examples/s]Tokenizing train dataset:  54%|█████▍    | 39792/73996 [00:08<00:07, 4878.36 examples/s]Tokenizing train dataset:  55%|█████▍    | 40531/73996 [00:08<00:06, 4837
0: .31 examples/s]Tokenizing train dataset:  56%|█████▌    | 41273/73996 [00:08<00:06, 4816.76 examples/s]Tokenizing train dataset:  56%|█████▋    | 41807/73996 [00:08<00:06, 4936.44 examples/s]Tokenizing train dataset:  57%|█████▋    | 42531/73996 [00:08<00:06, 4821.61 examples/s]Tokenizing train dataset:  58%|█████▊    | 43260/73996 [00:09<00:06, 4782.34 examples/s]Tokenizing train dataset:  59%|█████▉    | 43783/73996 [00:09<00:06, 4884.12 examples/s]Tokenizing train dataset:  60%|██████    | 44497/73996 [00:09<00:06, 4754.12 examples/s]Tokenizing train dataset:  61%|██████    | 45000/73996 [00:09<00:06, 4665.27 examples/s]Tokenizing train dataset:  62%|██████▏   | 45519/73996 [00:09<00:05, 4791.49 examples/s]Tokenizing train dataset:  63%|██████▎   | 46264/73996 [00:09<00:05, 4715.26 examples/s]Tokenizing train dataset:  63%|██████▎   | 46788/73996 [00:09<00:05, 4838.40 exam
0: ples/s]Tokenizing train dataset:  64%|██████▍   | 47523/73996 [00:09<00:05, 4778.71 examples/s]Tokenizing train dataset:  65%|██████▌   | 48268/73996 [00:10<00:05, 4704.26 examples/s]Tokenizing train dataset:  66%|██████▌   | 48795/73996 [00:10<00:05, 4833.28 examples/s]Tokenizing train dataset:  67%|██████▋   | 49537/73996 [00:10<00:05, 4831.89 examples/s]Tokenizing train dataset:  68%|██████▊   | 50266/73996 [00:10<00:04, 4799.27 examples/s]Tokenizing train dataset:  69%|██████▊   | 50794/73996 [00:10<00:04, 4909.62 examples/s]Tokenizing train dataset:  70%|██████▉   | 51530/73996 [00:10<00:04, 4880.22 examples/s]Tokenizing train dataset:  71%|███████   | 52276/73996 [00:10<00:04, 4854.51 examples/s]Tokenizing train dataset:  71%|███████▏  | 52789/73996 [00:11<00:04, 4914.60 examples/s]Tokenizing train dataset:  72%|███████▏  | 53539/73996 [00:11<00:04, 48
0: 74.37 examples/s]Tokenizing train dataset:  73%|███████▎  | 54264/73996 [00:11<00:04, 4815.79 examples/s]Tokenizing train dataset:  74%|███████▍  | 54794/73996 [00:11<00:03, 4927.10 examples/s]Tokenizing train dataset:  75%|███████▌  | 55515/73996 [00:11<00:03, 4851.61 examples/s]Tokenizing train dataset:  76%|███████▌  | 56269/73996 [00:11<00:03, 4796.22 examples/s]Tokenizing train dataset:  77%|███████▋  | 56797/73996 [00:11<00:03, 4905.01 examples/s]Tokenizing train dataset:  78%|███████▊  | 57540/73996 [00:12<00:04, 3311.95 examples/s]Tokenizing train dataset:  78%|███████▊  | 58000/73996 [00:12<00:04, 3517.27 examples/s]Tokenizing train dataset:  79%|███████▉  | 58518/73996 [00:12<00:04, 3844.76 examples/s]Tokenizing train dataset:  80%|███████▉  | 59000/73996 [00:12<00:03, 3955.42 examples/s]Tokenizing train dataset:  80%|████████  | 59
0: 510/73996 [00:12<00:03, 4223.47 examples/s]Tokenizing train dataset:  81%|████████  | 60000/73996 [00:12<00:03, 4271.41 examples/s]Tokenizing train dataset:  82%|████████▏ | 60526/73996 [00:12<00:02, 4525.53 examples/s]Tokenizing train dataset:  83%|████████▎ | 61259/73996 [00:13<00:02, 4586.40 examples/s]Tokenizing train dataset:  84%|████████▎ | 61804/73996 [00:13<00:02, 4802.19 examples/s]Tokenizing train dataset:  85%|████████▍ | 62535/73996 [00:13<00:02, 4814.66 examples/s]Tokenizing train dataset:  85%|████████▌ | 63265/73996 [00:13<00:02, 4791.77 examples/s]Tokenizing train dataset:  86%|████████▌ | 63787/73996 [00:13<00:02, 4892.34 examples/s]Tokenizing train dataset:  87%|████████▋ | 64543/73996 [00:13<00:01, 4898.63 examples/s]Tokenizing train dataset:  88%|████████▊ | 65253/73996 [00:13<00:01, 4808.53 examples/s]Tokenizing train da
0: taset:  89%|████████▉ | 65768/73996 [00:13<00:01, 4887.49 examples/s]Tokenizing train dataset:  90%|████████▉ | 66519/73996 [00:14<00:01, 4811.69 examples/s]Tokenizing train dataset:  91%|█████████ | 67187/73996 [00:14<00:01, 4580.27 examples/s]Tokenizing train dataset:  92%|█████████▏| 67879/73996 [00:14<00:01, 4586.13 examples/s]Tokenizing train dataset:  92%|█████████▏| 68413/73996 [00:14<00:01, 4270.54 examples/s]Tokenizing train dataset:  93%|█████████▎| 68935/73996 [00:14<00:01, 4482.07 examples/s]Tokenizing train dataset:  94%|█████████▍| 69414/73996 [00:14<00:01, 4554.75 examples/s]Tokenizing train dataset:  95%|█████████▍| 69942/73996 [00:14<00:00, 4739.98 examples/s]Tokenizing train dataset:  95%|█████████▌| 70650/73996 [00:15<00:00, 4729.48 examples/s]Tokenizing train dataset:  96%|█████████▋| 71359
0: /73996 [00:15<00:00, 4723.21 examples/s]Tokenizing train dataset:  97%|█████████▋| 71845/73996 [00:15<00:00, 4755.36 examples/s]Tokenizing train dataset:  98%|█████████▊| 72491/73996 [00:15<00:00, 4599.04 examples/s]Tokenizing train dataset:  99%|█████████▊| 72991/73996 [00:15<00:00, 4695.86 examples/s]Tokenizing train dataset: 100%|█████████▉| 73669/73996 [00:15<00:00, 4631.63 examples/s]Tokenizing train dataset: 100%|██████████| 73996/73996 [00:15<00:00, 4692.73 examples/s]
0: Truncating train dataset:   0%|          | 0/73996 [00:00<?, ? examples/s]Truncating train dataset: 100%|██████████| 73996/73996 [00:00<00:00, 2027818.77 examples/s]
0: Adding EOS to train dataset:   0%|          | 0/73996 [00:00<?, ? examples/s]Adding EOS to train dataset:   0%|          | 0/73996 [00:00<?, ? examples/s]Adding EOS to train dataset:   0%|          | 0/73996 [00:00<?, ? examples/s]Adding EOS to eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]Adding EOS to eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 25795.39 examples/s]
1: Adding EOS to train dataset:   0%|          | 0/73996 [00:00<?, ? examples/s]Adding EOS to train dataset:   0%|          | 0/73996 [00:00<?, ? examples/s]Adding EOS to train dataset:   0%|          | 0/73996 [00:00<?, ? examples/s]Adding EOS to train dataset:   0%|          | 0/73996 [00:00<?, ? examples/s]Adding EOS to train dataset:   3%|▎         | 2513/73996 [00:00<00:02, 25005.07 examples/s]Adding EOS to train dataset:   3%|▎         | 2529/73996 [00:00<00:02, 25162.72 examples/s]Adding EOS to train dataset:   3%|▎         | 2459/73996 [00:00<00:02, 24464.27 examples/s]Adding EOS to train dataset:   3%|▎         | 2435/73996 [00:00<00:02, 24215.22 examples/s]Adding EOS to train dataset:   7%|▋         | 5375/73996 [00:00<00:02, 27093.62 examples/s]Adding EOS to train dataset:   7%|▋         | 5286/73996 [00:00<00:02, 26596.73 examples/s]Adding EOS to train dataset:   7%|▋         | 5221/73996 [00:00<00:02, 26311.71 examples/s]Adding EOS to train dataset:   7%|▋         | 5130/
0: Adding EOS to train dataset:   4%|▎         | 2645/73996 [00:00<00:02, 26316.32 examples/s]Adding EOS to train dataset:   4%|▎         | 2600/73996 [00:00<00:02, 25859.82 examples/s]Adding EOS to train dataset:   4%|▎         | 2620/73996 [00:00<00:02, 26060.23 examples/s]Adding EOS to train dataset:   7%|▋         | 5400/73996 [00:00<00:02, 27077.33 examples/s]Adding EOS to train dataset:   7%|▋         | 5438/73996 [00:00<00:02, 27257.17 examples/s]Adding EOS to train dataset:   7%|▋         | 5385/73996 [00:00<00:02, 26900.13 examples/s]Tokenizing eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]Adding EOS to train dataset:  11%|█▏        | 8398/73996 [00:00<00:02, 28400.54 examples/s]Adding EOS to train dataset:  11%|█▏        | 8359/73996 [00:00<00:02, 28144.42 examples/s]Adding EOS to train dataset:  11%|█         | 8320/73996 [00:00<00:02, 28011.04 examples/s]Tokenizing eval dataset:  48%|████▊     | 483/1000 [00:00<00:00, 4805.52 examples/s]Addin
0: g EOS to train dataset:  15%|█▌        | 11421/73996 [00:00<00:02, 29119.91 examples/s]Adding EOS to train dataset:  15%|█▌        | 11354/73996 [00:00<00:02, 28854.60 examples/s]Adding EOS to train dataset:  15%|█▌        | 11232/73996 [00:00<00:02, 28441.46 examples/s]Tokenizing eval dataset:  97%|█████████▋| 966/1000 [00:00<00:00, 4811.67 examples/s]Tokenizing eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 4421.82 examples/s]
0: Truncating eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]Truncating eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 565880.19 examples/s]
1: 73996 [00:00<00:02, 25818.33 examples/s]Adding EOS to train dataset:  11%|█▏        | 8415/73996 [00:00<00:02, 28598.47 examples/s]Adding EOS to train dataset:  11%|█         | 8232/73996 [00:00<00:02, 27899.10 examples/s]Adding EOS to train dataset:  11%|█         | 8097/73996 [00:00<00:02, 27424.15 examples/s]Adding EOS to train dataset:  11%|█         | 8000/73996 [00:00<00:02, 26957.53 examples/s]Adding EOS to train dataset:  15%|█▌        | 11407/73996 [00:00<00:02, 29114.36 examples/s]Adding EOS to train dataset:  15%|█▌        | 11175/73996 [00:00<00:02, 28499.76 examples/s]Adding EOS to train dataset:  15%|█▍        | 11000/73996 [00:00<00:02, 27946.97 examples/s]Adding EOS to train dataset:  15%|█▍        | 10840/73996 [00:00<00:02, 27523.80 examples/s]Adding EOS to train dataset:  20%|█▉        | 14526/73996 [00:00<00:01, 29859.13 examples/s]Adding EOS to train dataset:  19%|█▉        | 14219/73996 [00:00<00:02, 29195.72 examples/s]Adding EOS to train dat
0: Adding EOS to train dataset:  20%|█▉        | 14527/73996 [00:00<00:01, 29815.45 examples/s]Adding EOS to train dataset:  20%|█▉        | 14444/73996 [00:00<00:02, 29588.33 examples/s]Adding EOS to train dataset:  19%|█▉        | 14273/73996 [00:00<00:02, 29147.79 examples/s]Adding EOS to train dataset:  25%|██▌       | 18772/73996 [00:00<00:01, 29261.56 examples/s]Adding EOS to train dataset:  26%|██▌       | 18879/73996 [00:00<00:01, 29454.10 examples/s]Adding EOS to train dataset:  25%|██▌       | 18575/73996 [00:00<00:01, 28943.11 examples/s]Adding EOS to train dataset:  31%|███       | 23015/73996 [00:00<00:01, 28883.51 examples/s]Adding EOS to train dataset:  31%|███       | 23114/73996 [00:00<00:01, 28982.00 examples/s]Adding EOS to train dataset:  31%|███       | 22857/73996 [00:00<00:01, 28506.35 examples/s]Adding EOS to train dataset:  35%|███▌      | 26026/73996 [00:00<00:01, 29210.55 examples/s]Adding EOS to train dataset:  35%|█
1: aset:  19%|█▊        | 13771/73996 [00:00<00:02, 28164.78 examples/s]Adding EOS to train dataset:  19%|█▉        | 14000/73996 [00:00<00:02, 28549.33 examples/s]Adding EOS to train dataset:  23%|██▎       | 17208/73996 [00:00<00:01, 29427.69 examples/s]Adding EOS to train dataset:  24%|██▍       | 17619/73996 [00:00<00:01, 30218.06 examples/s]Adding EOS to train dataset:  23%|██▎       | 16653/73996 [00:00<00:02, 28382.75 examples/s]Adding EOS to train dataset:  23%|██▎       | 16984/73996 [00:00<00:01, 28982.43 examples/s]Adding EOS to train dataset:  29%|██▉       | 21487/73996 [00:00<00:01, 29045.83 examples/s]Adding EOS to train dataset:  30%|██▉       | 22045/73996 [00:00<00:01, 29914.20 examples/s]Adding EOS to train dataset:  28%|██▊       | 20831/73996 [00:00<00:01, 28155.76 examples/s]Adding EOS to train dataset:  29%|██▊       | 21155/73996 [00:00<00:01, 28485.28 examples/s]Adding EOS to train dataset:  35%|███▍      | 25859/7
1: 3996 [00:00<00:01, 29079.79 examples/s]Adding EOS to train dataset:  36%|███▌      | 26595/73996 [00:00<00:01, 30052.76 examples/s]Adding EOS to train dataset:  34%|███▍      | 25056/73996 [00:00<00:01, 28155.91 examples/s]Adding EOS to train dataset:  34%|███▍      | 25492/73996 [00:00<00:01, 28582.22 examples/s]Adding EOS to train dataset:  39%|███▉      | 28853/73996 [00:01<00:01, 29304.40 examples/s]Adding EOS to train dataset:  40%|████      | 29640/73996 [00:01<00:01, 30152.95 examples/s]Adding EOS to train dataset:  38%|███▊      | 27978/73996 [00:01<00:01, 28432.42 examples/s]Adding EOS to train dataset:  38%|███▊      | 28447/73996 [00:01<00:01, 28737.26 examples/s]Adding EOS to train dataset:  46%|████▌     | 33914/73996 [00:01<00:01, 29548.52 examples/s]Adding EOS to train dataset:  45%|████▍     | 33000/73996 [00:01<00:01, 28660.54 examples/s]Adding EOS to train dataset:  43%|████▎     | 32020/73996 [00
0: ██▌      | 26095/73996 [00:00<00:01, 29200.64 examples/s]Adding EOS to train dataset:  35%|███▍      | 25771/73996 [00:00<00:01, 28673.41 examples/s]Adding EOS to train dataset:  41%|████      | 30234/73996 [00:01<00:01, 28783.48 examples/s]Adding EOS to train dataset:  41%|████      | 30257/73996 [00:01<00:01, 28666.11 examples/s]Adding EOS to train dataset:  40%|████      | 29908/73996 [00:01<00:01, 28274.67 examples/s]Adding EOS to train dataset:  47%|████▋     | 34601/73996 [00:01<00:01, 28893.57 examples/s]Adding EOS to train dataset:  47%|████▋     | 34559/73996 [00:01<00:01, 28665.66 examples/s]Adding EOS to train dataset:  46%|████▌     | 34117/73996 [00:01<00:01, 28196.84 examples/s]Adding EOS to train dataset:  50%|█████     | 37000/73996 [00:01<00:01, 28271.30 examples/s]Adding EOS to train dataset:  53%|█████▎    | 38898/73996 [00:01<00:01, 28809.75 examples/s]Adding EOS to train dataset:  52%|█
1: :01<00:01, 27893.12 examples/s]Adding EOS to train dataset:  44%|████▍     | 32578/73996 [00:01<00:01, 28304.46 examples/s]Adding EOS to train dataset:  49%|████▊     | 35937/73996 [00:01<00:01, 28840.06 examples/s]Adding EOS to train dataset:  47%|████▋     | 34868/73996 [00:01<00:01, 28040.44 examples/s]Adding EOS to train dataset:  52%|█████▏    | 38184/73996 [00:01<00:01, 29177.55 examples/s]Adding EOS to train dataset:  50%|████▉     | 36792/73996 [00:01<00:01, 28174.28 examples/s]Adding EOS to train dataset:  56%|█████▌    | 41141/73996 [00:01<00:01, 29271.78 examples/s]Adding EOS to train dataset:  54%|█████▍    | 40129/73996 [00:01<00:01, 28521.61 examples/s]Adding EOS to train dataset:  53%|█████▎    | 38989/73996 [00:01<00:01, 27835.73 examples/s]Adding EOS to train dataset:  55%|█████▌    | 41000/73996 [00:01<00:01, 28057.71 examples/s]Adding EOS to train dataset:  60%|█████▉   
1:  | 44114/73996 [00:01<00:01, 29385.38 examples/s]Adding EOS to train dataset:  58%|█████▊    | 43041/73996 [00:01<00:01, 28668.45 examples/s]Adding EOS to train dataset:  56%|█████▋    | 41799/73996 [00:01<00:01, 27900.76 examples/s]Adding EOS to train dataset:  59%|█████▉    | 43877/73996 [00:01<00:01, 28224.60 examples/s]Adding EOS to train dataset:  64%|██████▎   | 47069/73996 [00:01<00:00, 29427.16 examples/s]Adding EOS to train dataset:  62%|██████▏   | 45993/73996 [00:01<00:00, 28890.90 examples/s]Adding EOS to train dataset:  60%|██████    | 44599/73996 [00:01<00:01, 27924.94 examples/s]Adding EOS to train dataset:  63%|██████▎   | 46720/73996 [00:01<00:00, 28273.84 examples/s]Adding EOS to train dataset:  68%|██████▊   | 50050/73996 [00:01<00:00, 29530.98 examples/s]Adding EOS to train dataset:  64%|██████▍   | 47428/73996 [00:01<00:00, 27972.73 examples/s]Adding EOS to train
0: ███▏    | 38779/73996 [00:01<00:01, 28487.31 examples/s]Adding EOS to train dataset:  57%|█████▋    | 41809/73996 [00:01<00:01, 28877.88 examples/s]Adding EOS to train dataset:  56%|█████▌    | 41196/73996 [00:01<00:01, 28165.96 examples/s]Adding EOS to train dataset:  58%|█████▊    | 43120/73996 [00:01<00:01, 28631.11 examples/s]Adding EOS to train dataset:  61%|██████    | 44785/73996 [00:01<00:01, 29100.09 examples/s]Adding EOS to train dataset:  60%|█████▉    | 44101/73996 [00:01<00:01, 28380.22 examples/s]Adding EOS to train dataset:  62%|██████▏   | 46000/73996 [00:01<00:00, 28650.71 examples/s]Adding EOS to train dataset:  64%|██████▍   | 47711/73996 [00:01<00:00, 29140.70 examples/s]Adding EOS to train dataset:  64%|██████▎   | 47005/73996 [00:01<00:00, 28551.12 examples/s]Adding EOS to train dataset:  66%|██████▌   | 48972/73996 [00:01<00:00, 28915.61 examples/s]Addin
1:  dataset:  68%|██████▊   | 50287/73996 [00:01<00:00, 28790.27 examples/s]Adding EOS to train dataset:  72%|███████▏  | 53021/73996 [00:01<00:00, 29580.15 examples/s]Adding EOS to train dataset:  68%|██████▊   | 50235/73996 [00:01<00:00, 27999.23 examples/s]Adding EOS to train dataset:  69%|██████▉   | 50995/73996 [00:01<00:00, 28351.23 examples/s]Adding EOS to train dataset:  76%|███████▌  | 56017/73996 [00:01<00:00, 29685.95 examples/s]Adding EOS to train dataset:  74%|███████▍  | 54675/73996 [00:01<00:00, 28944.62 examples/s]Adding EOS to train dataset:  72%|███████▏  | 53083/73996 [00:01<00:00, 28136.11 examples/s]Adding EOS to train dataset:  73%|███████▎  | 53891/73996 [00:01<00:00, 28500.37 examples/s]Adding EOS to train dataset:  78%|███████▊  | 57581/73996 [00:02<00:00, 28971.85 examples/s]Adding EOS to train dataset:  80%|███████▉  | 59000/
0: g EOS to train dataset:  67%|██████▋   | 49871/73996 [00:01<00:00, 28578.02 examples/s]Adding EOS to train dataset:  70%|███████   | 52034/73996 [00:01<00:00, 29019.65 examples/s]Adding EOS to train dataset:  72%|███████▏  | 53311/73996 [00:01<00:00, 28916.27 examples/s]Adding EOS to train dataset:  71%|███████▏  | 52768/73996 [00:01<00:00, 28684.14 examples/s]Adding EOS to train dataset:  74%|███████▍  | 55008/73996 [00:01<00:00, 29201.41 examples/s]Adding EOS to train dataset:  78%|███████▊  | 57506/73996 [00:02<00:00, 28597.18 examples/s]Adding EOS to train dataset:  77%|███████▋  | 56873/73996 [00:02<00:00, 28188.59 examples/s]Adding EOS to train dataset:  80%|███████▉  | 59097/73996 [00:02<00:00, 28508.94 examples/s]Adding EOS to train dataset:  83%|████████▎ | 61749/73996 [00:02<00:00, 28494.36 examples/s]Adding EOS to train dataset:  84%|█████
1: 73996 [00:02<00:00, 29676.59 examples/s]Adding EOS to train dataset:  76%|███████▌  | 55969/73996 [00:02<00:00, 28344.87 examples/s]Adding EOS to train dataset:  79%|███████▊  | 58167/73996 [00:02<00:00, 28500.24 examples/s]Adding EOS to train dataset:  82%|████████▏ | 60505/73996 [00:02<00:00, 29039.31 examples/s]Adding EOS to train dataset:  84%|████████▍ | 62000/73996 [00:02<00:00, 29673.47 examples/s]Adding EOS to train dataset:  80%|███████▉  | 58842/73996 [00:02<00:00, 28455.36 examples/s]Adding EOS to train dataset:  84%|████████▍ | 62285/73996 [00:02<00:00, 28150.09 examples/s]Adding EOS to train dataset:  87%|████████▋ | 64544/73996 [00:02<00:00, 28282.05 examples/s]Adding EOS to train dataset:  89%|████████▉ | 66140/73996 [00:02<00:00, 28870.75 examples/s]Adding EOS to train dataset:  85%|████████▍ | 62818/73996 [00:02<00:00, 27698.67 ex
0: ██▍ | 62000/73996 [00:02<00:00, 28532.52 examples/s]Adding EOS to train dataset:  82%|████████▏ | 61000/73996 [00:02<00:00, 27923.99 examples/s]Adding EOS to train dataset:  87%|████████▋ | 64636/73996 [00:02<00:00, 28580.02 examples/s]Adding EOS to train dataset:  88%|████████▊ | 64903/73996 [00:02<00:00, 28660.23 examples/s]Adding EOS to train dataset:  86%|████████▋ | 63860/73996 [00:02<00:00, 28090.74 examples/s]Adding EOS to train dataset:  93%|█████████▎| 68923/73996 [00:02<00:00, 28572.73 examples/s]Adding EOS to train dataset:  93%|█████████▎| 69093/73996 [00:02<00:00, 28393.13 examples/s]Adding EOS to train dataset:  92%|█████████▏| 68000/73996 [00:02<00:00, 27913.06 examples/s]Adding EOS to train dataset:  97%|█████████▋| 71978/73996 [00:02<00:00, 28507.22 examples/s]Adding EOS to train dataset:  96%|█████████▌| 7
1: amples/s]Adding EOS to train dataset:  90%|████████▉ | 66382/73996 [00:02<00:00, 27860.78 examples/s]Adding EOS to train dataset:  93%|█████████▎| 68735/73996 [00:02<00:00, 28163.58 examples/s]Adding EOS to train dataset:  90%|█████████ | 66907/73996 [00:02<00:00, 27538.45 examples/s]Adding EOS to train dataset:  95%|█████████▌| 70477/73996 [00:02<00:00, 28782.09 examples/s]Adding EOS to train dataset:  94%|█████████▍| 69689/73996 [00:02<00:00, 27606.83 examples/s]Adding EOS to train dataset:  99%|█████████▉| 73389/73996 [00:02<00:00, 28864.84 examples/s]Adding EOS to train dataset:  95%|█████████▌| 70583/73996 [00:02<00:00, 27902.91 examples/s]Adding EOS to train dataset: 100%|██████████| 73996/73996 [00:02<00:00, 29264.64 examples/s]
0: 0805/73996 [00:02<00:00, 27943.67 examples/s]Adding EOS to train dataset:  99%|█████████▉| 73118/73996 [00:02<00:00, 28374.08 examples/s]Adding EOS to train dataset: 100%|██████████| 73996/73996 [00:02<00:00, 28716.84 examples/s]
0: Adding EOS to train dataset: 100%|██████████| 73996/73996 [00:02<00:00, 28630.90 examples/s]
1: Adding EOS to train dataset:  99%|█████████▊| 72979/73996 [00:02<00:00, 28202.89 examples/s]Adding EOS to train dataset: 100%|██████████| 73996/73996 [00:02<00:00, 28552.57 examples/s]
0: Adding EOS to train dataset: 100%|██████████| 73996/73996 [00:02<00:00, 27778.73 examples/s]Adding EOS to train dataset: 100%|██████████| 73996/73996 [00:02<00:00, 28183.81 examples/s]
1: Adding EOS to train dataset: 100%|██████████| 73996/73996 [00:02<00:00, 27722.20 examples/s]Adding EOS to train dataset: 100%|██████████| 73996/73996 [00:02<00:00, 28083.91 examples/s]
1: Adding EOS to train dataset: 100%|█████████▉| 73792/73996 [00:02<00:00, 27515.73 examples/s]Adding EOS to train dataset: 100%|██████████| 73996/73996 [00:02<00:00, 27776.38 examples/s]
1: Tokenizing train dataset:   0%|          | 0/73996 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 0/73996 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 429/73996 [00:00<00:17, 4260.46 examples/s]Tokenizing train dataset:   0%|          | 0/73996 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 0/73996 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 449/73996 [00:00<00:16, 4463.41 examples/s]Tokenizing train dataset:   1%|          | 891/73996 [00:00<00:16, 4465.48 examples/s]Tokenizing train dataset:   1%|          | 472/73996 [00:00<00:15, 4680.88 examples/s]Tokenizing train dataset:   1%|          | 467/73996 [00:00<00:15, 4644.04 examples/s]Tokenizing train dataset:   1%|          | 914/73996 [00:00<00:16, 4562.40 examples/s]Tokenizing train dataset:   1%|▏         | 942/73996 [00:00<00:15, 4690.32 examples/s]Tokenizing train dataset:   2%|▏         | 1500/73996 [00:00<00:17, 4236.78 examples/s]Tokenizing train datas
0: Tokenizing train dataset:   0%|          | 0/73996 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 0/73996 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 0/73996 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 453/73996 [00:00<00:16, 4495.55 examples/s]Tokenizing train dataset:   1%|          | 447/73996 [00:00<00:16, 4433.50 examples/s]Tokenizing train dataset:   1%|          | 463/73996 [00:00<00:15, 4598.52 examples/s]Tokenizing train dataset:   1%|          | 920/73996 [00:00<00:15, 4594.75 examples/s]Tokenizing train dataset:   1%|          | 911/73996 [00:00<00:16, 4546.19 examples/s]Tokenizing train dataset:   1%|▏         | 1058/73996 [00:00<00:17, 4161.34 examples/s]Tokenizing train dataset:   2%|▏         | 1533/73996 [00:00<00:16, 4307.99 examples/s]Tokenizing train dataset:   2%|▏         | 1520/73996 [00:00<00:16, 4270.03 examples/s]Tokenizing train dataset:   2%|▏         | 1530/73996 [00:00<00:16, 4378.82 examples/s]Tok
1: et:   1%|▏         | 942/73996 [00:00<00:15, 4702.04 examples/s]Tokenizing train dataset:   2%|▏         | 1540/73996 [00:00<00:16, 4338.69 examples/s]Tokenizing train dataset:   3%|▎         | 1970/73996 [00:00<00:16, 4392.14 examples/s]Tokenizing train dataset:   2%|▏         | 1570/73996 [00:00<00:16, 4402.31 examples/s]Tokenizing train dataset:   2%|▏         | 1578/73996 [00:00<00:16, 4440.87 examples/s]Tokenizing train dataset:   3%|▎         | 2000/73996 [00:00<00:17, 4198.17 examples/s]Tokenizing train dataset:   4%|▎         | 2627/73996 [00:00<00:16, 4385.43 examples/s]Tokenizing train dataset:   3%|▎         | 2236/73996 [00:00<00:16, 4304.10 examples/s]Tokenizing train dataset:   3%|▎         | 2481/73996 [00:00<00:16, 4391.11 examples/s]Tokenizing train dataset:   3%|▎         | 2237/73996 [00:00<00:16, 4331.00 examples/s]Tokenizing train dataset:   4%|▎         | 2724/73996 [00:00<00:15, 4468.74 examples/s]Tokenizing train dataset:   4%|▍         | 3287/73996 [
0: enizing train dataset:   3%|▎         | 1989/73996 [00:00<00:16, 4393.05 examples/s]Tokenizing train dataset:   3%|▎         | 1980/73996 [00:00<00:16, 4382.48 examples/s]Tokenizing train dataset:   3%|▎         | 2000/73996 [00:00<00:17, 4211.36 examples/s]Tokenizing train dataset:   4%|▎         | 2635/73996 [00:00<00:16, 4349.74 examples/s]Tokenizing train dataset:   4%|▎         | 2625/73996 [00:00<00:16, 4344.31 examples/s]Tokenizing train dataset:   3%|▎         | 2484/73996 [00:00<00:16, 4412.43 examples/s]Tokenizing train dataset:   4%|▍         | 3288/73996 [00:00<00:16, 4348.54 examples/s]Tokenizing train dataset:   4%|▍         | 2984/73996 [00:00<00:15, 4594.46 examples/s]Tokenizing train dataset:   4%|▍         | 3284/73996 [00:00<00:16, 4360.20 examples/s]Tokenizing train dataset:   5%|▌         | 3793/73996 [00:00<00:15, 4530.29 examples/s]Tokenizing train dataset:   5%|▌         | 3802/73996 [00:00<00:15, 4574.73 examples/s]Tokenizing train dataset:   5%|▍   
1: 00:00<00:16, 4387.81 examples/s]Tokenizing train dataset:   4%|▍         | 2979/73996 [00:00<00:15, 4574.62 examples/s]Tokenizing train dataset:   4%|▎         | 2735/73996 [00:00<00:15, 4516.16 examples/s]Tokenizing train dataset:   5%|▌         | 3793/73996 [00:00<00:15, 4563.62 examples/s]Tokenizing train dataset:   5%|▍         | 3402/73996 [00:00<00:15, 4485.90 examples/s]Tokenizing train dataset:   5%|▍         | 3645/73996 [00:00<00:15, 4517.38 examples/s]Tokenizing train dataset:   5%|▍         | 3417/73996 [00:00<00:15, 4525.52 examples/s]Tokenizing train dataset:   5%|▌         | 3906/73996 [00:00<00:15, 4631.82 examples/s]Tokenizing train dataset:   6%|▌         | 4503/73996 [00:01<00:15, 4534.94 examples/s]Tokenizing train dataset:   5%|▌         | 3927/73996 [00:00<00:14, 4678.12 examples/s]Tokenizing train dataset:   6%|▌         | 4312/73996 [00:00<00:15, 4487.72 examples/s]Tokenizing train dataset:   7%|▋         | 4980/73996 [00:01<00:15, 4591.50 examples/s]T
0:       | 3665/73996 [00:00<00:15, 4566.08 examples/s]Tokenizing train dataset:   6%|▌         | 4264/73996 [00:00<00:15, 4520.15 examples/s]Tokenizing train dataset:   6%|▌         | 4511/73996 [00:01<00:15, 4591.31 examples/s]Tokenizing train dataset:   6%|▌         | 4354/73996 [00:00<00:15, 4571.07 examples/s]Tokenizing train dataset:   6%|▋         | 4760/73996 [00:01<00:14, 4640.32 examples/s]Tokenizing train dataset:   7%|▋         | 4983/73996 [00:01<00:14, 4620.95 examples/s]Tokenizing train dataset:   7%|▋         | 4837/73996 [00:01<00:14, 4635.41 examples/s]Tokenizing train dataset:   7%|▋         | 5360/73996 [00:01<00:15, 4398.53 examples/s]Tokenizing train dataset:   8%|▊         | 5581/73996 [00:01<00:15, 4393.53 examples/s]Tokenizing train dataset:   8%|▊         | 5832/73996 [00:01<00:15, 4480.69 examples/s]Tokenizing train dataset:   7%|▋         | 5459/73996 [00:01<00:15, 4402.19 examples/s]Tokenizing train dataset:   8%|▊         | 5928/73996 [00:01<00:15, 4
1: okenizing train dataset:   6%|▌         | 4584/73996 [00:01<00:15, 4588.92 examples/s]Tokenizing train dataset:   6%|▋         | 4809/73996 [00:01<00:15, 4610.88 examples/s]Tokenizing train dataset:   6%|▌         | 4621/73996 [00:01<00:14, 4656.76 examples/s]Tokenizing train dataset:   8%|▊         | 5626/73996 [00:01<00:15, 4486.91 examples/s]Tokenizing train dataset:   7%|▋         | 5235/73996 [00:01<00:15, 4485.34 examples/s]Tokenizing train dataset:   7%|▋         | 5480/73996 [00:01<00:15, 4494.31 examples/s]Tokenizing train dataset:   7%|▋         | 5272/73996 [00:01<00:15, 4545.02 examples/s]Tokenizing train dataset:   8%|▊         | 5722/73996 [00:01<00:14, 4578.21 examples/s]Tokenizing train dataset:   8%|▊         | 6261/73996 [00:01<00:15, 4400.13 examples/s]Tokenizing train dataset:   8%|▊         | 5963/73996 [00:01<00:14, 4575.98 examples/s]Tokenizing train dataset:   8%|▊         | 5763/73996 [00:01<00:14, 4631.89 examples/s]Tokenizing train dataset:   9%|▉ 
1:         | 6744/73996 [00:01<00:14, 4500.87 examples/s]Tokenizing train dataset:   9%|▊         | 6347/73996 [00:01<00:15, 4433.88 examples/s]Tokenizing train dataset:   9%|▉         | 6589/73996 [00:01<00:15, 4430.12 examples/s]Tokenizing train dataset:   9%|▊         | 6396/73996 [00:01<00:15, 4485.91 examples/s]Tokenizing train dataset:   9%|▉         | 6831/73996 [00:01<00:14, 4531.49 examples/s]Tokenizing train dataset:  10%|█         | 7404/73996 [00:01<00:14, 4464.83 examples/s]Tokenizing train dataset:   9%|▉         | 6876/73996 [00:01<00:14, 4562.08 examples/s]Tokenizing train dataset:  10%|▉         | 7260/73996 [00:01<00:15, 4414.20 examples/s]Tokenizing train dataset:  11%|█         | 7922/73996 [00:01<00:14, 4634.36 examples/s]Tokenizing train dataset:  10%|█         | 7522/73996 [00:01<00:14, 4533.28 examples/s]Tokenizing train dataset:  10%|█         | 7571/73996 [00:01<00:14, 4580.72 examples/s]Tokenizing train dataset:  10%|█         | 7760/73996 [00:01<00:14,
0: 471.79 examples/s]Tokenizing train dataset:   8%|▊         | 6228/73996 [00:01<00:15, 4294.88 examples/s]Tokenizing train dataset:   9%|▊         | 6464/73996 [00:01<00:15, 4343.06 examples/s]Tokenizing train dataset:   9%|▉         | 6707/73996 [00:01<00:15, 4412.16 examples/s]Tokenizing train dataset:   9%|▉         | 6544/73996 [00:01<00:15, 4343.47 examples/s]Tokenizing train dataset:   9%|▉         | 6938/73996 [00:01<00:15, 4442.69 examples/s]Tokenizing train dataset:   9%|▉         | 7000/73996 [00:01<00:15, 4303.89 examples/s]Tokenizing train dataset:  10%|▉         | 7391/73996 [00:01<00:14, 4458.30 examples/s]Tokenizing train dataset:  10%|█         | 7646/73996 [00:01<00:14, 4533.99 examples/s]Tokenizing train dataset:  10%|█         | 7502/73996 [00:01<00:14, 4487.49 examples/s]Tokenizing train dataset:  11%|█         | 7888/73996 [00:01<00:14, 4582.74 examples/s]Tokenizing train dataset:  11%|█         | 8305/73996 [00:01<00:14, 4481.94 examples/s]Tokenizing trai
1:  4553.68 examples/s]Tokenizing train dataset:  12%|█▏        | 8584/73996 [00:01<00:14, 4554.79 examples/s]Tokenizing train dataset:  11%|█         | 8000/73996 [00:01<00:14, 4427.89 examples/s]Tokenizing train dataset:  11%|█▏        | 8420/73996 [00:01<00:14, 4498.22 examples/s]Tokenizing train dataset:  11%|█         | 8266/73996 [00:01<00:14, 4574.29 examples/s]Tokenizing train dataset:  12%|█▏        | 8516/73996 [00:01<00:14, 4610.95 examples/s]Tokenizing train dataset:  13%|█▎        | 9252/73996 [00:02<00:14, 4504.97 examples/s]Tokenizing train dataset:  12%|█▏        | 8914/73996 [00:01<00:14, 4604.39 examples/s]Tokenizing train dataset:  12%|█▏        | 8769/73996 [00:01<00:13, 4681.71 examples/s]Tokenizing train dataset:  12%|█▏        | 8992/73996 [00:01<00:13, 4648.28 examples/s]Tokenizing train dataset:  13%|█▎        | 9745/73996 [00:02<00:13, 4604.75 examples/s]Tokenizing train dataset:  13%|█▎        | 9556/73996 [00:02<00:14, 4489.19 example
0: n dataset:  11%|█         | 7992/73996 [00:01<00:14, 4595.55 examples/s]Tokenizing train dataset:  12%|█▏        | 8540/73996 [00:01<00:14, 4499.96 examples/s]Tokenizing train dataset:  12%|█▏        | 8785/73996 [00:01<00:14, 4554.68 examples/s]Tokenizing train dataset:  12%|█▏        | 8645/73996 [00:01<00:14, 4504.20 examples/s]Tokenizing train dataset:  12%|█▏        | 9000/73996 [00:02<00:14, 4403.93 examples/s]Tokenizing train dataset:  12%|█▏        | 9247/73996 [00:02<00:14, 4448.90 examples/s]Tokenizing train dataset:  13%|█▎        | 9508/73996 [00:02<00:14, 4574.10 examples/s]Tokenizing train dataset:  13%|█▎        | 9297/73996 [00:02<00:14, 4447.99 examples/s]Tokenizing train dataset:  13%|█▎        | 9759/73996 [00:02<00:13, 4621.15 examples/s]Tokenizing train dataset:  14%|█▎        | 9994/73996 [00:02<00:13, 4648.77 examples/s]Tokenizing train dataset:  13%|█▎        | 9796/73996 [00:02<00:14, 4580.49 examples/s]Tokenizing train dataset:  14
1: s/s]Tokenizing train dataset:  13%|█▎        | 9484/73996 [00:02<00:14, 4535.87 examples/s]Tokenizing train dataset:  13%|█▎        | 9628/73996 [00:02<00:14, 4496.53 examples/s]Tokenizing train dataset:  14%|█▍        | 10379/73996 [00:02<00:14, 4474.11 examples/s]Tokenizing train dataset:  13%|█▎        | 9962/73996 [00:02<00:13, 4590.45 examples/s]Tokenizing train dataset:  14%|█▍        | 10246/73996 [00:02<00:14, 4403.48 examples/s]Tokenizing train dataset:  15%|█▍        | 10872/73996 [00:02<00:13, 4582.46 examples/s]Tokenizing train dataset:  14%|█▍        | 10264/73996 [00:02<00:14, 4405.06 examples/s]Tokenizing train dataset:  14%|█▍        | 10716/73996 [00:02<00:14, 4470.55 examples/s]Tokenizing train dataset:  14%|█▍        | 10610/73996 [00:02<00:14, 4496.88 examples/s]Tokenizing train dataset:  15%|█▍        | 10742/73996 [00:02<00:14, 4496.24 examples/s]Tokenizing train dataset:  16%|█▌        | 11534/73996 [00:02<00:13, 4520.20 examples/s]
0: %|█▍        | 10433/73996 [00:02<00:13, 4570.35 examples/s]Tokenizing train dataset:  14%|█▍        | 10659/73996 [00:02<00:13, 4569.59 examples/s]Tokenizing train dataset:  15%|█▍        | 10916/73996 [00:02<00:13, 4635.04 examples/s]Tokenizing train dataset:  14%|█▍        | 10495/73996 [00:02<00:13, 4537.93 examples/s]Tokenizing train dataset:  15%|█▍        | 10970/73996 [00:02<00:13, 4586.19 examples/s]Tokenizing train dataset:  15%|█▌        | 11292/73996 [00:02<00:14, 4445.60 examples/s]Tokenizing train dataset:  16%|█▌        | 11554/73996 [00:02<00:13, 4495.93 examples/s]Tokenizing train dataset:  16%|█▌        | 11790/73996 [00:02<00:13, 4575.44 examples/s]Tokenizing train dataset:  16%|█▌        | 11619/73996 [00:02<00:13, 4490.99 examples/s]Tokenizing train dataset:  17%|█▋        | 12257/73996 [00:02<00:13, 4495.29 examples/s]Tokenizing train dataset:  17%|█▋        | 12494/73996 [00:02<00:13, 4521.92 examples/s]Tokenizing train dataset:  17%
1: Tokenizing train dataset:  15%|█▌        | 11377/73996 [00:02<00:14, 4444.82 examples/s]Tokenizing train dataset:  15%|█▌        | 11280/73996 [00:02<00:13, 4483.24 examples/s]Tokenizing train dataset:  15%|█▌        | 11396/73996 [00:02<00:14, 4449.02 examples/s]Tokenizing train dataset:  16%|█▌        | 12000/73996 [00:02<00:13, 4461.37 examples/s]Tokenizing train dataset:  16%|█▌        | 11905/73996 [00:02<00:13, 4643.77 examples/s]Tokenizing train dataset:  16%|█▌        | 11812/73996 [00:02<00:13, 4678.12 examples/s]Tokenizing train dataset:  16%|█▌        | 11923/73996 [00:02<00:13, 4648.10 examples/s]Tokenizing train dataset:  17%|█▋        | 12516/73996 [00:02<00:13, 4638.27 examples/s]Tokenizing train dataset:  17%|█▋        | 12558/73996 [00:02<00:13, 4541.36 examples/s]Tokenizing train dataset:  17%|█▋        | 12499/73996 [00:02<00:13, 4593.63 examples/s]Tokenizing train dataset:  18%|█▊        | 13000/73996 [00:02<00:13, 4483.29 examples/s]
1: Tokenizing train dataset:  17%|█▋        | 12562/73996 [00:02<00:13, 4508.55 examples/s]Tokenizing train dataset:  18%|█▊        | 12992/73996 [00:02<00:13, 4672.02 examples/s]Tokenizing train dataset:  18%|█▊        | 13492/73996 [00:02<00:13, 4599.24 examples/s]Tokenizing train dataset:  18%|█▊        | 13247/73996 [00:02<00:13, 4472.87 examples/s]Tokenizing train dataset:  18%|█▊        | 13254/73996 [00:02<00:13, 4487.14 examples/s]Tokenizing train dataset:  19%|█▉        | 14000/73996 [00:03<00:13, 4520.45 examples/s]Tokenizing train dataset:  19%|█▊        | 13740/73996 [00:03<00:13, 4578.31 examples/s]Tokenizing train dataset:  18%|█▊        | 13663/73996 [00:02<00:13, 4599.08 examples/s]Tokenizing train dataset:  19%|█▊        | 13757/73996 [00:03<00:13, 4612.89 examples/s]Tokenizing train dataset:  20%|█▉        | 14525/73996 [00:03<00:12, 4718.70 examples/s]Tokenizing train dataset:  19%|█▉        | 14258/73996 [00:03<00:13, 4553.40 examples/s]T
0: |█▋        | 12284/73996 [00:02<00:13, 4468.92 examples/s]Tokenizing train dataset:  17%|█▋        | 12751/73996 [00:02<00:13, 4600.55 examples/s]Tokenizing train dataset:  17%|█▋        | 12786/73996 [00:02<00:13, 4598.28 examples/s]Tokenizing train dataset:  18%|█▊        | 13000/73996 [00:02<00:13, 4462.23 examples/s]Tokenizing train dataset:  18%|█▊        | 13424/73996 [00:02<00:13, 4561.22 examples/s]Tokenizing train dataset:  18%|█▊        | 13498/73996 [00:03<00:13, 4588.93 examples/s]Tokenizing train dataset:  19%|█▉        | 13925/73996 [00:03<00:12, 4669.88 examples/s]Tokenizing train dataset:  18%|█▊        | 13499/73996 [00:03<00:13, 4532.51 examples/s]Tokenizing train dataset:  19%|█▉        | 14000/73996 [00:03<00:13, 4495.31 examples/s]Tokenizing train dataset:  19%|█▉        | 13997/73996 [00:03<00:12, 4638.93 examples/s]Tokenizing train dataset:  20%|█▉        | 14620/73996 [00:03<00:12, 4655.31 examples/s]Tokenizing train dataset:  20%|
1: okenizing train dataset:  19%|█▉        | 14428/73996 [00:03<00:13, 4579.43 examples/s]Tokenizing train dataset:  19%|█▉        | 14341/73996 [00:03<00:13, 4570.43 examples/s]Tokenizing train dataset:  21%|██        | 15259/73996 [00:03<00:12, 4689.71 examples/s]Tokenizing train dataset:  20%|█▉        | 14795/73996 [00:03<00:12, 4761.67 examples/s]Tokenizing train dataset:  20%|██        | 14950/73996 [00:03<00:12, 4732.02 examples/s]Tokenizing train dataset:  20%|██        | 14877/73996 [00:03<00:12, 4756.08 examples/s]Tokenizing train dataset:  21%|██▏       | 15802/73996 [00:03<00:11, 4875.87 examples/s]Tokenizing train dataset:  21%|██        | 15636/73996 [00:03<00:12, 4676.40 examples/s]Tokenizing train dataset:  21%|██        | 15574/73996 [00:03<00:12, 4716.70 examples/s]Tokenizing train dataset:  21%|██        | 15523/73996 [00:03<00:12, 4710.00 examples/s]Tokenizing train dataset:  22%|██▏       | 16527/73996 [00:03<00:12, 4788.09 examples/s
0: █▉        | 14523/73996 [00:03<00:12, 4687.95 examples/s]Tokenizing train dataset:  20%|█▉        | 14710/73996 [00:03<00:12, 4674.48 examples/s]Tokenizing train dataset:  20%|██        | 15000/73996 [00:03<00:12, 4657.66 examples/s]Tokenizing train dataset:  21%|██        | 15332/73996 [00:03<00:12, 4683.44 examples/s]Tokenizing train dataset:  21%|██        | 15549/73996 [00:03<00:11, 4887.61 examples/s]Tokenizing train dataset:  21%|██▏       | 15880/73996 [00:03<00:11, 4871.50 examples/s]Tokenizing train dataset:  21%|██        | 15421/73996 [00:03<00:12, 4691.92 examples/s]Tokenizing train dataset:  22%|██▏       | 15978/73996 [00:03<00:11, 4897.07 examples/s]Tokenizing train dataset:  22%|██▏       | 16286/73996 [00:03<00:11, 4892.91 examples/s]Tokenizing train dataset:  22%|██▏       | 16619/73996 [00:03<00:11, 4887.95 examples/s]Tokenizing train dataset:  23%|██▎       | 16843/73996 [00:03<00:11, 5067.78 examples/s]Tokenizing train datas
1: ]Tokenizing train dataset:  22%|██▏       | 16000/73996 [00:03<00:12, 4646.50 examples/s]Tokenizing train dataset:  22%|██▏       | 16320/73996 [00:03<00:12, 4635.92 examples/s]Tokenizing train dataset:  22%|██▏       | 16277/73996 [00:03<00:12, 4703.35 examples/s]Tokenizing train dataset:  22%|██▏       | 16547/73996 [00:03<00:11, 4859.41 examples/s]Tokenizing train dataset:  23%|██▎       | 17274/73996 [00:03<00:11, 4754.87 examples/s]Tokenizing train dataset:  23%|██▎       | 16875/73996 [00:03<00:11, 4849.47 examples/s]Tokenizing train dataset:  23%|██▎       | 16835/73996 [00:03<00:11, 4906.85 examples/s]Tokenizing train dataset:  24%|██▍       | 17812/73996 [00:03<00:11, 4901.32 examples/s]Tokenizing train dataset:  23%|██▎       | 17255/73996 [00:03<00:11, 4800.81 examples/s]Tokenizing train dataset:  24%|██▍       | 17587/73996 [00:03<00:11, 4811.92 examples/s]Tokenizing train dataset:  24%|██▎       | 17556/73996 [00:03<00:1
0: et:  23%|██▎       | 16709/73996 [00:03<00:11, 4884.56 examples/s]Tokenizing train dataset:  23%|██▎       | 17352/73996 [00:03<00:11, 4885.46 examples/s]Tokenizing train dataset:  24%|██▎       | 17563/73996 [00:03<00:11, 4969.08 examples/s]Tokenizing train dataset:  24%|██▍       | 17887/73996 [00:03<00:11, 4995.27 examples/s]Tokenizing train dataset:  24%|██▎       | 17422/73996 [00:03<00:11, 4838.68 examples/s]Tokenizing train dataset:  24%|██▍       | 17947/73996 [00:03<00:11, 4932.30 examples/s]Tokenizing train dataset:  25%|██▍       | 18270/73996 [00:03<00:11, 4878.17 examples/s]Tokenizing train dataset:  25%|██▌       | 18596/73996 [00:04<00:11, 4900.72 examples/s]Tokenizing train dataset:  25%|██▌       | 18803/73996 [00:04<00:11, 4986.80 examples/s]Tokenizing train dataset:  25%|██▌       | 18660/73996 [00:04<00:11, 4867.73 examples/s]Tokenizing train dataset:  26%|██▌       | 19281/73996 [00:04<00:11, 4790.96 examples/s]T
1: 1, 4872.01 examples/s]Tokenizing train dataset:  24%|██▍       | 17756/73996 [00:03<00:11, 4852.78 examples/s]Tokenizing train dataset:  25%|██▌       | 18549/73996 [00:04<00:11, 4886.21 examples/s]Tokenizing train dataset:  25%|██▍       | 18300/73996 [00:04<00:11, 4790.72 examples/s]Tokenizing train dataset:  25%|██▍       | 18282/73996 [00:03<00:11, 4858.23 examples/s]Tokenizing train dataset:  25%|██▍       | 18267/73996 [00:03<00:11, 4759.97 examples/s]Tokenizing train dataset:  26%|██▌       | 19258/73996 [00:04<00:11, 4785.82 examples/s]Tokenizing train dataset:  25%|██▌       | 18823/73996 [00:04<00:11, 4892.90 examples/s]Tokenizing train dataset:  25%|██▌       | 18814/73996 [00:04<00:11, 4966.43 examples/s]Tokenizing train dataset:  25%|██▌       | 18807/73996 [00:04<00:11, 4929.69 examples/s]Tokenizing train dataset:  27%|██▋       | 19784/73996 [00:04<00:11, 4894.22 examples/s]Tokenizing train dataset:  26%|██▋       | 19
0: okenizing train dataset:  26%|██▋       | 19519/73996 [00:04<00:11, 4823.84 examples/s]Tokenizing train dataset:  27%|██▋       | 19790/73996 [00:04<00:11, 4857.90 examples/s]Tokenizing train dataset:  26%|██▌       | 19326/73996 [00:04<00:11, 4726.24 examples/s]Tokenizing train dataset:  27%|██▋       | 19843/73996 [00:04<00:11, 4827.62 examples/s]Tokenizing train dataset:  27%|██▋       | 20256/73996 [00:04<00:11, 4721.32 examples/s]Tokenizing train dataset:  28%|██▊       | 20507/73996 [00:04<00:11, 4750.88 examples/s]Tokenizing train dataset:  28%|██▊       | 20753/73996 [00:04<00:11, 4776.53 examples/s]Tokenizing train dataset:  28%|██▊       | 20509/73996 [00:04<00:11, 4694.79 examples/s]Tokenizing train dataset:  28%|██▊       | 21000/73996 [00:04<00:11, 4605.19 examples/s]Tokenizing train dataset:  29%|██▊       | 21260/73996 [00:04<00:11, 4634.27 examples/s]Tokenizing train dataset:  29%|██▉       | 21511/73996 [00:04<00:11, 
1: 523/73996 [00:04<00:11, 4795.07 examples/s]Tokenizing train dataset:  26%|██▋       | 19528/73996 [00:04<00:11, 4857.82 examples/s]Tokenizing train dataset:  26%|██▋       | 19530/73996 [00:04<00:11, 4823.70 examples/s]Tokenizing train dataset:  28%|██▊       | 20524/73996 [00:04<00:11, 4794.72 examples/s]Tokenizing train dataset:  27%|██▋       | 20255/73996 [00:04<00:11, 4702.65 examples/s]Tokenizing train dataset:  27%|██▋       | 20260/73996 [00:04<00:11, 4765.19 examples/s]Tokenizing train dataset:  27%|██▋       | 20263/73996 [00:04<00:11, 4733.65 examples/s]Tokenizing train dataset:  28%|██▊       | 20764/73996 [00:04<00:11, 4789.78 examples/s]Tokenizing train dataset:  28%|██▊       | 20770/73996 [00:04<00:10, 4839.12 examples/s]Tokenizing train dataset:  29%|██▊       | 21250/73996 [00:04<00:11, 4674.80 examples/s]Tokenizing train dataset:  28%|██▊       | 20781/73996 [00:04<00:10, 4837.76 examples/s]Tokenizing train dataset:  29%
1: |██▉       | 21772/73996 [00:04<00:10, 4798.20 examples/s]Tokenizing train dataset:  29%|██▊       | 21252/73996 [00:04<00:11, 4608.64 examples/s]Tokenizing train dataset:  29%|██▉       | 21533/73996 [00:04<00:11, 4745.33 examples/s]Tokenizing train dataset:  29%|██▉       | 21534/73996 [00:04<00:11, 4744.90 examples/s]Tokenizing train dataset:  29%|██▉       | 21786/73996 [00:04<00:10, 4792.48 examples/s]Tokenizing train dataset:  30%|███       | 22526/73996 [00:04<00:10, 4774.55 examples/s]Tokenizing train dataset:  30%|███       | 22257/73996 [00:04<00:11, 4703.12 examples/s]Tokenizing train dataset:  30%|███       | 22254/73996 [00:04<00:11, 4695.46 examples/s]Tokenizing train dataset:  30%|███       | 22519/73996 [00:04<00:10, 4731.69 examples/s]Tokenizing train dataset:  31%|███       | 22786/73996 [00:04<00:10, 4834.09 examples/s]Tokenizing train dataset:  31%|███▏      | 23253/73996 [00:05<00:10, 4704.33 examples/s]Tokeniz
0: 4727.63 examples/s]Tokenizing train dataset:  28%|██▊       | 21000/73996 [00:04<00:11, 4545.20 examples/s]Tokenizing train dataset:  29%|██▉       | 21791/73996 [00:04<00:10, 4802.93 examples/s]Tokenizing train dataset:  29%|██▉       | 21526/73996 [00:04<00:11, 4722.02 examples/s]Tokenizing train dataset:  30%|██▉       | 22000/73996 [00:04<00:11, 4658.51 examples/s]Tokenizing train dataset:  30%|███       | 22527/73996 [00:04<00:10, 4820.00 examples/s]Tokenizing train dataset:  30%|███       | 22525/73996 [00:04<00:10, 4761.54 examples/s]Tokenizing train dataset:  30%|███       | 22252/73996 [00:04<00:11, 4668.08 examples/s]Tokenizing train dataset:  31%|███       | 22768/73996 [00:04<00:10, 4785.45 examples/s]Tokenizing train dataset:  31%|███▏      | 23246/73996 [00:05<00:10, 4703.09 examples/s]Tokenizing train dataset:  31%|███▏      | 23252/73996 [00:05<00:10, 4667.90 examples/s]Tokenizing train dataset:  32%|███▏      |
1: ing train dataset:  31%|███       | 22786/73996 [00:04<00:10, 4836.71 examples/s]Tokenizing train dataset:  31%|███       | 23000/73996 [00:05<00:11, 4612.72 examples/s]Tokenizing train dataset:  32%|███▏      | 23746/73996 [00:05<00:10, 4754.07 examples/s]Tokenizing train dataset:  32%|███▏      | 23509/73996 [00:05<00:10, 4731.26 examples/s]Tokenizing train dataset:  32%|███▏      | 23504/73996 [00:05<00:10, 4717.82 examples/s]Tokenizing train dataset:  32%|███▏      | 23501/73996 [00:05<00:10, 4713.02 examples/s]Tokenizing train dataset:  33%|███▎      | 24408/73996 [00:05<00:10, 4640.10 examples/s]Tokenizing train dataset:  32%|███▏      | 23995/73996 [00:05<00:10, 4760.08 examples/s]Tokenizing train dataset:  32%|███▏      | 23990/73996 [00:05<00:10, 4752.11 examples/s]Tokenizing train dataset:  32%|███▏      | 23992/73996 [00:05<00:10, 4758.60 examples/s]Tokenizing train dataset:  34%|███▎      | 24961/73996 [0
0:  23735/73996 [00:05<00:10, 4748.65 examples/s]Tokenizing train dataset:  32%|███▏      | 23727/73996 [00:05<00:10, 4684.14 examples/s]Tokenizing train dataset:  32%|███▏      | 23483/73996 [00:05<00:10, 4628.83 examples/s]Tokenizing train dataset:  32%|███▏      | 23974/73996 [00:05<00:10, 4692.90 examples/s]Tokenizing train dataset:  33%|███▎      | 24347/73996 [00:05<00:15, 3168.68 examples/s]Tokenizing train dataset:  33%|███▎      | 24347/73996 [00:05<00:16, 3086.43 examples/s]Tokenizing train dataset:  34%|███▎      | 24838/73996 [00:05<00:14, 3498.53 examples/s]Tokenizing train dataset:  33%|███▎      | 24588/73996 [00:05<00:15, 3133.04 examples/s]Tokenizing train dataset:  34%|███▎      | 24840/73996 [00:05<00:14, 3416.54 examples/s]Tokenizing train dataset:  34%|███▍      | 25487/73996 [00:05<00:13, 3728.79 examples/s]Tokenizing train dataset:  34%|███▍      | 25000/73996 [00:05<00:14, 3310.95 examples/s]Tokeniz
1: 0:05<00:15, 3133.86 examples/s]Tokenizing train dataset:  33%|███▎      | 24710/73996 [00:05<00:15, 3230.37 examples/s]Tokenizing train dataset:  33%|███▎      | 24709/73996 [00:05<00:16, 3070.66 examples/s]Tokenizing train dataset:  33%|███▎      | 24711/73996 [00:05<00:15, 3191.90 examples/s]Tokenizing train dataset:  34%|███▍      | 25364/73996 [00:05<00:14, 3293.05 examples/s]Tokenizing train dataset:  34%|███▍      | 25124/73996 [00:05<00:14, 3390.44 examples/s]Tokenizing train dataset:  34%|███▍      | 25121/73996 [00:05<00:14, 3260.81 examples/s]Tokenizing train dataset:  34%|███▍      | 25125/73996 [00:05<00:14, 3358.23 examples/s]Tokenizing train dataset:  35%|███▍      | 25892/73996 [00:05<00:13, 3697.07 examples/s]Tokenizing train dataset:  35%|███▍      | 25628/73996 [00:05<00:12, 3723.10 examples/s]Tokenizing train dataset:  35%|███▍      | 25605/73996 [00:05<00:13, 3585.33 examples/s]Tokenizing train datas
1: et:  35%|███▍      | 25619/73996 [00:05<00:13, 3674.44 examples/s]Tokenizing train dataset:  36%|███▌      | 26557/73996 [00:05<00:12, 3917.88 examples/s]Tokenizing train dataset:  36%|███▌      | 26285/73996 [00:05<00:12, 3918.95 examples/s]Tokenizing train dataset:  35%|███▌      | 26259/73996 [00:05<00:12, 3820.19 examples/s]Tokenizing train dataset:  36%|███▌      | 26282/73996 [00:05<00:12, 3895.31 examples/s]Tokenizing train dataset:  36%|███▋      | 27000/73996 [00:06<00:11, 3985.57 examples/s]Tokenizing train dataset:  36%|███▌      | 26790/73996 [00:05<00:11, 4168.10 examples/s]Tokenizing train dataset:  36%|███▌      | 26763/73996 [00:06<00:11, 4093.06 examples/s]Tokenizing train dataset:  36%|███▌      | 26790/73996 [00:06<00:11, 4155.91 examples/s]Tokenizing train dataset:  37%|███▋      | 27512/73996 [00:06<00:10, 4258.17 examples/s]Tokenizing train dataset:  37%|███▋      | 27258/73996 [00:06<00:11,
0: ing train dataset:  34%|███▍      | 25489/73996 [00:05<00:13, 3663.88 examples/s]Tokenizing train dataset:  35%|███▌      | 25991/73996 [00:05<00:11, 4010.03 examples/s]Tokenizing train dataset:  34%|███▍      | 25473/73996 [00:05<00:13, 3605.25 examples/s]Tokenizing train dataset:  35%|███▌      | 25993/73996 [00:05<00:12, 3949.23 examples/s]Tokenizing train dataset:  35%|███▌      | 25980/73996 [00:05<00:12, 3940.45 examples/s]Tokenizing train dataset:  36%|███▌      | 26666/73996 [00:05<00:11, 4160.67 examples/s]Tokenizing train dataset:  36%|███▌      | 26661/73996 [00:05<00:11, 4102.12 examples/s]Tokenizing train dataset:  36%|███▌      | 26642/73996 [00:05<00:11, 4093.95 examples/s]Tokenizing train dataset:  37%|███▋      | 27341/73996 [00:06<00:10, 4262.90 examples/s]Tokenizing train dataset:  37%|███▋      | 27346/73996 [00:06<00:10, 4242.82 examples/s]Tokenizing train dataset:  38%|███▊      | 27860/7399
1:  4213.75 examples/s]Tokenizing train dataset:  37%|███▋      | 27253/73996 [00:06<00:11, 4144.06 examples/s]Tokenizing train dataset:  37%|███▋      | 27257/73996 [00:06<00:11, 4206.45 examples/s]Tokenizing train dataset:  38%|███▊      | 28000/73996 [00:06<00:10, 4344.54 examples/s]Tokenizing train dataset:  38%|███▊      | 27791/73996 [00:06<00:10, 4493.47 examples/s]Tokenizing train dataset:  38%|███▊      | 27784/73996 [00:06<00:10, 4434.53 examples/s]Tokenizing train dataset:  38%|███▊      | 27786/73996 [00:06<00:10, 4477.48 examples/s]Tokenizing train dataset:  39%|███▊      | 28533/73996 [00:06<00:09, 4603.32 examples/s]Tokenizing train dataset:  38%|███▊      | 28263/73996 [00:06<00:10, 4445.12 examples/s]Tokenizing train dataset:  38%|███▊      | 28265/73996 [00:06<00:10, 4485.02 examples/s]Tokenizing train dataset:  39%|███▊      | 28537/73996 [00:06<00:09, 4605.43 examples/s]Tokenizing train dataset:  40%|
0: 6 [00:06<00:10, 4471.46 examples/s]Tokenizing train dataset:  37%|███▋      | 27306/73996 [00:06<00:11, 4197.91 examples/s]Tokenizing train dataset:  38%|███▊      | 27866/73996 [00:06<00:10, 4456.20 examples/s]Tokenizing train dataset:  38%|███▊      | 27829/73996 [00:06<00:10, 4437.19 examples/s]Tokenizing train dataset:  39%|███▊      | 28566/73996 [00:06<00:09, 4545.86 examples/s]Tokenizing train dataset:  39%|███▊      | 28583/73996 [00:06<00:09, 4559.77 examples/s]Tokenizing train dataset:  39%|███▊      | 28533/73996 [00:06<00:10, 4519.00 examples/s]Tokenizing train dataset:  40%|███▉      | 29297/73996 [00:06<00:09, 4647.41 examples/s]Tokenizing train dataset:  40%|███▉      | 29302/73996 [00:06<00:09, 4631.67 examples/s]Tokenizing train dataset:  40%|████      | 29820/73996 [00:06<00:09, 4780.34 examples/s]Tokenizing train dataset:  40%|███▉      | 29278/73996 [00:06<00:09, 4607.86 examples/s]Tokenizing train d
1: ██▉      | 29280/73996 [00:06<00:09, 4708.14 examples/s]Tokenizing train dataset:  39%|███▉      | 28810/73996 [00:06<00:09, 4719.31 examples/s]Tokenizing train dataset:  39%|███▉      | 28817/73996 [00:06<00:09, 4765.80 examples/s]Tokenizing train dataset:  40%|███▉      | 29276/73996 [00:06<00:09, 4692.84 examples/s]Tokenizing train dataset:  40%|████      | 29814/73996 [00:06<00:09, 4867.42 examples/s]Tokenizing train dataset:  40%|███▉      | 29534/73996 [00:06<00:09, 4747.39 examples/s]Tokenizing train dataset:  40%|███▉      | 29537/73996 [00:06<00:09, 4722.81 examples/s]Tokenizing train dataset:  40%|████      | 29810/73996 [00:06<00:09, 4846.87 examples/s]Tokenizing train dataset:  41%|████▏     | 30531/73996 [00:06<00:09, 4824.63 examples/s]Tokenizing train dataset:  41%|████      | 30261/73996 [00:06<00:09, 4745.05 examples/s]Tokenizing train dataset:  41%|████      | 30262/73996 [00:06<00:09, 4761.94 
0: ataset:  40%|████      | 29838/73996 [00:06<00:09, 4797.34 examples/s]Tokenizing train dataset:  40%|████      | 29803/73996 [00:06<00:09, 4755.66 examples/s]Tokenizing train dataset:  41%|████▏     | 30531/73996 [00:06<00:09, 4766.35 examples/s]Tokenizing train dataset:  41%|████▏     | 30536/73996 [00:06<00:09, 4745.18 examples/s]Tokenizing train dataset:  41%|████      | 30521/73996 [00:06<00:09, 4699.45 examples/s]Tokenizing train dataset:  42%|████▏     | 31277/73996 [00:06<00:09, 4740.76 examples/s]Tokenizing train dataset:  42%|████▏     | 31270/73996 [00:06<00:09, 4727.86 examples/s]Tokenizing train dataset:  42%|████▏     | 31000/73996 [00:06<00:09, 4608.50 examples/s]Tokenizing train dataset:  43%|████▎     | 31808/73996 [00:07<00:08, 4871.69 examples/s]Tokenizing train dataset:  43%|████▎     | 31794/73996 [00:07<00:08, 4845.71 examples/s]Tokenizing train dataset:  43%|████▎     | 31521
1: examples/s]Tokenizing train dataset:  41%|████▏     | 30533/73996 [00:06<00:09, 4811.07 examples/s]Tokenizing train dataset:  42%|████▏     | 31273/73996 [00:06<00:08, 4787.22 examples/s]Tokenizing train dataset:  42%|████▏     | 30790/73996 [00:06<00:08, 4875.55 examples/s]Tokenizing train dataset:  42%|████▏     | 30796/73996 [00:06<00:08, 4902.71 examples/s]Tokenizing train dataset:  42%|████▏     | 31276/73996 [00:06<00:08, 4783.93 examples/s]Tokenizing train dataset:  43%|████▎     | 31810/73996 [00:07<00:08, 4924.35 examples/s]Tokenizing train dataset:  43%|████▎     | 31533/73996 [00:06<00:08, 4828.86 examples/s]Tokenizing train dataset:  43%|████▎     | 31526/73996 [00:07<00:08, 4781.73 examples/s]Tokenizing train dataset:  43%|████▎     | 31810/73996 [00:06<00:08, 4909.91 examples/s]Tokenizing train dataset:  44%|████▍     | 32524/73996 [00:07<00:08, 4837.16 examples/s]Tokenizing train datas
1: et:  44%|████▎     | 32258/73996 [00:07<00:08, 4792.47 examples/s]Tokenizing train dataset:  44%|████▎     | 32258/73996 [00:07<00:08, 4737.84 examples/s]Tokenizing train dataset:  44%|████▍     | 32505/73996 [00:07<00:08, 4790.40 examples/s]Tokenizing train dataset:  45%|████▍     | 33272/73996 [00:07<00:08, 4792.97 examples/s]Tokenizing train dataset:  44%|████▍     | 32788/73996 [00:07<00:08, 4908.15 examples/s]Tokenizing train dataset:  44%|████▍     | 32783/73996 [00:07<00:08, 4856.65 examples/s]Tokenizing train dataset:  45%|████▍     | 33000/73996 [00:07<00:08, 4661.96 examples/s]Tokenizing train dataset:  46%|████▌     | 33786/73996 [00:07<00:08, 4872.45 examples/s]Tokenizing train dataset:  45%|████▌     | 33534/73996 [00:07<00:08, 4829.06 examples/s]Tokenizing train dataset:  45%|████▌     | 33531/73996 [00:07<00:08, 4825.74 examples/s]Tokenizing train dataset:  45%|████▌     | 335
0: /73996 [00:07<00:08, 4756.13 examples/s]Tokenizing train dataset:  44%|████▍     | 32504/73996 [00:07<00:08, 4754.50 examples/s]Tokenizing train dataset:  44%|████▍     | 32514/73996 [00:07<00:08, 4708.98 examples/s]Tokenizing train dataset:  44%|████▎     | 32262/73996 [00:07<00:08, 4694.74 examples/s]Tokenizing train dataset:  45%|████▍     | 33000/73996 [00:07<00:08, 4677.46 examples/s]Tokenizing train dataset:  44%|████▍     | 32763/73996 [00:07<00:08, 4769.09 examples/s]Tokenizing train dataset:  45%|████▍     | 33000/73996 [00:07<00:08, 4634.37 examples/s]Tokenizing train dataset:  45%|████▌     | 33520/73996 [00:07<00:08, 4804.67 examples/s]Tokenizing train dataset:  45%|████▌     | 33542/73996 [00:07<00:08, 4825.96 examples/s]Tokenizing train dataset:  45%|████▍     | 33274/73996 [00:07<00:08, 4676.55 examples/s]Tokenizing train dataset:  46%|████▋     | 34259/73996 [00:07<00:08, 4777.89 examp
1: 41/73996 [00:07<00:08, 4795.96 examples/s]Tokenizing train dataset:  47%|████▋     | 34531/73996 [00:07<00:08, 4833.41 examples/s]Tokenizing train dataset:  46%|████▋     | 34258/73996 [00:07<00:08, 4800.39 examples/s]Tokenizing train dataset:  46%|████▋     | 34259/73996 [00:07<00:08, 4798.02 examples/s]Tokenizing train dataset:  46%|████▋     | 34260/73996 [00:07<00:08, 4767.11 examples/s]Tokenizing train dataset:  47%|████▋     | 34790/73996 [00:07<00:07, 4928.37 examples/s]Tokenizing train dataset:  48%|████▊     | 35252/73996 [00:07<00:08, 4738.14 examples/s]Tokenizing train dataset:  47%|████▋     | 34779/73996 [00:07<00:08, 4889.42 examples/s]Tokenizing train dataset:  47%|████▋     | 34791/73996 [00:07<00:08, 4891.04 examples/s]Tokenizing train dataset:  48%|████▊     | 35760/73996 [00:07<00:07, 4814.14 examples/s]Tokenizing train dataset:  48%|████▊     | 35509/73996 [00:07<00:08, 4793.55 exa
0: les/s]Tokenizing train dataset:  46%|████▌     | 33806/73996 [00:07<00:08, 4843.96 examples/s]Tokenizing train dataset:  46%|████▋     | 34258/73996 [00:07<00:08, 4803.21 examples/s]Tokenizing train dataset:  47%|████▋     | 34792/73996 [00:07<00:07, 4911.17 examples/s]Tokenizing train dataset:  47%|████▋     | 34796/73996 [00:07<00:07, 4943.87 examples/s]Tokenizing train dataset:  47%|████▋     | 34535/73996 [00:07<00:08, 4817.20 examples/s]Tokenizing train dataset:  48%|████▊     | 35510/73996 [00:07<00:08, 4796.26 examples/s]Tokenizing train dataset:  48%|████▊     | 35506/73996 [00:07<00:08, 4795.53 examples/s]Tokenizing train dataset:  48%|████▊     | 35253/73996 [00:07<00:08, 4717.77 examples/s]Tokenizing train dataset:  49%|████▊     | 36000/73996 [00:07<00:08, 4684.69 examples/s]Tokenizing train dataset:  49%|████▊     | 36000/73996 [00:07<00:08, 4684.81 examples/s]Tokenizing train dataset:  
1: mples/s]Tokenizing train dataset:  48%|████▊     | 35503/73996 [00:07<00:08, 4725.32 examples/s]Tokenizing train dataset:  48%|████▊     | 35502/73996 [00:07<00:08, 4749.04 examples/s]Tokenizing train dataset:  49%|████▉     | 36251/73996 [00:07<00:08, 4676.18 examples/s]Tokenizing train dataset:  49%|████▊     | 36000/73996 [00:07<00:08, 4671.47 examples/s]Tokenizing train dataset:  49%|████▊     | 36000/73996 [00:07<00:08, 4627.61 examples/s]Tokenizing train dataset:  49%|████▊     | 36000/73996 [00:07<00:08, 4629.24 examples/s]Tokenizing train dataset:  50%|████▉     | 36770/73996 [00:08<00:07, 4803.42 examples/s]Tokenizing train dataset:  49%|████▉     | 36512/73996 [00:07<00:07, 4784.42 examples/s]Tokenizing train dataset:  49%|████▉     | 36506/73996 [00:08<00:07, 4730.62 examples/s]Tokenizing train dataset:  49%|████▉     | 36503/73996 [00:08<00:07, 4725.28 examples/s]Tokenizing train dataset:
0: 48%|████▊     | 35762/73996 [00:07<00:07, 4805.36 examples/s]Tokenizing train dataset:  49%|████▉     | 36519/73996 [00:08<00:07, 4810.70 examples/s]Tokenizing train dataset:  49%|████▉     | 36515/73996 [00:08<00:07, 4801.82 examples/s]Tokenizing train dataset:  49%|████▉     | 36253/73996 [00:08<00:08, 4663.11 examples/s]Tokenizing train dataset:  50%|█████     | 37236/73996 [00:08<00:07, 4699.56 examples/s]Tokenizing train dataset:  50%|█████     | 37000/73996 [00:08<00:07, 4647.73 examples/s]Tokenizing train dataset:  50%|████▉     | 36748/73996 [00:08<00:07, 4734.66 examples/s]Tokenizing train dataset:  51%|█████     | 37727/73996 [00:08<00:07, 4747.59 examples/s]Tokenizing train dataset:  51%|█████     | 37485/73996 [00:08<00:07, 4700.52 examples/s]Tokenizing train dataset:  51%|█████     | 37408/73996 [00:08<00:07, 4611.84 examples/s]Tokenizing train dataset:  51%|█████▏    | 38000/
1:   50%|█████     | 37000/73996 [00:08<00:07, 4668.41 examples/s]Tokenizing train dataset:  51%|█████     | 37502/73996 [00:08<00:07, 4689.54 examples/s]Tokenizing train dataset:  50%|█████     | 37000/73996 [00:08<00:07, 4628.96 examples/s]Tokenizing train dataset:  50%|█████     | 37000/73996 [00:08<00:08, 4567.58 examples/s]Tokenizing train dataset:  51%|█████     | 37503/73996 [00:08<00:07, 4762.50 examples/s]Tokenizing train dataset:  51%|█████▏    | 38000/73996 [00:08<00:07, 4619.67 examples/s]Tokenizing train dataset:  51%|█████     | 37499/73996 [00:08<00:07, 4722.84 examples/s]Tokenizing train dataset:  51%|█████     | 37507/73996 [00:08<00:07, 4695.38 examples/s]Tokenizing train dataset:  51%|█████▏    | 38000/73996 [00:08<00:07, 4666.27 examples/s]Tokenizing train dataset:  52%|█████▏    | 38506/73996 [00:08<00:07, 4730.91 examples/s]Tokenizing train dataset:  51%|█████▏    
1: | 38000/73996 [00:08<00:07, 4637.73 examples/s]Tokenizing train dataset:  51%|█████▏    | 38000/73996 [00:08<00:07, 4606.26 examples/s]Tokenizing train dataset:  52%|█████▏    | 38507/73996 [00:08<00:07, 4774.43 examples/s]Tokenizing train dataset:  53%|█████▎    | 39000/73996 [00:08<00:07, 4624.51 examples/s]Tokenizing train dataset:  52%|█████▏    | 38495/73996 [00:08<00:07, 4720.67 examples/s]Tokenizing train dataset:  52%|█████▏    | 38506/73996 [00:08<00:07, 4727.91 examples/s]Tokenizing train dataset:  53%|█████▎    | 39000/73996 [00:08<00:07, 4635.61 examples/s]Tokenizing train dataset:  53%|█████▎    | 39516/73996 [00:08<00:07, 4765.84 examples/s]Tokenizing train dataset:  53%|█████▎    | 39000/73996 [00:08<00:07, 4590.91 examples/s]Tokenizing train dataset:  53%|█████▎    | 39000/73996 [00:08<00:07, 4592.59 examples/s]Tokenizing train dataset:  53%|█████▎    | 39512/73996 
0: 73996 [00:08<00:07, 4629.15 examples/s]Tokenizing train dataset:  52%|█████▏    | 38419/73996 [00:08<00:07, 4696.39 examples/s]Tokenizing train dataset:  51%|█████▏    | 37928/73996 [00:08<00:07, 4757.25 examples/s]Tokenizing train dataset:  52%|█████▏    | 38514/73996 [00:08<00:07, 4768.47 examples/s]Tokenizing train dataset:  53%|█████▎    | 38937/73996 [00:08<00:07, 4814.05 examples/s]Tokenizing train dataset:  52%|█████▏    | 38601/73996 [00:08<00:07, 4659.00 examples/s]Tokenizing train dataset:  53%|█████▎    | 39000/73996 [00:08<00:07, 4629.68 examples/s]Tokenizing train dataset:  54%|█████▎    | 39628/73996 [00:08<00:07, 4739.32 examples/s]Tokenizing train dataset:  53%|█████▎    | 39520/73996 [00:08<00:07, 4785.72 examples/s]Tokenizing train dataset:  53%|█████▎    | 39269/73996 [00:08<00:07, 4586.51 examples/s]Tokenizing train dataset:  55%|█████▍    | 40337/73996 [00:08<0
1: [00:08<00:07, 4770.39 examples/s]Tokenizing train dataset:  54%|█████▍    | 40000/73996 [00:08<00:07, 4671.09 examples/s]Tokenizing train dataset:  53%|█████▎    | 39511/73996 [00:08<00:07, 4730.23 examples/s]Tokenizing train dataset:  53%|█████▎    | 39516/73996 [00:08<00:07, 4749.51 examples/s]Tokenizing train dataset:  54%|█████▍    | 40000/73996 [00:08<00:07, 4670.47 examples/s]Tokenizing train dataset:  55%|█████▍    | 40522/73996 [00:08<00:06, 4822.35 examples/s]Tokenizing train dataset:  54%|█████▍    | 40000/73996 [00:08<00:07, 4637.35 examples/s]Tokenizing train dataset:  54%|█████▍    | 40000/73996 [00:08<00:07, 4614.07 examples/s]Tokenizing train dataset:  55%|█████▍    | 40503/73996 [00:08<00:07, 4769.33 examples/s]Tokenizing train dataset:  55%|█████▍    | 40507/73996 [00:08<00:07, 4758.00 examples/s]Tokenizing train dataset:  55%|█████▍    | 40508/73996 [00:08<00:07, 
0: 0:07, 4731.49 examples/s]Tokenizing train dataset:  54%|█████▍    | 39792/73996 [00:08<00:07, 4740.77 examples/s]Tokenizing train dataset:  54%|█████▍    | 40255/73996 [00:08<00:07, 4734.22 examples/s]Tokenizing train dataset:  55%|█████▌    | 40826/73996 [00:08<00:06, 4764.81 examples/s]Tokenizing train dataset:  55%|█████▌    | 40768/73996 [00:08<00:06, 4833.60 examples/s]Tokenizing train dataset:  55%|█████▍    | 40523/73996 [00:08<00:07, 4666.74 examples/s]Tokenizing train dataset:  56%|█████▌    | 41543/73996 [00:09<00:06, 4766.61 examples/s]Tokenizing train dataset:  56%|█████▌    | 41269/73996 [00:09<00:06, 4749.96 examples/s]Tokenizing train dataset:  55%|█████▌    | 41000/73996 [00:09<00:07, 4585.89 examples/s]Tokenizing train dataset:  56%|█████▋    | 41805/73996 [00:09<00:06, 4913.18 examples/s]Tokenizing train dataset:  56%|█████▌    | 41529/73996 [00:09<00:06, 4759.65 
1: 4742.35 examples/s]Tokenizing train dataset:  56%|█████▌    | 41266/73996 [00:09<00:06, 4738.72 examples/s]Tokenizing train dataset:  55%|█████▌    | 41000/73996 [00:08<00:07, 4663.43 examples/s]Tokenizing train dataset:  55%|█████▌    | 41000/73996 [00:08<00:07, 4663.22 examples/s]Tokenizing train dataset:  55%|█████▌    | 41000/73996 [00:09<00:07, 4627.22 examples/s]Tokenizing train dataset:  56%|█████▋    | 41800/73996 [00:09<00:06, 4893.17 examples/s]Tokenizing train dataset:  56%|█████▌    | 41537/73996 [00:09<00:06, 4862.08 examples/s]Tokenizing train dataset:  56%|█████▌    | 41534/73996 [00:09<00:06, 4853.65 examples/s]Tokenizing train dataset:  56%|█████▌    | 41536/73996 [00:09<00:06, 4832.03 examples/s]Tokenizing train dataset:  57%|█████▋    | 42516/73996 [00:09<00:06, 4724.78 examples/s]Tokenizing train dataset:  57%|█████▋    | 42259/73996 [00:09<00:06, 4695.00 exampl
1: es/s]Tokenizing train dataset:  57%|█████▋    | 42261/73996 [00:09<00:06, 4688.80 examples/s]Tokenizing train dataset:  57%|█████▋    | 42262/73996 [00:09<00:06, 4666.38 examples/s]Tokenizing train dataset:  58%|█████▊    | 43000/73996 [00:09<00:06, 4663.20 examples/s]Tokenizing train dataset:  58%|█████▊    | 42793/73996 [00:09<00:06, 4860.75 examples/s]Tokenizing train dataset:  58%|█████▊    | 42794/73996 [00:09<00:06, 4853.01 examples/s]Tokenizing train dataset:  58%|█████▊    | 42793/73996 [00:09<00:06, 4828.96 examples/s]Tokenizing train dataset:  59%|█████▉    | 43508/73996 [00:09<00:06, 4767.52 examples/s]Tokenizing train dataset:  59%|█████▉    | 43511/73996 [00:09<00:06, 4767.45 examples/s]Tokenizing train dataset:  59%|█████▉    | 44000/73996 [00:09<00:06, 4664.46 examples/s]Tokenizing train dataset:  59%|█████▉    | 43511/73996 [00:09<00:06, 4755.33 examples/s]Tokenizi
0: examples/s]Tokenizing train dataset:  57%|█████▋    | 42259/73996 [00:09<00:06, 4681.29 examples/s]Tokenizing train dataset:  58%|█████▊    | 42788/73996 [00:09<00:06, 4821.36 examples/s]Tokenizing train dataset:  57%|█████▋    | 42531/73996 [00:09<00:06, 4733.67 examples/s]Tokenizing train dataset:  57%|█████▋    | 42260/73996 [00:09<00:06, 4645.69 examples/s]Tokenizing train dataset:  59%|█████▉    | 43516/73996 [00:09<00:06, 4769.27 examples/s]Tokenizing train dataset:  58%|█████▊    | 42793/73996 [00:09<00:06, 4810.27 examples/s]Tokenizing train dataset:  58%|█████▊    | 43260/73996 [00:09<00:06, 4733.77 examples/s]Tokenizing train dataset:  59%|█████▉    | 44000/73996 [00:09<00:06, 4672.39 examples/s]Tokenizing train dataset:  59%|█████▉    | 43782/73996 [00:09<00:06, 4850.48 examples/s]Tokenizing train dataset:  59%|█████▉    | 43505/73996 [00:09<00:06, 4719.02 examples/s]To
1: ng train dataset:  59%|█████▉    | 43508/73996 [00:09<00:06, 4732.03 examples/s]Tokenizing train dataset:  59%|█████▉    | 44000/73996 [00:09<00:06, 4660.50 examples/s]Tokenizing train dataset:  60%|██████    | 44481/73996 [00:09<00:06, 4702.72 examples/s]Tokenizing train dataset:  59%|█████▉    | 44000/73996 [00:09<00:06, 4656.21 examples/s]Tokenizing train dataset:  59%|█████▉    | 44000/73996 [00:09<00:06, 4608.54 examples/s]Tokenizing train dataset:  60%|██████    | 44479/73996 [00:09<00:06, 4692.39 examples/s]Tokenizing train dataset:  61%|██████    | 44989/73996 [00:09<00:06, 4804.71 examples/s]Tokenizing train dataset:  60%|██████    | 44478/73996 [00:09<00:06, 4685.82 examples/s]Tokenizing train dataset:  60%|██████    | 44480/73996 [00:09<00:06, 4655.81 examples/s]Tokenizing train dataset:  61%|██████    | 44982/73996 [00:09<00:06, 4780.85 examples/s]Tokenizing train datas
0: kenizing train dataset:  60%|██████    | 44487/73996 [00:09<00:06, 4719.31 examples/s]Tokenizing train dataset:  59%|█████▉    | 44000/73996 [00:09<00:06, 4616.21 examples/s]Tokenizing train dataset:  60%|██████    | 44485/73996 [00:09<00:06, 4678.03 examples/s]Tokenizing train dataset:  61%|██████    | 44983/73996 [00:09<00:06, 4779.31 examples/s]Tokenizing train dataset:  60%|██████    | 44478/73996 [00:09<00:06, 4655.39 examples/s]Tokenizing train dataset:  61%|██████    | 44999/73996 [00:09<00:06, 4784.89 examples/s]Tokenizing train dataset:  62%|██████▏   | 45663/73996 [00:09<00:06, 4686.10 examples/s]Tokenizing train dataset:  61%|██████    | 44975/73996 [00:09<00:06, 4737.36 examples/s]Tokenizing train dataset:  62%|██████▏   | 45680/73996 [00:09<00:06, 4698.07 examples/s]Tokenizing train dataset:  63%|██████▎   | 46341/73996 [00:10<00:05, 4627.71 examples/s]Tokenizing
1: et:  61%|██████    | 44986/73996 [00:09<00:06, 4789.01 examples/s]Tokenizing train dataset:  61%|██████    | 44982/73996 [00:09<00:06, 4752.34 examples/s]Tokenizing train dataset:  62%|██████▏   | 45666/73996 [00:09<00:06, 4691.98 examples/s]Tokenizing train dataset:  62%|██████▏   | 45658/73996 [00:09<00:06, 4676.98 examples/s]Tokenizing train dataset:  62%|██████▏   | 45666/73996 [00:09<00:06, 4690.46 examples/s]Tokenizing train dataset:  62%|██████▏   | 45663/73996 [00:10<00:06, 4672.35 examples/s]Tokenizing train dataset:  63%|██████▎   | 46331/73996 [00:10<00:06, 4599.83 examples/s]Tokenizing train dataset:  63%|██████▎   | 46334/73996 [00:10<00:05, 4614.85 examples/s]Tokenizing train dataset:  63%|██████▎   | 46849/73996 [00:10<00:05, 4742.11 examples/s]Tokenizing train dataset:  63%|██████▎   | 46340/73996 [00:10<00:05, 4619.46 examples/s]Tokenizing train dat
0:  train dataset:  62%|██████▏   | 45648/73996 [00:10<00:06, 4643.24 examples/s]Tokenizing train dataset:  63%|██████▎   | 46353/73996 [00:10<00:05, 4627.13 examples/s]Tokenizing train dataset:  63%|██████▎   | 46863/73996 [00:10<00:05, 4769.04 examples/s]Tokenizing train dataset:  63%|██████▎   | 46312/73996 [00:10<00:06, 4566.38 examples/s]Tokenizing train dataset:  63%|██████▎   | 46880/73996 [00:10<00:05, 4777.17 examples/s]Tokenizing train dataset:  64%|██████▍   | 47548/73996 [00:10<00:05, 4695.16 examples/s]Tokenizing train dataset:  63%|██████▎   | 46834/73996 [00:10<00:05, 4722.26 examples/s]Tokenizing train dataset:  64%|██████▍   | 47568/73996 [00:10<00:05, 4709.56 examples/s]Tokenizing train dataset:  65%|██████▌   | 48267/73996 [00:10<00:05, 4693.49 examples/s]Tokenizing train dataset:  64%|██████▍   | 47523/73996 [00:10<00:05, 4671.72 examples/s]Toke
1: aset:  63%|██████▎   | 46331/73996 [00:10<00:06, 4594.22 examples/s]Tokenizing train dataset:  63%|██████▎   | 46857/73996 [00:10<00:05, 4763.49 examples/s]Tokenizing train dataset:  63%|██████▎   | 46860/73996 [00:10<00:05, 4762.04 examples/s]Tokenizing train dataset:  63%|██████▎   | 46853/73996 [00:10<00:05, 4745.60 examples/s]Tokenizing train dataset:  64%|██████▍   | 47527/73996 [00:10<00:05, 4662.15 examples/s]Tokenizing train dataset:  64%|██████▍   | 47542/73996 [00:10<00:05, 4690.67 examples/s]Tokenizing train dataset:  65%|██████▍   | 48000/73996 [00:10<00:05, 4580.01 examples/s]Tokenizing train dataset:  64%|██████▍   | 47542/73996 [00:10<00:05, 4682.87 examples/s]Tokenizing train dataset:  64%|██████▍   | 47536/73996 [00:10<00:05, 4676.29 examples/s]Tokenizing train dataset:  66%|██████▌   | 48520/73996 [00:10<00:05, 4737.74 examples/s]Tokenizing tra
1: in dataset:  65%|██████▌   | 48264/73996 [00:10<00:05, 4664.24 examples/s]Tokenizing train dataset:  65%|██████▌   | 48264/73996 [00:10<00:05, 4662.31 examples/s]Tokenizing train dataset:  65%|██████▌   | 48264/73996 [00:10<00:05, 4646.70 examples/s]Tokenizing train dataset:  66%|██████▌   | 49000/73996 [00:10<00:05, 4666.01 examples/s]Tokenizing train dataset:  66%|██████▌   | 48791/73996 [00:10<00:05, 4803.86 examples/s]Tokenizing train dataset:  66%|██████▌   | 48792/73996 [00:10<00:05, 4806.64 examples/s]Tokenizing train dataset:  66%|██████▌   | 48786/73996 [00:10<00:05, 4778.65 examples/s]Tokenizing train dataset:  67%|██████▋   | 49530/73996 [00:10<00:05, 4838.58 examples/s]Tokenizing train dataset:  67%|██████▋   | 49527/73996 [00:10<00:05, 4767.44 examples/s]Tokenizing train dataset:  67%|██████▋   | 49530/73996 [00:10<00:05, 4775.07 examples/s]Tokenizi
0: nizing train dataset:  65%|██████▌   | 48267/73996 [00:10<00:05, 4689.57 examples/s]Tokenizing train dataset:  66%|██████▌   | 48794/73996 [00:10<00:05, 4826.99 examples/s]Tokenizing train dataset:  65%|██████▍   | 48000/73996 [00:10<00:05, 4551.72 examples/s]Tokenizing train dataset:  66%|██████▌   | 48795/73996 [00:10<00:05, 4827.04 examples/s]Tokenizing train dataset:  66%|██████▌   | 48522/73996 [00:10<00:05, 4718.33 examples/s]Tokenizing train dataset:  67%|██████▋   | 49543/73996 [00:10<00:05, 4831.82 examples/s]Tokenizing train dataset:  67%|██████▋   | 49531/73996 [00:10<00:05, 4797.89 examples/s]Tokenizing train dataset:  66%|██████▌   | 49000/73996 [00:10<00:05, 4610.08 examples/s]Tokenizing train dataset:  68%|██████▊   | 50263/73996 [00:10<00:04, 4762.85 examples/s]Tokenizing train dataset:  67%|██████▋   | 49472/73996 [00:10<00:05, 4638.53 examples/s
1: ng train dataset:  67%|██████▋   | 49524/73996 [00:10<00:05, 4726.81 examples/s]Tokenizing train dataset:  68%|██████▊   | 50262/73996 [00:10<00:04, 4769.35 examples/s]Tokenizing train dataset:  68%|██████▊   | 50262/73996 [00:10<00:05, 4714.80 examples/s]Tokenizing train dataset:  69%|██████▊   | 50782/73996 [00:11<00:04, 4876.97 examples/s]Tokenizing train dataset:  68%|██████▊   | 50260/73996 [00:10<00:05, 4726.22 examples/s]Tokenizing train dataset:  68%|██████▊   | 50259/73996 [00:11<00:05, 4653.80 examples/s]Tokenizing train dataset:  69%|██████▊   | 50790/73996 [00:10<00:04, 4843.87 examples/s]Tokenizing train dataset:  69%|██████▊   | 50789/73996 [00:11<00:04, 4853.69 examples/s]Tokenizing train dataset:  69%|██████▊   | 50789/73996 [00:11<00:04, 4797.98 examples/s]Tokenizing train dataset:  70%|██████▉   | 51521/73996 [00:11<00:04, 4807.69 examples/s]To
0: ]Tokenizing train dataset:  68%|██████▊   | 50264/73996 [00:10<00:04, 4752.64 examples/s]Tokenizing train dataset:  69%|██████▊   | 50784/73996 [00:11<00:04, 4864.01 examples/s]Tokenizing train dataset:  68%|██████▊   | 49984/73996 [00:10<00:05, 4768.30 examples/s]Tokenizing train dataset:  69%|██████▊   | 50796/73996 [00:11<00:04, 4882.60 examples/s]Tokenizing train dataset:  70%|██████▉   | 51514/73996 [00:11<00:04, 4803.89 examples/s]Tokenizing train dataset:  68%|██████▊   | 50670/73996 [00:11<00:04, 4693.89 examples/s]Tokenizing train dataset:  70%|██████▉   | 51511/73996 [00:11<00:04, 4796.84 examples/s]Tokenizing train dataset:  70%|███████   | 52000/73996 [00:11<00:04, 4692.70 examples/s]Tokenizing train dataset:  69%|██████▉   | 51368/73996 [00:11<00:04, 4678.33 examples/s]Tokenizing train dataset:  70%|███████   | 52000/73996 [00:11<00:04, 4699.97 exam
1: kenizing train dataset:  70%|██████▉   | 51520/73996 [00:11<00:04, 4796.87 examples/s]Tokenizing train dataset:  70%|██████▉   | 51516/73996 [00:11<00:04, 4791.91 examples/s]Tokenizing train dataset:  70%|██████▉   | 51523/73996 [00:11<00:04, 4758.36 examples/s]Tokenizing train dataset:  71%|███████   | 52266/73996 [00:11<00:04, 4762.84 examples/s]Tokenizing train dataset:  71%|███████   | 52271/73996 [00:11<00:04, 4761.23 examples/s]Tokenizing train dataset:  71%|███████▏  | 52799/73996 [00:11<00:04, 4894.98 examples/s]Tokenizing train dataset:  71%|███████   | 52272/73996 [00:11<00:04, 4766.71 examples/s]Tokenizing train dataset:  71%|███████   | 52273/73996 [00:11<00:04, 4730.38 examples/s]Tokenizing train dataset:  71%|███████▏  | 52803/73996 [00:11<00:04, 4886.85 examples/s]Tokenizing train dataset:  71%|███████▏  | 52805/73996 [00:11<00:04, 4894.26 ex
0: ples/s]Tokenizing train dataset:  71%|███████   | 52538/73996 [00:11<00:04, 4863.18 examples/s]Tokenizing train dataset:  70%|███████   | 51880/73996 [00:11<00:04, 4784.63 examples/s]Tokenizing train dataset:  71%|███████   | 52544/73996 [00:11<00:04, 4882.15 examples/s]Tokenizing train dataset:  72%|███████▏  | 53266/73996 [00:11<00:04, 4822.94 examples/s]Tokenizing train dataset:  71%|███████   | 52590/73996 [00:11<00:04, 4765.85 examples/s]Tokenizing train dataset:  72%|███████▏  | 53267/73996 [00:11<00:04, 4825.72 examples/s]Tokenizing train dataset:  73%|███████▎  | 53791/73996 [00:11<00:04, 4927.16 examples/s]Tokenizing train dataset:  73%|███████▎  | 53796/73996 [00:11<00:04, 4939.41 examples/s]Tokenizing train dataset:  72%|███████▏  | 53288/73996 [00:11<00:04, 4725.42 examples/s]Tokenizing train dataset:  74%|███████▎  | 54532/73996 [00:11<0
1: amples/s]Tokenizing train dataset:  72%|███████▏  | 53532/73996 [00:11<00:04, 4843.93 examples/s]Tokenizing train dataset:  71%|███████▏  | 52805/73996 [00:11<00:04, 4862.75 examples/s]Tokenizing train dataset:  72%|███████▏  | 53534/73996 [00:11<00:04, 4839.53 examples/s]Tokenizing train dataset:  72%|███████▏  | 53533/73996 [00:11<00:04, 4846.15 examples/s]Tokenizing train dataset:  72%|███████▏  | 53533/73996 [00:11<00:04, 4815.72 examples/s]Tokenizing train dataset:  73%|███████▎  | 54259/73996 [00:11<00:04, 4789.69 examples/s]Tokenizing train dataset:  73%|███████▎  | 54256/73996 [00:11<00:04, 4773.14 examples/s]Tokenizing train dataset:  74%|███████▍  | 54791/73996 [00:11<00:03, 4908.99 examples/s]Tokenizing train dataset:  73%|███████▎  | 54255/73996 [00:11<00:04, 4769.77 examples/s]Tokenizing train dataset:  73%|███████▎  | 54257/7399
1: 6 [00:11<00:04, 4741.80 examples/s]Tokenizing train dataset:  74%|███████▍  | 54789/73996 [00:11<00:03, 4898.04 examples/s]Tokenizing train dataset:  74%|███████▍  | 54789/73996 [00:11<00:03, 4898.20 examples/s]Tokenizing train dataset:  75%|███████▌  | 55507/73996 [00:12<00:03, 4801.80 examples/s]Tokenizing train dataset:  74%|███████▍  | 54786/73996 [00:11<00:03, 4864.17 examples/s]Tokenizing train dataset:  75%|███████▌  | 55508/73996 [00:11<00:03, 4788.80 examples/s]Tokenizing train dataset:  76%|███████▌  | 56000/73996 [00:12<00:03, 4663.28 examples/s]Tokenizing train dataset:  75%|███████▌  | 55505/73996 [00:12<00:03, 4779.29 examples/s]Tokenizing train dataset:  75%|███████▌  | 55506/73996 [00:12<00:03, 4751.30 examples/s]Tokenizing train dataset:  76%|███████▌  | 56000/73996 [00:12<00:03, 4663.28 examples/s]Tokenizing train dataset:  76%|████
0: 0:03, 4868.77 examples/s]Tokenizing train dataset:  73%|███████▎  | 53807/73996 [00:11<00:04, 4833.56 examples/s]Tokenizing train dataset:  74%|███████▎  | 54534/73996 [00:11<00:04, 4862.15 examples/s]Tokenizing train dataset:  75%|███████▍  | 55259/73996 [00:11<00:03, 4806.79 examples/s]Tokenizing train dataset:  74%|███████▎  | 54529/73996 [00:11<00:04, 4776.96 examples/s]Tokenizing train dataset:  75%|███████▍  | 55258/73996 [00:11<00:03, 4798.89 examples/s]Tokenizing train dataset:  75%|███████▌  | 55771/73996 [00:12<00:03, 4878.16 examples/s]Tokenizing train dataset:  75%|███████▌  | 55759/73996 [00:12<00:03, 4846.83 examples/s]Tokenizing train dataset:  75%|███████▍  | 55230/73996 [00:12<00:04, 4668.16 examples/s]Tokenizing train dataset:  76%|███████▋  | 56489/73996 [00:12<00:03, 4695.69 examples/s]Tokenizing train dataset:  75%|███████
1: ███▋  | 56525/73996 [00:12<00:03, 4807.00 examples/s]Tokenizing train dataset:  76%|███████▌  | 56000/73996 [00:12<00:03, 4672.12 examples/s]Tokenizing train dataset:  76%|███████▌  | 56000/73996 [00:12<00:03, 4623.00 examples/s]Tokenizing train dataset:  76%|███████▋  | 56530/73996 [00:12<00:03, 4817.73 examples/s]Tokenizing train dataset:  76%|███████▋  | 56528/73996 [00:12<00:03, 4819.20 examples/s]Tokenizing train dataset:  76%|███████▋  | 56516/73996 [00:12<00:03, 4752.62 examples/s]Tokenizing train dataset:  77%|███████▋  | 57066/73996 [00:12<00:05, 2973.60 examples/s]Tokenizing train dataset:  78%|███████▊  | 57570/73996 [00:12<00:04, 3349.48 examples/s]Tokenizing train dataset:  77%|███████▋  | 57087/73996 [00:12<00:05, 2878.57 examples/s]Tokenizing train dataset:  77%|███████▋  | 57082/73996 [00:12<00:05, 3007.32 examples/s]Tokenizing train 
0:   | 55703/73996 [00:12<00:03, 4678.36 examples/s]Tokenizing train dataset:  76%|███████▌  | 56395/73996 [00:12<00:03, 4640.25 examples/s]Tokenizing train dataset:  76%|███████▌  | 56359/73996 [00:12<00:03, 4574.49 examples/s]Tokenizing train dataset:  77%|███████▋  | 57000/73996 [00:12<00:05, 3138.65 examples/s]Tokenizing train dataset:  78%|███████▊  | 57511/73996 [00:12<00:04, 3494.44 examples/s]Tokenizing train dataset:  77%|███████▋  | 57000/73996 [00:12<00:05, 2880.52 examples/s]Tokenizing train dataset:  78%|███████▊  | 58000/73996 [00:12<00:04, 3715.91 examples/s]Tokenizing train dataset:  78%|███████▊  | 57540/73996 [00:12<00:04, 3299.19 examples/s]Tokenizing train dataset:  77%|███████▋  | 57000/73996 [00:12<00:05, 2946.14 examples/s]Tokenizing train dataset:  79%|███████▉  | 58509/73996 [00:12<00:03, 4019.82 examples/s]Tokenizing train dataset:  
1: dataset:  77%|███████▋  | 57093/73996 [00:12<00:05, 3043.80 examples/s]Tokenizing train dataset:  78%|███████▊  | 58001/73996 [00:12<00:04, 3544.64 examples/s]Tokenizing train dataset:  78%|███████▊  | 57618/73996 [00:12<00:04, 3304.33 examples/s]Tokenizing train dataset:  78%|███████▊  | 57545/73996 [00:12<00:04, 3302.59 examples/s]Tokenizing train dataset:  78%|███████▊  | 57619/73996 [00:12<00:04, 3449.44 examples/s]Tokenizing train dataset:  79%|███████▉  | 58511/73996 [00:12<00:03, 3896.61 examples/s]Tokenizing train dataset:  78%|███████▊  | 57973/73996 [00:12<00:04, 3502.68 examples/s]Tokenizing train dataset:  79%|███████▉  | 58287/73996 [00:12<00:04, 3618.08 examples/s]Tokenizing train dataset:  80%|███████▉  | 58993/73996 [00:13<00:03, 4120.10 examples/s]Tokenizing train dataset:  79%|███████▊  | 58271/73996 [00:12<00:04, 3699.59 exa
0: 78%|███████▊  | 58000/73996 [00:12<00:04, 3504.40 examples/s]Tokenizing train dataset:  78%|███████▊  | 57509/73996 [00:12<00:04, 3305.26 examples/s]Tokenizing train dataset:  80%|███████▉  | 58982/73996 [00:12<00:03, 4187.65 examples/s]Tokenizing train dataset:  79%|███████▉  | 58497/73996 [00:12<00:04, 3815.10 examples/s]Tokenizing train dataset:  78%|███████▊  | 58000/73996 [00:12<00:04, 3528.68 examples/s]Tokenizing train dataset:  80%|███████▉  | 58987/73996 [00:13<00:03, 4067.79 examples/s]Tokenizing train dataset:  81%|████████  | 59657/73996 [00:13<00:03, 4291.18 examples/s]Tokenizing train dataset:  79%|███████▉  | 58501/73996 [00:13<00:04, 3841.86 examples/s]Tokenizing train dataset:  80%|███████▉  | 58988/73996 [00:13<00:03, 4079.82 examples/s]Tokenizing train dataset:  81%|████████  | 59662/73996 [00:13<00:03, 4207.99 examples/s]T
1: mples/s]Tokenizing train dataset:  79%|███████▉  | 58785/73996 [00:12<00:03, 3897.64 examples/s]Tokenizing train dataset:  79%|███████▉  | 58614/73996 [00:12<00:04, 3737.61 examples/s]Tokenizing train dataset:  79%|███████▉  | 58765/73996 [00:13<00:03, 3960.44 examples/s]Tokenizing train dataset:  81%|████████  | 59667/73996 [00:13<00:03, 4245.01 examples/s]Tokenizing train dataset:  80%|████████  | 59247/73996 [00:13<00:03, 3972.07 examples/s]Tokenizing train dataset:  80%|████████  | 59245/73996 [00:13<00:03, 4019.14 examples/s]Tokenizing train dataset:  80%|████████  | 59263/73996 [00:13<00:03, 3915.16 examples/s]Tokenizing train dataset:  81%|████████  | 59764/73996 [00:13<00:03, 4256.93 examples/s]Tokenizing train dataset:  82%|████████▏ | 60334/73996 [00:13<00:03, 4309.60 examples/s]Tokenizing train dataset:  81%|████████  | 59759/739
1: 96 [00:13<00:03, 4290.88 examples/s]Tokenizing train dataset:  81%|████████  | 59782/73996 [00:13<00:03, 4200.36 examples/s]Tokenizing train dataset:  81%|████████▏ | 60252/73996 [00:13<00:03, 4259.24 examples/s]Tokenizing train dataset:  82%|████████▏ | 60857/73996 [00:13<00:02, 4525.63 examples/s]Tokenizing train dataset:  81%|████████▏ | 60248/73996 [00:13<00:03, 4260.39 examples/s]Tokenizing train dataset:  81%|████████▏ | 60252/73996 [00:13<00:03, 4196.97 examples/s]Tokenizing train dataset:  82%|████████▏ | 60780/73996 [00:13<00:02, 4522.69 examples/s]Tokenizing train dataset:  82%|████████▏ | 60756/73996 [00:13<00:02, 4472.43 examples/s]Tokenizing train dataset:  82%|████████▏ | 60786/73996 [00:13<00:02, 4484.22 examples/s]Tokenizing train dataset:  83%|████████▎ | 61561/73996 [00:13<00:02, 4579.63 examples/s]Tokenizing train dataset: 
0: okenizing train dataset:  82%|████████▏ | 60317/73996 [00:13<00:03, 4323.07 examples/s]Tokenizing train dataset:  82%|████████▏ | 60838/73996 [00:13<00:02, 4531.22 examples/s]Tokenizing train dataset:  81%|████████  | 59656/73996 [00:13<00:03, 4200.78 examples/s]Tokenizing train dataset:  82%|████████▏ | 60327/73996 [00:13<00:03, 4277.90 examples/s]Tokenizing train dataset:  82%|████████▏ | 60850/73996 [00:13<00:02, 4499.31 examples/s]Tokenizing train dataset:  83%|████████▎ | 61546/73996 [00:13<00:02, 4592.69 examples/s]Tokenizing train dataset:  82%|████████▏ | 60320/73996 [00:13<00:03, 4271.85 examples/s]Tokenizing train dataset:  82%|████████▏ | 60840/73996 [00:13<00:02, 4487.50 examples/s]Tokenizing train dataset:  83%|████████▎ | 61557/73996 [00:13<00:02, 4568.60 examples/s]Tokenizing train dataset:  84%|████████▍ | 622
1:  83%|████████▎ | 61262/73996 [00:13<00:02, 4485.66 examples/s]Tokenizing train dataset:  83%|████████▎ | 61259/73996 [00:13<00:02, 4449.26 examples/s]Tokenizing train dataset:  83%|████████▎ | 61255/73996 [00:13<00:02, 4420.02 examples/s]Tokenizing train dataset:  84%|████████▍ | 62271/73996 [00:13<00:02, 4625.94 examples/s]Tokenizing train dataset:  84%|████████▎ | 61806/73996 [00:13<00:02, 4745.73 examples/s]Tokenizing train dataset:  84%|████████▎ | 61811/73996 [00:13<00:02, 4735.29 examples/s]Tokenizing train dataset:  84%|████████▎ | 61801/73996 [00:13<00:02, 4698.08 examples/s]Tokenizing train dataset:  85%|████████▍ | 62804/73996 [00:13<00:02, 4791.06 examples/s]Tokenizing train dataset:  85%|████████▍ | 62527/73996 [00:13<00:02, 4744.17 examples/s]Tokenizing train dataset:  85%|████████▍ | 62528/73996 [00:13<00:02, 
0: 70/73996 [00:13<00:02, 4666.55 examples/s]Tokenizing train dataset:  85%|████████▍ | 62805/73996 [00:13<00:02, 4826.33 examples/s]Tokenizing train dataset:  83%|████████▎ | 61542/73996 [00:13<00:02, 4548.22 examples/s]Tokenizing train dataset:  84%|████████▍ | 62274/73996 [00:13<00:02, 4633.97 examples/s]Tokenizing train dataset:  85%|████████▍ | 62803/73996 [00:13<00:02, 4784.86 examples/s]Tokenizing train dataset:  86%|████████▌ | 63529/73996 [00:13<00:02, 4768.42 examples/s]Tokenizing train dataset:  84%|████████▍ | 62258/73996 [00:13<00:02, 4594.19 examples/s]Tokenizing train dataset:  85%|████████▍ | 62783/73996 [00:13<00:02, 4745.77 examples/s]Tokenizing train dataset:  86%|████████▌ | 63535/73996 [00:13<00:02, 4763.67 examples/s]Tokenizing train dataset:  87%|████████▋ | 64267/73996 [00:14<00:02, 4782.97 examples/s]Tokenizing train d
1: 4732.33 examples/s]Tokenizing train dataset:  84%|████████▍ | 62523/73996 [00:13<00:02, 4694.83 examples/s]Tokenizing train dataset:  86%|████████▌ | 63523/73996 [00:13<00:02, 4743.90 examples/s]Tokenizing train dataset:  85%|████████▌ | 63257/73996 [00:13<00:02, 4696.82 examples/s]Tokenizing train dataset:  85%|████████▌ | 63260/73996 [00:13<00:02, 4622.34 examples/s]Tokenizing train dataset:  85%|████████▌ | 63260/73996 [00:13<00:02, 4665.01 examples/s]Tokenizing train dataset:  87%|████████▋ | 64264/73996 [00:14<00:02, 4738.01 examples/s]Tokenizing train dataset:  86%|████████▌ | 63783/73996 [00:13<00:02, 4831.43 examples/s]Tokenizing train dataset:  86%|████████▌ | 63794/73996 [00:14<00:02, 4793.38 examples/s]Tokenizing train dataset:  86%|████████▌ | 63790/73996 [00:14<00:02, 4816.78 examples/s]Tokenizing train dataset:  88%|███
1: ████▊ | 64796/73996 [00:14<00:01, 4873.00 examples/s]Tokenizing train dataset:  87%|████████▋ | 64533/73996 [00:14<00:01, 4827.93 examples/s]Tokenizing train dataset:  87%|████████▋ | 64526/73996 [00:14<00:01, 4762.06 examples/s]Tokenizing train dataset:  87%|████████▋ | 64523/73996 [00:14<00:01, 4784.81 examples/s]Tokenizing train dataset:  89%|████████▊ | 65489/73996 [00:14<00:01, 4709.82 examples/s]Tokenizing train dataset:  88%|████████▊ | 65246/73996 [00:14<00:01, 4698.89 examples/s]Tokenizing train dataset:  89%|████████▉ | 65985/73996 [00:14<00:01, 4767.18 examples/s]Tokenizing train dataset:  88%|████████▊ | 65227/73996 [00:14<00:01, 4630.17 examples/s]Tokenizing train dataset:  88%|████████▊ | 65227/73996 [00:14<00:01, 4631.45 examples/s]Tokenizing train dataset:  89%|████████▉ | 65730/73996 [00:14<00:01, 4728.86 example
0: ataset:  88%|████████▊ | 64803/73996 [00:14<00:01, 4915.45 examples/s]Tokenizing train dataset:  86%|████████▌ | 63518/73996 [00:14<00:02, 4703.66 examples/s]Tokenizing train dataset:  87%|████████▋ | 64259/73996 [00:14<00:02, 4749.48 examples/s]Tokenizing train dataset:  86%|████████▋ | 64000/73996 [00:14<00:02, 4632.48 examples/s]Tokenizing train dataset:  88%|████████▊ | 64778/73996 [00:14<00:01, 4850.70 examples/s]Tokenizing train dataset:  89%|████████▊ | 65493/73996 [00:14<00:01, 4732.03 examples/s]Tokenizing train dataset:  87%|████████▋ | 64521/73996 [00:14<00:01, 4775.83 examples/s]Tokenizing train dataset:  89%|████████▉ | 66000/73996 [00:14<00:01, 4670.22 examples/s]Tokenizing train dataset:  89%|████████▊ | 65517/73996 [00:14<00:01, 4750.89 examples/s]Tokenizing train dataset:  90%|████████▉ | 66520/73996 [00:14
1: s/s]Tokenizing train dataset:  89%|████████▉ | 65722/73996 [00:14<00:01, 4701.57 examples/s]Tokenizing train dataset:  89%|████████▉ | 65721/73996 [00:14<00:01, 4702.47 examples/s]Tokenizing train dataset:  90%|█████████ | 66628/73996 [00:14<00:01, 4600.40 examples/s]Tokenizing train dataset:  90%|████████▉ | 66393/73996 [00:14<00:01, 4622.14 examples/s]Tokenizing train dataset:  90%|████████▉ | 66389/73996 [00:14<00:01, 4615.21 examples/s]Tokenizing train dataset:  90%|████████▉ | 66387/73996 [00:14<00:01, 4612.78 examples/s]Tokenizing train dataset:  91%|█████████ | 67299/73996 [00:14<00:01, 4554.35 examples/s]Tokenizing train dataset:  90%|█████████ | 66893/73996 [00:14<00:01, 4709.52 examples/s]Tokenizing train dataset:  90%|█████████ | 66895/73996 [00:14<00:01, 4720.53 examples/s]Tokenizing train dataset:  90%|████████
0: <00:01, 4799.07 examples/s]Tokenizing train dataset:  88%|████████▊ | 65251/73996 [00:14<00:01, 4708.34 examples/s]Tokenizing train dataset:  89%|████████▉ | 66000/73996 [00:14<00:01, 4660.85 examples/s]Tokenizing train dataset:  89%|████████▉ | 65761/73996 [00:14<00:01, 4801.05 examples/s]Tokenizing train dataset:  90%|████████▉ | 66513/73996 [00:14<00:01, 4774.59 examples/s]Tokenizing train dataset:  91%|█████████ | 67261/73996 [00:14<00:01, 4715.81 examples/s]Tokenizing train dataset:  90%|████████▉ | 66252/73996 [00:14<00:01, 4664.10 examples/s]Tokenizing train dataset:  91%|█████████ | 67000/73996 [00:14<00:01, 4622.98 examples/s]Tokenizing train dataset:  92%|█████████▏| 67796/73996 [00:14<00:01, 4867.59 examples/s]Tokenizing train dataset:  90%|█████████ | 66750/73996 [00:14<00:01, 4745.41 examples/s]Tokenizing train dataset:  91%|
1:  | 66887/73996 [00:14<00:01, 4702.51 examples/s]Tokenizing train dataset:  92%|█████████▏| 67827/73996 [00:14<00:01, 4723.21 examples/s]Tokenizing train dataset:  91%|█████████▏| 67574/73996 [00:14<00:01, 4648.36 examples/s]Tokenizing train dataset:  91%|█████████▏| 67571/73996 [00:14<00:01, 4645.84 examples/s]Tokenizing train dataset:  91%|█████████▏| 67552/73996 [00:14<00:01, 4608.28 examples/s]Tokenizing train dataset:  93%|█████████▎| 68536/73996 [00:15<00:01, 4718.32 examples/s]Tokenizing train dataset:  92%|█████████▏| 68282/73996 [00:14<00:01, 4668.98 examples/s]Tokenizing train dataset:  92%|█████████▏| 68282/73996 [00:14<00:01, 4673.44 examples/s]Tokenizing train dataset:  92%|█████████▏| 68265/73996 [00:15<00:01, 4627.33 examples/s]Tokenizing train dataset:  94%|█████████▎| 69270/73996 [00:15<00:00, 4730.08 exam
0: █████████▏| 67530/73996 [00:14<00:01, 4798.34 examples/s]Tokenizing train dataset:  93%|█████████▎| 68529/73996 [00:14<00:01, 4823.71 examples/s]Tokenizing train dataset:  91%|█████████ | 67252/73996 [00:14<00:01, 4605.47 examples/s]Tokenizing train dataset:  92%|█████████▏| 68270/73996 [00:14<00:01, 4790.05 examples/s]Tokenizing train dataset:  92%|█████████▏| 67767/73996 [00:14<00:01, 4749.70 examples/s]Tokenizing train dataset:  94%|█████████▎| 69271/73996 [00:15<00:00, 4821.75 examples/s]Tokenizing train dataset:  93%|█████████▎| 68796/73996 [00:15<00:01, 4907.57 examples/s]Tokenizing train dataset:  92%|█████████▏| 68257/73996 [00:15<00:01, 4659.15 examples/s]Tokenizing train dataset:  94%|█████████▍| 69798/73996 [00:15<00:00, 4925.14 examples/s]Tokenizing train dataset:  93%|█████████▎| 68768/73996 [
1: ples/s]Tokenizing train dataset:  93%|█████████▎| 68807/73996 [00:15<00:01, 4804.54 examples/s]Tokenizing train dataset:  93%|█████████▎| 68811/73996 [00:15<00:01, 4817.10 examples/s]Tokenizing train dataset:  93%|█████████▎| 68789/73996 [00:15<00:01, 4769.54 examples/s]Tokenizing train dataset:  94%|█████████▍| 69807/73996 [00:15<00:00, 4874.35 examples/s]Tokenizing train dataset:  94%|█████████▍| 69542/73996 [00:15<00:00, 4818.67 examples/s]Tokenizing train dataset:  94%|█████████▍| 69545/73996 [00:15<00:00, 4819.82 examples/s]Tokenizing train dataset:  94%|█████████▍| 69542/73996 [00:15<00:00, 4784.86 examples/s]Tokenizing train dataset:  95%|█████████▌| 70510/73996 [00:15<00:00, 4783.61 examples/s]Tokenizing train dataset:  95%|█████████▍| 70257/73996 [00:15<00:00, 4759.93 examples/s]Tokenizing train dataset:  95%|█
0: 00:15<00:01, 4783.49 examples/s]Tokenizing train dataset:  94%|█████████▍| 69540/73996 [00:15<00:00, 4855.67 examples/s]Tokenizing train dataset:  95%|█████████▌| 70519/73996 [00:15<00:00, 4841.46 examples/s]Tokenizing train dataset:  94%|█████████▎| 69270/73996 [00:15<00:01, 4722.14 examples/s]Tokenizing train dataset:  95%|█████████▍| 70266/73996 [00:15<00:00, 4825.12 examples/s]Tokenizing train dataset:  94%|█████████▍| 69798/73996 [00:15<00:00, 4878.08 examples/s]Tokenizing train dataset:  96%|█████████▋| 71262/73996 [00:15<00:00, 4798.35 examples/s]Tokenizing train dataset:  96%|█████████▌| 70779/73996 [00:15<00:00, 4897.74 examples/s]Tokenizing train dataset:  97%|█████████▋| 71799/73996 [00:15<00:00, 4928.25 examples/s]Tokenizing train dataset:  95%|█████████▌| 70513/73996 [00:15<00:00, 4782.55 examples/s]Tokenizing
1: ███████▍| 70256/73996 [00:15<00:00, 4754.13 examples/s]Tokenizing train dataset:  96%|█████████▌| 71000/73996 [00:15<00:00, 4651.18 examples/s]Tokenizing train dataset:  95%|█████████▍| 70259/73996 [00:15<00:00, 4714.98 examples/s]Tokenizing train dataset:  96%|█████████▌| 70764/73996 [00:15<00:00, 4831.27 examples/s]Tokenizing train dataset:  96%|█████████▌| 70770/73996 [00:15<00:00, 4842.17 examples/s]Tokenizing train dataset:  97%|█████████▋| 71536/73996 [00:15<00:00, 4825.32 examples/s]Tokenizing train dataset:  96%|█████████▌| 70768/73996 [00:15<00:00, 4799.71 examples/s]Tokenizing train dataset:  96%|█████████▋| 71261/73996 [00:15<00:00, 4719.05 examples/s]Tokenizing train dataset:  96%|█████████▋| 71262/73996 [00:15<00:00, 4703.81 examples/s]Tokenizing train dataset:  96%|█████████▋| 71261/73996 [00
1: :15<00:00, 4686.17 examples/s]Tokenizing train dataset:  97%|█████████▋| 72131/73996 [00:15<00:00, 4523.93 examples/s]Tokenizing train dataset:  97%|█████████▋| 71784/73996 [00:15<00:00, 4848.13 examples/s]Tokenizing train dataset:  97%|█████████▋| 71790/73996 [00:15<00:00, 4850.02 examples/s]Tokenizing train dataset:  97%|█████████▋| 71781/73996 [00:15<00:00, 4814.35 examples/s]Tokenizing train dataset:  98%|█████████▊| 72624/73996 [00:15<00:00, 4623.64 examples/s]Tokenizing train dataset:  98%|█████████▊| 72496/73996 [00:15<00:00, 4696.90 examples/s]Tokenizing train dataset:  98%|█████████▊| 72492/73996 [00:15<00:00, 4717.03 examples/s]Tokenizing train dataset:  98%|█████████▊| 72491/73996 [00:15<00:00, 4686.21 examples/s]Tokenizing train dataset:  99%|█████████▉| 73286/73996 [00:16<00:00, 4547.64 examples/s]Tokenizing t
0:  train dataset:  97%|█████████▋| 71540/73996 [00:15<00:00, 4846.45 examples/s]Tokenizing train dataset:  96%|█████████▌| 71000/73996 [00:15<00:00, 4659.11 examples/s]Tokenizing train dataset:  98%|█████████▊| 72501/73996 [00:15<00:00, 4804.42 examples/s]Tokenizing train dataset:  98%|█████████▊| 72249/73996 [00:15<00:00, 4730.32 examples/s]Tokenizing train dataset:  97%|█████████▋| 71521/73996 [00:15<00:00, 4804.82 examples/s]Tokenizing train dataset:  99%|█████████▊| 73000/73996 [00:15<00:00, 4683.74 examples/s]Tokenizing train dataset:  98%|█████████▊| 72758/73996 [00:15<00:00, 4810.85 examples/s]Tokenizing train dataset:  99%|█████████▉| 73505/73996 [00:15<00:00, 4772.59 examples/s]Tokenizing train dataset:  98%|█████████▊| 72243/73996 [00:15<00:00, 4677.74 examples/s]Tokenizing train dataset: 100%|███████
0: ██| 73996/73996 [00:16<00:00, 4649.01 examples/s]Tokenizing train dataset: 100%|██████████| 73996/73996 [00:16<00:00, 4598.61 examples/s]
0: Truncating train dataset:   0%|          | 0/73996 [00:00<?, ? examples/s]Tokenizing train dataset:  99%|█████████▉| 73420/73996 [00:16<00:00, 4676.64 examples/s]Tokenizing train dataset:  98%|█████████▊| 72729/73996 [00:16<00:00, 4722.21 examples/s]Truncating train dataset: 100%|██████████| 73996/73996 [00:00<00:00, 2217487.15 examples/s]
1: rain dataset:  99%|█████████▊| 73000/73996 [00:15<00:00, 4582.51 examples/s]Tokenizing train dataset:  99%|█████████▊| 72995/73996 [00:15<00:00, 4791.40 examples/s]Tokenizing train dataset:  99%|█████████▊| 72990/73996 [00:16<00:00, 4758.55 examples/s]Tokenizing train dataset: 100%|█████████▉| 73802/73996 [00:16<00:00, 4697.64 examples/s]Tokenizing train dataset:  99%|█████████▉| 73512/73996 [00:16<00:00, 4717.96 examples/s]Tokenizing train dataset: 100%|██████████| 73996/73996 [00:16<00:00, 4566.33 examples/s]
1: Truncating train dataset:   0%|          | 0/73996 [00:00<?, ? examples/s]Truncating train dataset: 100%|██████████| 73996/73996 [00:00<00:00, 2104218.58 examples/s]
0: Tokenizing train dataset: 100%|█████████▉| 73939/73996 [00:16<00:00, 4797.00 examples/s]Tokenizing train dataset: 100%|██████████| 73996/73996 [00:16<00:00, 4569.33 examples/s]
1: Tokenizing train dataset: 100%|█████████▉| 73665/73996 [00:16<00:00, 4673.39 examples/s]Tokenizing train dataset: 100%|█████████▉| 73661/73996 [00:16<00:00, 4657.90 examples/s]Tokenizing train dataset: 100%|██████████| 73996/73996 [00:16<00:00, 4556.56 examples/s]Tokenizing train dataset: 100%|██████████| 73996/73996 [00:16<00:00, 4584.16 examples/s]
0: Truncating train dataset:   0%|          | 0/73996 [00:00<?, ? examples/s]Tokenizing train dataset:  99%|█████████▉| 73384/73996 [00:16<00:00, 4594.85 examples/s]Truncating train dataset: 100%|██████████| 73996/73996 [00:00<00:00, 2175198.83 examples/s]
1: Truncating train dataset:   0%|          | 0/73996 [00:00<?, ? examples/s]Truncating train dataset: 100%|██████████| 73996/73996 [00:00<00:00, 2300526.42 examples/s]
1: Tokenizing train dataset: 100%|██████████| 73996/73996 [00:16<00:00, 4564.33 examples/s]
1: Truncating train dataset:   0%|          | 0/73996 [00:00<?, ? examples/s]Tokenizing train dataset: 100%|██████████| 73996/73996 [00:16<00:00, 4546.73 examples/s]
1: Truncating train dataset:   0%|          | 0/73996 [00:00<?, ? examples/s]Truncating train dataset: 100%|██████████| 73996/73996 [00:00<00:00, 1958871.99 examples/s]
1: Truncating train dataset: 100%|██████████| 73996/73996 [00:00<00:00, 2066611.97 examples/s]
0: Tokenizing train dataset: 100%|█████████▉| 73901/73996 [00:16<00:00, 4736.88 examples/s]Tokenizing train dataset: 100%|██████████| 73996/73996 [00:16<00:00, 4534.09 examples/s]
0: Truncating train dataset:   0%|          | 0/73996 [00:00<?, ? examples/s]Truncating train dataset: 100%|██████████| 73996/73996 [00:00<00:00, 2296356.15 examples/s]
0: Adding EOS to eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]Adding EOS to eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]Adding EOS to eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]The model is already on multiple devices. Skipping the move to device specified in `args`.
1: Adding EOS to eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]Adding EOS to eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]Adding EOS to eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]Adding EOS to eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]Adding EOS to eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 27956.44 examples/s]
1: Adding EOS to eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 27751.30 examples/s]
1: Adding EOS to eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 27243.35 examples/s]
1: Adding EOS to eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 26464.49 examples/s]
0: Adding EOS to eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 23417.74 examples/s]
0: Adding EOS to eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 22994.46 examples/s]
0: Adding EOS to eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 22625.20 examples/s]
0: Tokenizing eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]Tokenizing eval dataset:  47%|████▋     | 472/1000 [00:00<00:00, 4683.00 examples/s]Tokenizing eval dataset:  49%|████▉     | 488/1000 [00:00<00:00, 4839.23 examples/s]Tokenizing eval dataset:  48%|████▊     | 483/1000 [00:00<00:00, 4789.57 examples/s]Tokenizing eval dataset:  94%|█████████▍| 944/1000 [00:00<00:00, 4698.88 examples/s]Tokenizing eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 4337.81 examples/s]
0: Truncating eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]Truncating eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 576536.63 examples/s]
1: Tokenizing eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]Tokenizing eval dataset:  48%|████▊     | 479/1000 [00:00<00:00, 4755.37 examples/s]Tokenizing eval dataset:  48%|████▊     | 477/1000 [00:00<00:00, 4730.91 examples/s]Tokenizing eval dataset:  48%|████▊     | 483/1000 [00:00<00:00, 4794.28 examples/s]Tokenizing eval dataset:  46%|████▋     | 465/1000 [00:00<00:00, 4615.23 examples/s]Tokenizing eval dataset:  93%|█████████▎| 930/1000 [00:00<00:00, 4634.77 examples/s]Tokenizing eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 4297.45 examples/s]Tokenizing eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 4289.35 examples/s]Tokenizing eval dataset: 100%|█
1: ████████| 1000/1000 [00:00<00:00, 4317.45 examples/s]
1: Tokenizing eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 4317.87 examples/s]
1: Tokenizing eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 4326.98 examples/s]Truncating eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]Truncating eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]Tokenizing eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 4368.20 examples/s]
1: Truncating eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 526525.73 examples/s]
1: Truncating eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 535807.87 examples/s]
0: The model is already on multiple devices. Skipping the move to device specified in `args`.
1: Truncating eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]Truncating eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 444311.86 examples/s]
1: The model is already on multiple devices. Skipping the move to device specified in `args`.
1: The model is already on multiple devices. Skipping the move to device specified in `args`.
1: Tokenizing eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 4214.49 examples/s]
1: The model is already on multiple devices. Skipping the move to device specified in `args`.
1: Truncating eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]Truncating eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 506680.84 examples/s]
0: Tokenizing eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 4189.88 examples/s]Tokenizing eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 4249.89 examples/s]
1: The model is already on multiple devices. Skipping the move to device specified in `args`.
0: Truncating eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]Truncating eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 446392.51 examples/s]
0: Tokenizing eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 4160.07 examples/s]Tokenizing eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 4216.69 examples/s]
0: Truncating eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]Truncating eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 451340.15 examples/s]
0: The model is already on multiple devices. Skipping the move to device specified in `args`.
0: The model is already on multiple devices. Skipping the move to device specified in `args`.
0: 
0: --- Starting Baseline Evaluation (Pre-training) on Rank 0 ---
0: Evaluating on the FULL validation set (1000 samples)...
0: Inference:   0%|          | 0/125 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
0: Inference:   1%|          | 1/125 [00:01<02:36,  1.26s/it]Inference:   2%|▏         | 2/125 [00:01<01:53,  1.09it/s]Inference:   2%|▏         | 3/125 [00:02<01:33,  1.31it/s]Inference:   3%|▎         | 4/125 [00:03<01:23,  1.45it/s]Inference:   4%|▍         | 5/125 [00:03<01:17,  1.55it/s]Inference:   5%|▍         | 6/125 [00:04<01:13,  1.62it/s]Inference:   6%|▌         | 7/125 [00:04<01:11,  1.65it/s]Inference:   6%|▋         | 8/125 [00:05<01:10,  1.66it/s]Inference:   7%|▋         | 9/125 [00:05<01:08,  1.69it/s]Inference:   8%|▊         | 10/125 [00:06<01:01,  1.86it/s]Inference:   9%|▉         | 11/125 [00:07<01:06,  1.72it/s]Inference:  10%|▉         | 12/125 [00:07<01:06,  1.70it/s]Inference:  10%|█         | 13/125 [00:08<01:06,  1.68it/s]Inference:  11%|█         | 14/125 [00:08<01:04,  1.73it/s]Inference:  12%|█▏        | 15/125 [00:09<01:04,  1.70it/s]Inference:  13%|█▎        | 16/125 [00:10<01:05,  1.65it/s]Inference:  14%|█▎        | 17/125
0:  [00:10<01:04,  1.67it/s]Inference:  14%|█▍        | 18/125 [00:11<01:03,  1.69it/s]Inference:  15%|█▌        | 19/125 [00:11<01:05,  1.62it/s]Inference:  16%|█▌        | 20/125 [00:12<01:03,  1.65it/s]Inference:  17%|█▋        | 21/125 [00:13<01:00,  1.71it/s]Inference:  18%|█▊        | 22/125 [00:13<01:03,  1.62it/s]Inference:  18%|█▊        | 23/125 [00:14<01:01,  1.66it/s]Inference:  19%|█▉        | 24/125 [00:14<01:00,  1.67it/s]Inference:  20%|██        | 25/125 [00:15<01:01,  1.63it/s]Inference:  21%|██        | 26/125 [00:16<00:59,  1.66it/s]Inference:  22%|██▏       | 27/125 [00:16<00:58,  1.67it/s]Inference:  22%|██▏       | 28/125 [00:17<00:56,  1.72it/s]Inference:  23%|██▎       | 29/125 [00:17<00:59,  1.61it/s]Inference:  24%|██▍       | 30/125 [00:18<01:09,  1.36it/s]Inference:  25%|██▍       | 31/125 [00:19<01:05,  1.44it/s]Inference:  26%|██▌       | 32/125 [00:20<01:02,  1.49it/s]Inference:  26%|██▋ 
0:       | 33/125 [00:20<01:01,  1.50it/s]Inference:  27%|██▋       | 34/125 [00:21<00:57,  1.57it/s]Inference:  28%|██▊       | 35/125 [00:22<00:58,  1.54it/s]Inference:  29%|██▉       | 36/125 [00:22<00:54,  1.63it/s]Inference:  30%|██▉       | 37/125 [00:23<00:51,  1.69it/s]Inference:  30%|███       | 38/125 [00:23<00:54,  1.59it/s]Inference:  31%|███       | 39/125 [00:24<00:52,  1.63it/s]Inference:  32%|███▏      | 40/125 [00:25<00:51,  1.66it/s]Inference:  33%|███▎      | 41/125 [00:25<00:52,  1.59it/s]Inference:  34%|███▎      | 42/125 [00:26<00:52,  1.58it/s]Inference:  34%|███▍      | 43/125 [00:26<00:47,  1.72it/s]Inference:  35%|███▌      | 44/125 [00:27<00:48,  1.67it/s]Inference:  36%|███▌      | 45/125 [00:28<00:55,  1.45it/s]Inference:  37%|███▋      | 46/125 [00:28<00:52,  1.52it/s]Inference:  38%|███▊      | 47/125 [00:29<00:50,  1.55it/s]Inference:  38%|███▊      | 48/125 [
0: 00:30<00:47,  1.61it/s]Inference:  39%|███▉      | 49/125 [00:30<00:45,  1.66it/s]Inference:  40%|████      | 50/125 [00:31<00:58,  1.28it/s]Inference:  41%|████      | 51/125 [00:32<00:53,  1.39it/s]Inference:  42%|████▏     | 52/125 [00:33<00:51,  1.41it/s]Inference:  42%|████▏     | 53/125 [00:33<00:48,  1.50it/s]Inference:  43%|████▎     | 54/125 [00:34<00:46,  1.54it/s]Inference:  44%|████▍     | 55/125 [00:34<00:42,  1.64it/s]Inference:  45%|████▍     | 56/125 [00:35<00:41,  1.66it/s]Inference:  46%|████▌     | 57/125 [00:35<00:40,  1.68it/s]Inference:  46%|████▋     | 58/125 [00:36<00:40,  1.66it/s]Inference:  47%|████▋     | 59/125 [00:37<00:38,  1.72it/s]Inference:  48%|████▊     | 60/125 [00:37<00:37,  1.73it/s]Inference:  49%|████▉     | 61/125 [00:38<00:37,  1.70it/s]Inference:  50%|████▉     | 62/125 [00:38<00:37,  1.68it/s]Inference:  50%|███
0: █     | 63/125 [00:39<00:36,  1.69it/s]Inference:  51%|█████     | 64/125 [00:40<00:35,  1.71it/s]Inference:  52%|█████▏    | 65/125 [00:40<00:36,  1.64it/s]Inference:  53%|█████▎    | 66/125 [00:41<00:35,  1.66it/s]Inference:  54%|█████▎    | 67/125 [00:41<00:30,  1.89it/s]Inference:  54%|█████▍    | 68/125 [00:42<00:30,  1.88it/s]Inference:  55%|█████▌    | 69/125 [00:42<00:30,  1.83it/s]Inference:  56%|█████▌    | 70/125 [00:43<00:32,  1.69it/s]Inference:  57%|█████▋    | 71/125 [00:44<00:32,  1.64it/s]Inference:  58%|█████▊    | 72/125 [00:45<00:42,  1.26it/s]Inference:  58%|█████▊    | 73/125 [00:46<00:40,  1.30it/s]Inference:  59%|█████▉    | 74/125 [00:46<00:36,  1.40it/s]Inference:  60%|██████    | 75/125 [00:47<00:38,  1.31it/s]Inference:  61%|██████    | 76/125 [00:48<00:36,  1.34it/s]Inference:  62%|██████▏   | 77/1
0: 25 [00:48<00:33,  1.42it/s]Inference:  62%|██████▏   | 78/125 [00:49<00:31,  1.48it/s]Inference:  63%|██████▎   | 79/125 [00:50<00:30,  1.50it/s]Inference:  64%|██████▍   | 80/125 [00:50<00:28,  1.57it/s]Inference:  65%|██████▍   | 81/125 [00:51<00:27,  1.62it/s]Inference:  66%|██████▌   | 82/125 [00:52<00:34,  1.25it/s]Inference:  66%|██████▋   | 83/125 [00:53<00:31,  1.34it/s]Inference:  67%|██████▋   | 84/125 [00:53<00:28,  1.43it/s]Inference:  68%|██████▊   | 85/125 [00:54<00:27,  1.46it/s]Inference:  69%|██████▉   | 86/125 [00:54<00:25,  1.54it/s]Inference:  70%|██████▉   | 87/125 [00:55<00:23,  1.64it/s]Inference:  70%|███████   | 88/125 [00:56<00:25,  1.47it/s]Inference:  71%|███████   | 89/125 [00:56<00:23,  1.55it/s]Inference:  72%|███████▏  | 90/125 [00:57<00:23,  1.51it/s]Inference:  73%|█████
0: █▎  | 91/125 [00:58<00:21,  1.57it/s]Inference:  74%|███████▎  | 92/125 [00:58<00:21,  1.53it/s]Inference:  74%|███████▍  | 93/125 [00:59<00:19,  1.63it/s]Inference:  75%|███████▌  | 94/125 [00:59<00:18,  1.65it/s]Inference:  76%|███████▌  | 95/125 [01:00<00:18,  1.58it/s]Inference:  77%|███████▋  | 96/125 [01:01<00:17,  1.62it/s]Inference:  78%|███████▊  | 97/125 [01:01<00:17,  1.56it/s]Inference:  78%|███████▊  | 98/125 [01:02<00:16,  1.60it/s]Inference:  79%|███████▉  | 99/125 [01:03<00:16,  1.61it/s]Inference:  80%|████████  | 100/125 [01:03<00:14,  1.69it/s]Inference:  81%|████████  | 101/125 [01:04<00:14,  1.71it/s]Inference:  82%|████████▏ | 102/125 [01:04<00:13,  1.71it/s]Inference:  82%|████████▏ | 103/125 [01:05<00:13,  1.67it/s]Inference:  83%|████████▎ | 104/125 [01:06
0: <00:13,  1.55it/s]Inference:  84%|████████▍ | 105/125 [01:06<00:13,  1.52it/s]Inference:  85%|████████▍ | 106/125 [01:07<00:11,  1.69it/s]Inference:  86%|████████▌ | 107/125 [01:07<00:11,  1.63it/s]Inference:  86%|████████▋ | 108/125 [01:08<00:10,  1.60it/s]Inference:  87%|████████▋ | 109/125 [01:09<00:09,  1.63it/s]Inference:  88%|████████▊ | 110/125 [01:09<00:08,  1.71it/s]Inference:  89%|████████▉ | 111/125 [01:10<00:08,  1.73it/s]Inference:  90%|████████▉ | 112/125 [01:11<00:10,  1.28it/s]Inference:  90%|█████████ | 113/125 [01:12<00:09,  1.30it/s]Inference:  91%|█████████ | 114/125 [01:12<00:07,  1.41it/s]Inference:  92%|█████████▏| 115/125 [01:13<00:06,  1.49it/s]Inference:  93%|█████████▎| 116/125 [01:14<00:05,  1.53it/s]Inference:  94%|█████████▎| 117/1
0: 25 [01:14<00:05,  1.55it/s]Inference:  94%|█████████▍| 118/125 [01:15<00:04,  1.61it/s]Inference:  95%|█████████▌| 119/125 [01:15<00:03,  1.69it/s]Inference:  96%|█████████▌| 120/125 [01:16<00:02,  1.67it/s]Inference:  97%|█████████▋| 121/125 [01:16<00:02,  1.78it/s]Inference:  98%|█████████▊| 122/125 [01:17<00:01,  1.78it/s]Inference:  98%|█████████▊| 123/125 [01:17<00:01,  1.77it/s]Inference:  99%|█████████▉| 124/125 [01:18<00:00,  1.77it/s]Inference: 100%|██████████| 125/125 [01:19<00:00,  1.75it/s]Inference: 100%|██████████| 125/125 [01:19<00:00,  1.58it/s]
0: 
0: --- Baseline Evaluation Results ---
0: Overall Accuracy: 0.267
0: 
0: Classification Report:
0:               precision    recall  f1-score   support
0: 
0:     positive       0.49      0.52      0.50       277
0:     negative       0.54      0.36      0.43       266
0:      neutral       0.51      0.09      0.16       285
0:   irrelevant       0.00      0.00      0.00       172
0: 
0:    micro avg       0.51      0.27      0.35      1000
0:    macro avg       0.38      0.24      0.27      1000
0: weighted avg       0.42      0.27      0.30      1000
0: 
0: 
0: Confusion Matrix (Labels: Pos, Neg, Neu, Irr):
0: [[143  17   8   1]
0:  [ 11  97  10   0]
0:  [ 79  44  27   0]
0:  [ 60  23   8   0]]
0: --- Baseline Evaluation Finished ---
0: 
0: --- Starting Training on Twitter Dataset (12B Model) ---
0: The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 1, 'bos_token_id': 2, 'pad_token_id': 1}.
0: The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 1, 'bos_token_id': 2, 'pad_token_id': 1}.
0: The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 1, 'bos_token_id': 2, 'pad_token_id': 1}.
0: The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 1, 'bos_token_id': 2, 'pad_token_id': 1}.
1: The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 1, 'bos_token_id': 2, 'pad_token_id': 1}.
1: The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 1, 'bos_token_id': 2, 'pad_token_id': 1}.
1: The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 1, 'bos_token_id': 2, 'pad_token_id': 1}.
1: The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 1, 'bos_token_id': 2, 'pad_token_id': 1}.
0: {'loss': 3.8582, 'grad_norm': 3.538749933242798, 'learning_rate': 9.922212618841833e-06, 'entropy': 1.340372410416603, 'num_tokens': 57654.0, 'mean_token_accuracy': 0.5283902600407601, 'epoch': 0.01}
0:   0%|          | 0/1157 [00:00<?, ?it/s]  0%|          | 1/1157 [00:03<1:11:05,  3.69s/it]  0%|          | 2/1157 [00:06<1:00:50,  3.16s/it]  0%|          | 3/1157 [00:09<1:00:45,  3.16s/it]  0%|          | 4/1157 [00:12<57:54,  3.01s/it]    0%|          | 5/1157 [00:15<55:56,  2.91s/it]  1%|          | 6/1157 [00:18<57:51,  3.02s/it]  1%|          | 7/1157 [00:21<56:20,  2.94s/it]  1%|          | 8/1157 [00:23<55:10,  2.88s/it]  1%|          | 9/1157 [00:27<57:14,  2.99s/it]  1%|          | 10/1157 [00:29<55:49,  2.92s/it]                                                   1%|          | 10/1157 [00:29<55:49,  2.92s/it]  1%|          | 11/1157 [00:32<54:39,  2.86s/it]  1%|          | 12/1157 [00:35<56:52,  2.98s/it]  1%|          | 13/1157 [00:38<56:36,  2.97s/it]  1%|          | 14/1157 [00:41<55:41,  2.92s/it]  1%|▏         | 15/1157 [00:44<57:08,  3.00s/it]  1%|▏         | 16/1157 [00:47<57:00,  3.00s/it]  1%|▏         | 17/1157 [00:50<55:50,  2.94s/it]  2%|▏         | 18/1157
0: {'loss': 3.1418, 'grad_norm': 2.7444100379943848, 'learning_rate': 9.835782195332758e-06, 'entropy': 1.5387901276350022, 'num_tokens': 116331.0, 'mean_token_accuracy': 0.5493376523256301, 'epoch': 0.02}
0: {'loss': 2.4202, 'grad_norm': 3.697125196456909, 'learning_rate': 9.749351771823683e-06, 'entropy': 1.5709220319986343, 'num_tokens': 173519.0, 'mean_token_accuracy': 0.6283036604523659, 'epoch': 0.03}
0:  [00:53<58:04,  3.06s/it]  2%|▏         | 19/1157 [00:56<56:38,  2.99s/it]  2%|▏         | 20/1157 [00:59<55:18,  2.92s/it]                                                   2%|▏         | 20/1157 [00:59<55:18,  2.92s/it]  2%|▏         | 21/1157 [01:02<57:47,  3.05s/it]  2%|▏         | 22/1157 [01:05<56:06,  2.97s/it]  2%|▏         | 23/1157 [01:08<55:02,  2.91s/it]  2%|▏         | 24/1157 [01:11<57:41,  3.06s/it]  2%|▏         | 25/1157 [01:14<56:13,  2.98s/it]  2%|▏         | 26/1157 [01:17<54:53,  2.91s/it]  2%|▏         | 27/1157 [01:20<56:43,  3.01s/it]  2%|▏         | 28/1157 [01:23<55:28,  2.95s/it]  3%|▎         | 29/1157 [01:26<54:32,  2.90s/it]  3%|▎         | 30/1157 [01:29<56:31,  3.01s/it]                                                   3%|▎         | 30/1157 [01:29<56:31,  3.01s/it]  3%|▎         | 31/1157 [01:32<55:16,  2.95s/it]  3%|▎         | 32/1157 [01:35<54:13,  2.89s/it]  3%|▎         | 33/1157 [01:38<55:56,  2.99s/it]  3%|▎    
0: {'loss': 1.8922, 'grad_norm': 1.178661584854126, 'learning_rate': 9.662921348314608e-06, 'entropy': 1.251910036802292, 'num_tokens': 232072.0, 'mean_token_accuracy': 0.7052579969167709, 'epoch': 0.03}
0:      | 34/1157 [01:41<55:48,  2.98s/it]  3%|▎         | 35/1157 [01:44<54:50,  2.93s/it]  3%|▎         | 36/1157 [01:47<57:19,  3.07s/it]  3%|▎         | 37/1157 [01:50<55:40,  2.98s/it]  3%|▎         | 38/1157 [01:53<55:00,  2.95s/it]  3%|▎         | 39/1157 [01:56<57:39,  3.09s/it]  3%|▎         | 40/1157 [01:59<55:47,  3.00s/it]                                                   3%|▎         | 40/1157 [01:59<55:47,  3.00s/it]  4%|▎         | 41/1157 [02:02<54:28,  2.93s/it]  4%|▎         | 42/1157 [02:05<57:36,  3.10s/it]  4%|▎         | 43/1157 [02:08<55:58,  3.01s/it]  4%|▍         | 44/1157 [02:11<54:35,  2.94s/it]  4%|▍         | 45/1157 [02:14<57:51,  3.12s/it]  4%|▍         | 46/1157 [02:17<55:44,  3.01s/it]  4%|▍         | 47/1157 [02:20<54:32,  2.95s/it]  4%|▍         | 48/1157 [02:23<57:24,  3.11s/it]  4%|▍         | 49/1157 [02:26<55:36,  3.01s/it]  4%|▍         | 50/1157 [02:29<54:07,  2.93s/it]                                                 
0: {'loss': 1.6469, 'grad_norm': 0.6056000590324402, 'learning_rate': 9.576490924805532e-06, 'entropy': 1.118793497979641, 'num_tokens': 290235.0, 'mean_token_accuracy': 0.7506322279572487, 'epoch': 0.04}
0: {'loss': 1.5682, 'grad_norm': 0.8151083588600159, 'learning_rate': 9.490060501296458e-06, 'entropy': 1.1406948074698449, 'num_tokens': 347644.0, 'mean_token_accuracy': 0.7597763121128083, 'epoch': 0.05}
0:   4%|▍         | 50/1157 [02:29<54:07,  2.93s/it]  4%|▍         | 51/1157 [02:32<56:43,  3.08s/it]  4%|▍         | 52/1157 [02:35<54:49,  2.98s/it]  5%|▍         | 53/1157 [02:38<53:28,  2.91s/it]  5%|▍         | 54/1157 [02:41<55:53,  3.04s/it]  5%|▍         | 55/1157 [02:44<55:20,  3.01s/it]  5%|▍         | 56/1157 [02:47<54:01,  2.94s/it]  5%|▍         | 57/1157 [02:50<56:13,  3.07s/it]  5%|▌         | 58/1157 [02:53<54:34,  2.98s/it]  5%|▌         | 59/1157 [02:56<53:25,  2.92s/it]  5%|▌         | 60/1157 [02:59<56:35,  3.10s/it]                                                   5%|▌         | 60/1157 [02:59<56:35,  3.10s/it]  5%|▌         | 61/1157 [03:02<54:34,  2.99s/it]  5%|▌         | 62/1157 [03:05<53:12,  2.92s/it]  5%|▌         | 63/1157 [03:08<56:30,  3.10s/it]  6%|▌         | 64/1157 [03:11<54:48,  3.01s/it]  6%|▌         | 65/1157 [03:14<53:36,  2.95s/it]  6%|▌         | 66/1157 [03:17<56:59,  3.13s/it]  6%|▌         | 67/1157 [03:20<5
0: {'loss': 1.5539, 'grad_norm': 0.48973289132118225, 'learning_rate': 9.403630077787382e-06, 'entropy': 1.183540053665638, 'num_tokens': 405468.0, 'mean_token_accuracy': 0.7580419406294823, 'epoch': 0.06}
0: {'loss': 1.5183, 'grad_norm': 0.5287085771560669, 'learning_rate': 9.317199654278306e-06, 'entropy': 1.2018351182341576, 'num_tokens': 462647.0, 'mean_token_accuracy': 0.7624009907245636, 'epoch': 0.07}
0: 5:17,  3.04s/it]  6%|▌         | 68/1157 [03:23<53:50,  2.97s/it]  6%|▌         | 69/1157 [03:27<57:29,  3.17s/it]  6%|▌         | 70/1157 [03:29<55:24,  3.06s/it]                                                   6%|▌         | 70/1157 [03:29<55:24,  3.06s/it]  6%|▌         | 71/1157 [03:32<53:55,  2.98s/it]  6%|▌         | 72/1157 [03:36<58:16,  3.22s/it]  6%|▋         | 73/1157 [03:39<56:01,  3.10s/it]  6%|▋         | 74/1157 [03:42<53:58,  2.99s/it]  6%|▋         | 75/1157 [03:45<56:25,  3.13s/it]  7%|▋         | 76/1157 [03:48<55:28,  3.08s/it]  7%|▋         | 77/1157 [03:51<53:42,  2.98s/it]  7%|▋         | 78/1157 [03:54<56:02,  3.12s/it]  7%|▋         | 79/1157 [03:57<55:23,  3.08s/it]  7%|▋         | 80/1157 [04:00<53:42,  2.99s/it]                                                   7%|▋         | 80/1157 [04:00<53:42,  2.99s/it]  7%|▋         | 81/1157 [04:03<55:38,  3.10s/it]  7%|▋         | 82/1157 [04:06<54:56,  3.07s/it]  7%|▋         | 83
0: {'loss': 1.5487, 'grad_norm': 0.694656252861023, 'learning_rate': 9.230769230769232e-06, 'entropy': 1.287597519159317, 'num_tokens': 520879.0, 'mean_token_accuracy': 0.7526163786649704, 'epoch': 0.08}
0: /1157 [04:09<54:21,  3.04s/it]  7%|▋         | 84/1157 [04:13<56:14,  3.14s/it]  7%|▋         | 85/1157 [04:15<54:23,  3.04s/it]  7%|▋         | 86/1157 [04:18<53:54,  3.02s/it]  8%|▊         | 87/1157 [04:22<55:42,  3.12s/it]  8%|▊         | 88/1157 [04:25<54:00,  3.03s/it]  8%|▊         | 89/1157 [04:27<52:21,  2.94s/it]  8%|▊         | 90/1157 [04:31<54:29,  3.06s/it]                                                   8%|▊         | 90/1157 [04:31<54:29,  3.06s/it]  8%|▊         | 91/1157 [04:34<53:16,  3.00s/it]  8%|▊         | 92/1157 [04:36<52:10,  2.94s/it]  8%|▊         | 93/1157 [04:40<54:36,  3.08s/it]  8%|▊         | 94/1157 [04:43<53:09,  3.00s/it]  8%|▊         | 95/1157 [04:45<51:52,  2.93s/it]  8%|▊         | 96/1157 [04:49<54:33,  3.09s/it]  8%|▊         | 97/1157 [04:52<52:40,  2.98s/it]  8%|▊         | 98/1157 [04:54<51:41,  2.93s/it]  9%|▊         | 99/1157 [04:58<53:58,  3.06s/it]  9%|▊         | 100/1157 [05:00<52:23,  2.97s/it]     
0: {'loss': 1.4928, 'grad_norm': 0.6207109093666077, 'learning_rate': 9.144338807260157e-06, 'entropy': 1.277075210213661, 'num_tokens': 579035.0, 'mean_token_accuracy': 0.757582277059555, 'epoch': 0.09}
0: {'loss': 1.4621, 'grad_norm': 0.5504766702651978, 'learning_rate': 9.05790838375108e-06, 'entropy': 1.2684838205575943, 'num_tokens': 636713.0, 'mean_token_accuracy': 0.7640261277556419, 'epoch': 0.1}
0:                                                9%|▊         | 100/1157 [05:00<52:23,  2.97s/it]  9%|▊         | 101/1157 [05:03<52:10,  2.96s/it]  9%|▉         | 102/1157 [05:07<54:15,  3.09s/it]  9%|▉         | 103/1157 [05:10<52:30,  2.99s/it]  9%|▉         | 104/1157 [05:13<53:30,  3.05s/it]  9%|▉         | 105/1157 [05:16<55:20,  3.16s/it]  9%|▉         | 106/1157 [05:19<53:17,  3.04s/it]  9%|▉         | 107/1157 [05:22<53:00,  3.03s/it]  9%|▉         | 108/1157 [05:25<54:53,  3.14s/it]  9%|▉         | 109/1157 [05:28<52:55,  3.03s/it] 10%|▉         | 110/1157 [05:31<52:35,  3.01s/it]                                                   10%|▉         | 110/1157 [05:31<52:35,  3.01s/it] 10%|▉         | 111/1157 [05:35<55:34,  3.19s/it] 10%|▉         | 112/1157 [05:37<53:21,  3.06s/it] 10%|▉         | 113/1157 [05:40<53:03,  3.05s/it] 10%|▉         | 114/1157 [05:44<54:29,  3.13s/it] 10%|▉         | 115/1157 [05:47<52:40,  3.03s/it] 10%|█         | 116/1
0: {'loss': 1.4444, 'grad_norm': 0.600412130355835, 'learning_rate': 8.971477960242005e-06, 'entropy': 1.28255552649498, 'num_tokens': 693977.0, 'mean_token_accuracy': 0.7649086222052575, 'epoch': 0.1}
0: {'loss': 1.4515, 'grad_norm': 0.6050087213516235, 'learning_rate': 8.885047536732931e-06, 'entropy': 1.301843073964119, 'num_tokens': 751670.0, 'mean_token_accuracy': 0.7611205413937568, 'epoch': 0.11}
0: 157 [05:49<52:07,  3.00s/it] 10%|█         | 117/1157 [05:53<53:02,  3.06s/it] 10%|█         | 118/1157 [05:55<51:29,  2.97s/it] 10%|█         | 119/1157 [05:59<52:10,  3.02s/it] 10%|█         | 120/1157 [06:02<52:46,  3.05s/it]                                                   10%|█         | 120/1157 [06:02<52:46,  3.05s/it] 10%|█         | 121/1157 [06:04<51:02,  2.96s/it] 11%|█         | 122/1157 [06:07<50:51,  2.95s/it] 11%|█         | 123/1157 [06:10<51:42,  3.00s/it] 11%|█         | 124/1157 [06:13<50:15,  2.92s/it] 11%|█         | 125/1157 [06:16<51:26,  2.99s/it] 11%|█         | 126/1157 [06:20<52:07,  3.03s/it] 11%|█         | 127/1157 [06:22<50:41,  2.95s/it] 11%|█         | 128/1157 [06:25<52:00,  3.03s/it] 11%|█         | 129/1157 [06:29<52:31,  3.07s/it] 11%|█         | 130/1157 [06:31<50:54,  2.97s/it]                                                   11%|█         | 130/1157 [06:31<50:54,  2.97s/it] 11%|█▏        | 131/1157 [06:35<51:50,
0: {'loss': 1.4346, 'grad_norm': 0.7091216444969177, 'learning_rate': 8.798617113223855e-06, 'entropy': 1.3081878572702408, 'num_tokens': 809273.0, 'mean_token_accuracy': 0.7617551147937774, 'epoch': 0.12}
0:   3.03s/it] 11%|█▏        | 132/1157 [06:38<52:29,  3.07s/it] 11%|█▏        | 133/1157 [06:40<50:43,  2.97s/it] 12%|█▏        | 134/1157 [06:44<51:34,  3.03s/it] 12%|█▏        | 135/1157 [06:47<53:07,  3.12s/it] 12%|█▏        | 136/1157 [06:50<51:15,  3.01s/it] 12%|█▏        | 137/1157 [06:53<51:43,  3.04s/it] 12%|█▏        | 138/1157 [06:56<53:19,  3.14s/it] 12%|█▏        | 139/1157 [06:59<51:20,  3.03s/it] 12%|█▏        | 140/1157 [07:02<51:59,  3.07s/it]                                                   12%|█▏        | 140/1157 [07:02<51:59,  3.07s/it] 12%|█▏        | 141/1157 [07:05<52:14,  3.09s/it] 12%|█▏        | 142/1157 [07:08<50:30,  2.99s/it] 12%|█▏        | 143/1157 [07:11<51:32,  3.05s/it] 12%|█▏        | 144/1157 [07:14<52:05,  3.09s/it] 13%|█▎        | 145/1157 [07:17<50:24,  2.99s/it] 13%|█▎        | 146/1157 [07:20<51:23,  3.05s/it] 13%|█▎        | 147/1157 [07:24<52:25,  3.11s/it] 13%|█▎        | 148/
0: {'loss': 1.3936, 'grad_norm': 0.8369367122650146, 'learning_rate': 8.71218668971478e-06, 'entropy': 1.2983392372727394, 'num_tokens': 866349.0, 'mean_token_accuracy': 0.7662611916661263, 'epoch': 0.13}
0: {'loss': 1.4063, 'grad_norm': 1.027862787246704, 'learning_rate': 8.625756266205705e-06, 'entropy': 1.416552597284317, 'num_tokens': 924222.0, 'mean_token_accuracy': 0.7642576098442078, 'epoch': 0.14}
0: 1157 [07:26<50:52,  3.03s/it] 13%|█▎        | 149/1157 [07:30<51:38,  3.07s/it] 13%|█▎        | 150/1157 [07:33<52:16,  3.11s/it]                                                   13%|█▎        | 150/1157 [07:33<52:16,  3.11s/it] 13%|█▎        | 151/1157 [07:36<50:24,  3.01s/it] 13%|█▎        | 152/1157 [07:39<52:04,  3.11s/it] 13%|█▎        | 153/1157 [07:42<52:09,  3.12s/it] 13%|█▎        | 154/1157 [07:45<50:28,  3.02s/it] 13%|█▎        | 155/1157 [07:48<52:20,  3.13s/it] 13%|█▎        | 156/1157 [07:51<52:23,  3.14s/it] 14%|█▎        | 157/1157 [07:54<50:58,  3.06s/it] 14%|█▎        | 158/1157 [07:58<52:48,  3.17s/it] 14%|█▎        | 159/1157 [08:01<51:49,  3.12s/it] 14%|█▍        | 160/1157 [08:03<50:13,  3.02s/it]                                                   14%|█▍        | 160/1157 [08:03<50:13,  3.02s/it] 14%|█▍        | 161/1157 [08:07<51:47,  3.12s/it] 14%|█▍        | 162/1157 [08:10<50:52,  3.07s/it] 14%|█
0: {'loss': 1.3808, 'grad_norm': 0.9545660614967346, 'learning_rate': 8.53932584269663e-06, 'entropy': 1.3978675067424775, 'num_tokens': 982666.0, 'mean_token_accuracy': 0.7600775912404061, 'epoch': 0.15}
0:         | 163/1157 [08:13<49:18,  2.98s/it] 14%|█▍        | 164/1157 [08:16<51:15,  3.10s/it] 14%|█▍        | 165/1157 [08:19<51:23,  3.11s/it] 14%|█▍        | 166/1157 [08:22<49:49,  3.02s/it] 14%|█▍        | 167/1157 [08:25<51:33,  3.12s/it] 15%|█▍        | 168/1157 [08:28<50:39,  3.07s/it] 15%|█▍        | 169/1157 [08:31<48:56,  2.97s/it] 15%|█▍        | 170/1157 [08:34<50:33,  3.07s/it]                                                   15%|█▍        | 170/1157 [08:34<50:33,  3.07s/it] 15%|█▍        | 171/1157 [08:37<51:00,  3.10s/it] 15%|█▍        | 172/1157 [08:40<49:28,  3.01s/it] 15%|█▍        | 173/1157 [08:44<50:50,  3.10s/it] 15%|█▌        | 174/1157 [08:47<50:22,  3.08s/it] 15%|█▌        | 175/1157 [08:49<48:49,  2.98s/it] 15%|█▌        | 176/1157 [08:53<50:31,  3.09s/it] 15%|█▌        | 177/1157 [08:56<49:55,  3.06s/it] 15%|█▌        | 178/1157 [08:58<48:23,  2.97s/it] 15%|█▌        | 179/1157 [09:02<50:58,  3.
0: {'loss': 1.3264, 'grad_norm': 0.6657541990280151, 'learning_rate': 8.452895419187554e-06, 'entropy': 1.3842025369405746, 'num_tokens': 1040407.0, 'mean_token_accuracy': 0.7735023245215416, 'epoch': 0.16}
0: {'loss': 1.2805, 'grad_norm': 0.49227413535118103, 'learning_rate': 8.36646499567848e-06, 'entropy': 1.3447657823562622, 'num_tokens': 1098167.0, 'mean_token_accuracy': 0.7766313597559928, 'epoch': 0.16}
0: 13s/it] 16%|█▌        | 180/1157 [09:05<50:10,  3.08s/it]                                                   16%|█▌        | 180/1157 [09:05<50:10,  3.08s/it] 16%|█▌        | 181/1157 [09:08<48:26,  2.98s/it] 16%|█▌        | 182/1157 [09:11<49:59,  3.08s/it] 16%|█▌        | 183/1157 [09:14<49:10,  3.03s/it] 16%|█▌        | 184/1157 [09:17<47:45,  2.95s/it] 16%|█▌        | 185/1157 [09:20<49:48,  3.07s/it] 16%|█▌        | 186/1157 [09:23<49:23,  3.05s/it] 16%|█▌        | 187/1157 [09:26<47:54,  2.96s/it] 16%|█▌        | 188/1157 [09:29<49:48,  3.08s/it] 16%|█▋        | 189/1157 [09:32<49:09,  3.05s/it] 16%|█▋        | 190/1157 [09:35<47:31,  2.95s/it]                                                   16%|█▋        | 190/1157 [09:35<47:31,  2.95s/it] 17%|█▋        | 191/1157 [09:38<50:30,  3.14s/it] 17%|█▋        | 192/1157 [09:41<49:29,  3.08s/it] 17%|█▋        | 193/1157 [09:44<47:50,  2.98s/it] 17%|█▋        | 194/1157 [0
0: {'loss': 1.2233, 'grad_norm': 0.5098627209663391, 'learning_rate': 8.280034572169404e-06, 'entropy': 1.2577385634183884, 'num_tokens': 1155092.0, 'mean_token_accuracy': 0.7834437340497971, 'epoch': 0.17}
0: 9:48<50:56,  3.17s/it] 17%|█▋        | 195/1157 [09:51<49:48,  3.11s/it] 17%|█▋        | 196/1157 [09:53<48:31,  3.03s/it] 17%|█▋        | 197/1157 [09:57<51:46,  3.24s/it] 17%|█▋        | 198/1157 [10:00<50:35,  3.17s/it] 17%|█▋        | 199/1157 [10:03<49:32,  3.10s/it] 17%|█▋        | 200/1157 [10:06<50:49,  3.19s/it]                                                   17%|█▋        | 200/1157 [10:07<50:49,  3.19s/it] 17%|█▋        | 201/1157 [10:09<49:40,  3.12s/it] 17%|█▋        | 202/1157 [10:12<48:59,  3.08s/it] 18%|█▊        | 203/1157 [10:16<50:23,  3.17s/it] 18%|█▊        | 204/1157 [10:19<49:23,  3.11s/it] 18%|█▊        | 205/1157 [10:22<47:48,  3.01s/it] 18%|█▊        | 206/1157 [10:25<50:32,  3.19s/it] 18%|█▊        | 207/1157 [10:28<49:20,  3.12s/it] 18%|█▊        | 208/1157 [10:31<47:40,  3.01s/it] 18%|█▊        | 209/1157 [10:34<50:14,  3.18s/it] 18%|█▊        | 210/1157 [10:37<49:15,  3.12s/it]              
0: {'loss': 1.2299, 'grad_norm': 0.5050461888313293, 'learning_rate': 8.193604148660328e-06, 'entropy': 1.216880349814892, 'num_tokens': 1212346.0, 'mean_token_accuracy': 0.782032173871994, 'epoch': 0.18}
0: {'loss': 1.2629, 'grad_norm': 0.42084819078445435, 'learning_rate': 8.107173725151254e-06, 'entropy': 1.2471643790602684, 'num_tokens': 1269877.0, 'mean_token_accuracy': 0.7771531462669372, 'epoch': 0.19}
0:                                      18%|█▊        | 210/1157 [10:37<49:15,  3.12s/it] 18%|█▊        | 211/1157 [10:40<47:48,  3.03s/it] 18%|█▊        | 212/1157 [10:44<50:01,  3.18s/it] 18%|█▊        | 213/1157 [10:47<48:57,  3.11s/it] 18%|█▊        | 214/1157 [10:50<48:16,  3.07s/it] 19%|█▊        | 215/1157 [10:53<49:44,  3.17s/it] 19%|█▊        | 216/1157 [10:56<49:06,  3.13s/it] 19%|█▉        | 217/1157 [10:59<48:09,  3.07s/it] 19%|█▉        | 218/1157 [11:03<50:25,  3.22s/it] 19%|█▉        | 219/1157 [11:05<48:03,  3.07s/it] 19%|█▉        | 220/1157 [11:08<47:31,  3.04s/it]                                                   19%|█▉        | 220/1157 [11:08<47:31,  3.04s/it] 19%|█▉        | 221/1157 [11:12<49:49,  3.19s/it] 19%|█▉        | 222/1157 [11:15<47:47,  3.07s/it] 19%|█▉        | 223/1157 [11:18<47:01,  3.02s/it] 19%|█▉        | 224/1157 [11:21<48:30,  3.12s/it] 19%|█▉        | 225/1157 [11:24<47:49,  3.08s/it]
0: {'loss': 1.2537, 'grad_norm': 0.4644128680229187, 'learning_rate': 8.020743301642178e-06, 'entropy': 1.2524877071380616, 'num_tokens': 1327559.0, 'mean_token_accuracy': 0.7780734539031983, 'epoch': 0.2}
0: {'loss': 1.2585, 'grad_norm': 0.4267500936985016, 'learning_rate': 7.934312878133104e-06, 'entropy': 1.259573782980442, 'num_tokens': 1385463.0, 'mean_token_accuracy': 0.7720842629671096, 'epoch': 0.21}
0:  20%|█▉        | 226/1157 [11:27<46:22,  2.99s/it] 20%|█▉        | 227/1157 [11:30<48:09,  3.11s/it] 20%|█▉        | 228/1157 [11:33<47:26,  3.06s/it] 20%|█▉        | 229/1157 [11:36<46:56,  3.04s/it] 20%|█▉        | 230/1157 [11:39<48:25,  3.13s/it]                                                   20%|█▉        | 230/1157 [11:39<48:25,  3.13s/it] 20%|█▉        | 231/1157 [11:42<47:33,  3.08s/it] 20%|██        | 232/1157 [11:45<46:56,  3.05s/it] 20%|██        | 233/1157 [11:49<49:09,  3.19s/it] 20%|██        | 234/1157 [11:52<47:09,  3.07s/it] 20%|██        | 235/1157 [11:55<46:40,  3.04s/it] 20%|██        | 236/1157 [11:58<49:07,  3.20s/it] 20%|██        | 237/1157 [12:01<47:02,  3.07s/it] 21%|██        | 238/1157 [12:04<46:25,  3.03s/it] 21%|██        | 239/1157 [12:07<47:58,  3.14s/it] 21%|██        | 240/1157 [12:10<46:10,  3.02s/it]                                                   21%|██        | 240/1157 [12:10<46
0: {'loss': 1.2935, 'grad_norm': 0.5177574157714844, 'learning_rate': 7.847882454624029e-06, 'entropy': 1.2816718131303788, 'num_tokens': 1443702.0, 'mean_token_accuracy': 0.770802067220211, 'epoch': 0.22}
0: :10,  3.02s/it] 21%|██        | 241/1157 [12:13<45:49,  3.00s/it] 21%|██        | 242/1157 [12:17<48:14,  3.16s/it] 21%|██        | 243/1157 [12:19<46:29,  3.05s/it] 21%|██        | 244/1157 [12:22<46:08,  3.03s/it] 21%|██        | 245/1157 [12:26<48:43,  3.21s/it] 21%|██▏       | 246/1157 [12:29<47:16,  3.11s/it] 21%|██▏       | 247/1157 [12:32<46:25,  3.06s/it] 21%|██▏       | 248/1157 [12:35<48:48,  3.22s/it] 22%|██▏       | 249/1157 [12:38<46:33,  3.08s/it] 22%|██▏       | 250/1157 [12:41<45:51,  3.03s/it]                                                   22%|██▏       | 250/1157 [12:41<45:51,  3.03s/it] 22%|██▏       | 251/1157 [12:45<48:07,  3.19s/it] 22%|██▏       | 252/1157 [12:47<46:07,  3.06s/it] 22%|██▏       | 253/1157 [12:50<46:17,  3.07s/it] 22%|██▏       | 254/1157 [12:54<48:22,  3.21s/it] 22%|██▏       | 255/1157 [12:57<46:05,  3.07s/it] 22%|██▏       | 256/1157 [13:00<45:18,  3.02s/i
0: {'loss': 1.2991, 'grad_norm': 0.4587044417858124, 'learning_rate': 7.761452031114953e-06, 'entropy': 1.2967593744397163, 'num_tokens': 1502509.0, 'mean_token_accuracy': 0.7723699390888215, 'epoch': 0.22}
0: {'loss': 1.2799, 'grad_norm': 0.5343644618988037, 'learning_rate': 7.675021607605879e-06, 'entropy': 1.2661889731884002, 'num_tokens': 1560306.0, 'mean_token_accuracy': 0.775344817340374, 'epoch': 0.23}
0: t] 22%|██▏       | 257/1157 [13:03<45:54,  3.06s/it] 22%|██▏       | 258/1157 [13:05<44:18,  2.96s/it] 22%|██▏       | 259/1157 [13:09<44:54,  3.00s/it] 22%|██▏       | 260/1157 [13:12<47:10,  3.16s/it]                                                   22%|██▏       | 260/1157 [13:12<47:10,  3.16s/it] 23%|██▎       | 261/1157 [13:15<45:16,  3.03s/it] 23%|██▎       | 262/1157 [13:18<44:43,  3.00s/it] 23%|██▎       | 263/1157 [13:21<47:03,  3.16s/it] 23%|██▎       | 264/1157 [13:24<45:11,  3.04s/it] 23%|██▎       | 265/1157 [13:27<44:36,  3.00s/it] 23%|██▎       | 266/1157 [13:30<45:09,  3.04s/it] 23%|██▎       | 267/1157 [13:33<43:47,  2.95s/it] 23%|██▎       | 268/1157 [13:36<44:36,  3.01s/it] 23%|██▎       | 269/1157 [13:39<45:53,  3.10s/it] 23%|██▎       | 270/1157 [13:42<44:07,  2.98s/it]                                                   23%|██▎       | 270/1157 [13:42<44:07,  2.98s/it] 23%|
0: {'loss': 1.2599, 'grad_norm': 0.43884775042533875, 'learning_rate': 7.588591184096803e-06, 'entropy': 1.2679277643561364, 'num_tokens': 1618539.0, 'mean_token_accuracy': 0.7777374163269997, 'epoch': 0.24}
0: ██▎       | 271/1157 [13:45<44:47,  3.03s/it] 24%|██▎       | 272/1157 [13:48<45:27,  3.08s/it] 24%|██▎       | 273/1157 [13:51<44:00,  2.99s/it] 24%|██▎       | 274/1157 [13:54<44:44,  3.04s/it] 24%|██▍       | 275/1157 [13:58<46:01,  3.13s/it] 24%|██▍       | 276/1157 [14:00<44:13,  3.01s/it] 24%|██▍       | 277/1157 [14:03<44:42,  3.05s/it] 24%|██▍       | 278/1157 [14:07<46:51,  3.20s/it] 24%|██▍       | 279/1157 [14:10<44:55,  3.07s/it] 24%|██▍       | 280/1157 [14:13<44:24,  3.04s/it]                                                   24%|██▍       | 280/1157 [14:13<44:24,  3.04s/it] 24%|██▍       | 281/1157 [14:16<46:31,  3.19s/it] 24%|██▍       | 282/1157 [14:19<44:34,  3.06s/it] 24%|██▍       | 283/1157 [14:22<44:49,  3.08s/it] 25%|██▍       | 284/1157 [14:26<46:03,  3.17s/it] 25%|██▍       | 285/1157 [14:28<44:06,  3.04s/it] 25%|██▍       | 286/1157 [14:31<44:28,  3.06s/it] 25%|█
0: {'loss': 1.2655, 'grad_norm': 0.5283185243606567, 'learning_rate': 7.502160760587728e-06, 'entropy': 1.2408617988228798, 'num_tokens': 1676229.0, 'mean_token_accuracy': 0.7775886595249176, 'epoch': 0.25}
0: {'loss': 1.2393, 'grad_norm': 0.49688881635665894, 'learning_rate': 7.415730337078652e-06, 'entropy': 1.2380984619259834, 'num_tokens': 1733791.0, 'mean_token_accuracy': 0.7794038787484169, 'epoch': 0.26}
0: █▍       | 287/1157 [14:35<45:46,  3.16s/it] 25%|██▍       | 288/1157 [14:38<43:58,  3.04s/it] 25%|██▍       | 289/1157 [14:41<44:16,  3.06s/it] 25%|██▌       | 290/1157 [14:44<46:15,  3.20s/it]                                                   25%|██▌       | 290/1157 [14:44<46:15,  3.20s/it] 25%|██▌       | 291/1157 [14:47<44:12,  3.06s/it] 25%|██▌       | 292/1157 [14:50<45:16,  3.14s/it] 25%|██▌       | 293/1157 [14:53<45:26,  3.16s/it] 25%|██▌       | 294/1157 [14:56<43:41,  3.04s/it] 25%|██▌       | 295/1157 [14:59<44:04,  3.07s/it] 26%|██▌       | 296/1157 [15:02<44:27,  3.10s/it] 26%|██▌       | 297/1157 [15:05<42:53,  2.99s/it] 26%|██▌       | 298/1157 [15:08<42:45,  2.99s/it] 26%|██▌       | 299/1157 [15:12<44:12,  3.09s/it] 26%|██▌       | 300/1157 [15:14<42:36,  2.98s/it]                                                   26%|██▌       | 300/1157 [15:14<42:36,  2.98s/it] 26%|██▌  
0: {'loss': 1.303, 'grad_norm': 0.5673211812973022, 'learning_rate': 7.3292999135695774e-06, 'entropy': 1.2933331817388534, 'num_tokens': 1793057.0, 'mean_token_accuracy': 0.7667166262865066, 'epoch': 0.27}
0:      | 301/1157 [15:17<42:27,  2.98s/it] 26%|██▌       | 302/1157 [15:21<44:19,  3.11s/it] 26%|██▌       | 303/1157 [15:23<42:48,  3.01s/it] 26%|██▋       | 304/1157 [15:26<42:43,  3.01s/it] 26%|██▋       | 305/1157 [15:30<44:12,  3.11s/it] 26%|██▋       | 306/1157 [15:33<42:39,  3.01s/it] 27%|██▋       | 307/1157 [15:35<42:18,  2.99s/it] 27%|██▋       | 308/1157 [15:39<43:45,  3.09s/it] 27%|██▋       | 309/1157 [15:42<42:11,  2.99s/it] 27%|██▋       | 310/1157 [15:44<41:53,  2.97s/it]                                                   27%|██▋       | 310/1157 [15:45<41:53,  2.97s/it] 27%|██▋       | 311/1157 [15:48<44:17,  3.14s/it] 27%|██▋       | 312/1157 [15:51<42:44,  3.03s/it] 27%|██▋       | 313/1157 [15:54<44:05,  3.13s/it] 27%|██▋       | 314/1157 [15:57<43:59,  3.13s/it] 27%|██▋       | 315/1157 [16:00<42:15,  3.01s/it] 27%|██▋       | 316/1157 [16:03<43:20,  3.09s/it] 27%|██▋     
0: {'loss': 1.2809, 'grad_norm': 0.5642127394676208, 'learning_rate': 7.2428694900605025e-06, 'entropy': 1.2779295712709426, 'num_tokens': 1851283.0, 'mean_token_accuracy': 0.7717993870377541, 'epoch': 0.28}
0: {'loss': 1.2604, 'grad_norm': 0.472786009311676, 'learning_rate': 7.156439066551427e-06, 'entropy': 1.250912782549858, 'num_tokens': 1909320.0, 'mean_token_accuracy': 0.77512167096138, 'epoch': 0.29}
0:   | 317/1157 [16:07<44:12,  3.16s/it] 27%|██▋       | 318/1157 [16:09<42:23,  3.03s/it] 28%|██▊       | 319/1157 [16:13<43:26,  3.11s/it] 28%|██▊       | 320/1157 [16:16<44:13,  3.17s/it]                                                   28%|██▊       | 320/1157 [16:16<44:13,  3.17s/it] 28%|██▊       | 321/1157 [16:19<42:22,  3.04s/it] 28%|██▊       | 322/1157 [16:22<43:29,  3.12s/it] 28%|██▊       | 323/1157 [16:25<43:32,  3.13s/it] 28%|██▊       | 324/1157 [16:28<41:55,  3.02s/it] 28%|██▊       | 325/1157 [16:31<43:11,  3.11s/it] 28%|██▊       | 326/1157 [16:35<44:01,  3.18s/it] 28%|██▊       | 327/1157 [16:37<42:10,  3.05s/it] 28%|██▊       | 328/1157 [16:41<43:12,  3.13s/it] 28%|██▊       | 329/1157 [16:44<43:18,  3.14s/it] 29%|██▊       | 330/1157 [16:47<41:33,  3.02s/it]                                                   29%|██▊       | 330/1157 [16:47<41:33,  3.02s/it] 29%|██▊       | 331/
0: {'loss': 1.2184, 'grad_norm': 0.51128751039505, 'learning_rate': 7.070008643042352e-06, 'entropy': 1.2297891452908516, 'num_tokens': 1967193.0, 'mean_token_accuracy': 0.7821431711316109, 'epoch': 0.29}
0: 1157 [16:50<42:50,  3.11s/it] 29%|██▊       | 332/1157 [16:53<43:06,  3.14s/it] 29%|██▉       | 333/1157 [16:56<41:43,  3.04s/it] 29%|██▉       | 334/1157 [16:59<42:01,  3.06s/it] 29%|██▉       | 335/1157 [17:02<42:19,  3.09s/it] 29%|██▉       | 336/1157 [17:05<40:52,  2.99s/it] 29%|██▉       | 337/1157 [17:08<42:15,  3.09s/it] 29%|██▉       | 338/1157 [17:11<42:19,  3.10s/it] 29%|██▉       | 339/1157 [17:14<40:46,  2.99s/it] 29%|██▉       | 340/1157 [17:17<42:08,  3.09s/it]                                                   29%|██▉       | 340/1157 [17:17<42:08,  3.09s/it] 29%|██▉       | 341/1157 [17:21<42:38,  3.14s/it] 30%|██▉       | 342/1157 [17:23<41:15,  3.04s/it] 30%|██▉       | 343/1157 [17:27<43:03,  3.17s/it] 30%|██▉       | 344/1157 [17:30<42:44,  3.15s/it] 30%|██▉       | 345/1157 [17:33<40:54,  3.02s/it] 30%|██▉       | 346/1157 [17:36<41:58,  3.11s/it] 30%|██▉       | 347/115
0: {'loss': 1.2962, 'grad_norm': 0.5009310245513916, 'learning_rate': 6.983578219533276e-06, 'entropy': 1.2757289350032806, 'num_tokens': 2025774.0, 'mean_token_accuracy': 0.7688824668526649, 'epoch': 0.3}
0: {'loss': 1.2143, 'grad_norm': 0.48749426007270813, 'learning_rate': 6.8971477960242e-06, 'entropy': 1.2104886144399643, 'num_tokens': 2083365.0, 'mean_token_accuracy': 0.7799344018101693, 'epoch': 0.31}
0: 7 [17:39<41:22,  3.06s/it] 30%|███       | 348/1157 [17:42<40:01,  2.97s/it] 30%|███       | 349/1157 [17:45<40:34,  3.01s/it] 30%|███       | 350/1157 [17:48<41:00,  3.05s/it]                                                   30%|███       | 350/1157 [17:48<41:00,  3.05s/it] 30%|███       | 351/1157 [17:51<40:24,  3.01s/it] 30%|███       | 352/1157 [17:54<41:39,  3.10s/it] 31%|███       | 353/1157 [17:57<41:34,  3.10s/it] 31%|███       | 354/1157 [18:00<40:46,  3.05s/it] 31%|███       | 355/1157 [18:04<41:43,  3.12s/it] 31%|███       | 356/1157 [18:07<40:58,  3.07s/it] 31%|███       | 357/1157 [18:09<39:35,  2.97s/it] 31%|███       | 358/1157 [18:13<41:48,  3.14s/it] 31%|███       | 359/1157 [18:16<41:27,  3.12s/it] 31%|███       | 360/1157 [18:19<39:41,  2.99s/it]                                                   31%|███       | 360/1157 [18:19<39:41,  2.99s/it] 31%|███       | 361/1157 [18:22
0: {'loss': 1.2478, 'grad_norm': 0.4849601089954376, 'learning_rate': 6.810717372515125e-06, 'entropy': 1.2465615272521973, 'num_tokens': 2141767.0, 'mean_token_accuracy': 0.7759457275271415, 'epoch': 0.32}
0: <41:50,  3.15s/it] 31%|███▏      | 362/1157 [18:25<41:02,  3.10s/it] 31%|███▏      | 363/1157 [18:28<39:18,  2.97s/it] 31%|███▏      | 364/1157 [18:31<41:30,  3.14s/it] 32%|███▏      | 365/1157 [18:34<40:47,  3.09s/it] 32%|███▏      | 366/1157 [18:37<39:31,  3.00s/it] 32%|███▏      | 367/1157 [18:41<41:37,  3.16s/it] 32%|███▏      | 368/1157 [18:44<40:46,  3.10s/it] 32%|███▏      | 369/1157 [18:47<40:05,  3.05s/it] 32%|███▏      | 370/1157 [18:50<41:01,  3.13s/it]                                                   32%|███▏      | 370/1157 [18:50<41:01,  3.13s/it] 32%|███▏      | 371/1157 [18:53<40:27,  3.09s/it] 32%|███▏      | 372/1157 [18:56<40:03,  3.06s/it] 32%|███▏      | 373/1157 [18:59<40:59,  3.14s/it] 32%|███▏      | 374/1157 [19:02<40:10,  3.08s/it] 32%|███▏      | 375/1157 [19:05<38:42,  2.97s/it] 32%|███▏      | 376/1157 [19:08<40:02,  3.08s/it] 33%|█
0: {'loss': 1.2767, 'grad_norm': 0.4675261676311493, 'learning_rate': 6.7242869490060505e-06, 'entropy': 1.2582803085446357, 'num_tokens': 2200061.0, 'mean_token_accuracy': 0.7766390085220337, 'epoch': 0.33}
0: {'loss': 1.2367, 'grad_norm': 0.5257816314697266, 'learning_rate': 6.637856525496975e-06, 'entropy': 1.238394170999527, 'num_tokens': 2257505.0, 'mean_token_accuracy': 0.7802263215184212, 'epoch': 0.34}
0: █▎      | 377/1157 [19:11<39:39,  3.05s/it] 33%|███▎      | 378/1157 [19:14<38:20,  2.95s/it] 33%|███▎      | 379/1157 [19:17<39:49,  3.07s/it] 33%|███▎      | 380/1157 [19:20<39:18,  3.04s/it]                                                   33%|███▎      | 380/1157 [19:20<39:18,  3.04s/it] 33%|███▎      | 381/1157 [19:23<38:11,  2.95s/it] 33%|███▎      | 382/1157 [19:26<40:21,  3.13s/it] 33%|███▎      | 383/1157 [19:29<39:25,  3.06s/it] 33%|███▎      | 384/1157 [19:32<37:59,  2.95s/it] 33%|███▎      | 385/1157 [19:35<40:01,  3.11s/it] 33%|███▎      | 386/1157 [19:38<39:13,  3.05s/it] 33%|███▎      | 387/1157 [19:41<38:00,  2.96s/it] 34%|███▎      | 388/1157 [19:45<39:28,  3.08s/it] 34%|███▎      | 389/1157 [19:48<39:07,  3.06s/it] 34%|███▎      | 390/1157 [19:50<38:38,  3.02s/it]                                                   34%|███▎      | 390/1157 [19:50<38:
0: {'loss': 1.2442, 'grad_norm': 0.4613913893699646, 'learning_rate': 6.5514261019879e-06, 'entropy': 1.2299561023712158, 'num_tokens': 2315220.0, 'mean_token_accuracy': 0.7784706443548203, 'epoch': 0.35}
0: 38,  3.02s/it] 34%|███▍      | 391/1157 [19:54<39:55,  3.13s/it] 34%|███▍      | 392/1157 [19:57<39:11,  3.07s/it] 34%|███▍      | 393/1157 [20:00<38:37,  3.03s/it] 34%|███▍      | 394/1157 [20:03<39:38,  3.12s/it] 34%|███▍      | 395/1157 [20:06<38:51,  3.06s/it] 34%|███▍      | 396/1157 [20:09<37:38,  2.97s/it] 34%|███▍      | 397/1157 [20:12<38:57,  3.08s/it] 34%|███▍      | 398/1157 [20:15<38:17,  3.03s/it] 34%|███▍      | 399/1157 [20:18<37:51,  3.00s/it] 35%|███▍      | 400/1157 [20:21<39:05,  3.10s/it]                                                   35%|███▍      | 400/1157 [20:21<39:05,  3.10s/it] 35%|███▍      | 401/1157 [20:24<37:51,  3.01s/it] 35%|███▍      | 402/1157 [20:27<36:43,  2.92s/it] 35%|███▍      | 403/1157 [20:30<38:22,  3.05s/it] 35%|███▍      | 404/1157 [20:33<37:03,  2.95s/it] 35%|███▌      | 405/1157 [20:36<36:53,  2.94s/it] 35%|██
0: {'loss': 1.2561, 'grad_norm': 0.5290850400924683, 'learning_rate': 6.464995678478825e-06, 'entropy': 1.2584412723779679, 'num_tokens': 2373757.0, 'mean_token_accuracy': 0.7739092037081718, 'epoch': 0.35}
0: ▌      | 406/1157 [20:39<38:30,  3.08s/it] 35%|███▌      | 407/1157 [20:42<37:54,  3.03s/it] 35%|███▌      | 408/1157 [20:45<37:32,  3.01s/it] 35%|███▌      | 409/1157 [20:48<38:08,  3.06s/it] 35%|███▌      | 410/1157 [20:51<37:37,  3.02s/it]                                                   35%|███▌      | 410/1157 [20:51<37:37,  3.02s/it] 36%|███▌      | 411/1157 [20:54<37:32,  3.02s/it] 36%|███▌      | 412/1157 [20:57<38:13,  3.08s/it] 36%|███▌      | 413/1157 [21:00<37:39,  3.04s/it] 36%|███▌      | 414/1157 [21:03<37:15,  3.01s/it] 36%|███▌      | 415/1157 [21:06<37:54,  3.07s/it] 36%|███▌      | 416/1157 [21:09<37:18,  3.02s/it] 36%|███▌      | 417/1157 [21:13<37:49,  3.07s/it] 36%|███▌      | 418/1157 [21:16<38:42,  3.14s/it] 36%|███▌      | 419/1157 [21:19<37:10,  3.02s/it] 36%|███▋      | 420/1157 [21:21<36:46,  2.99s/it]                                         
0: {'loss': 1.2614, 'grad_norm': 0.5209531188011169, 'learning_rate': 6.37856525496975e-06, 'entropy': 1.2559787303209304, 'num_tokens': 2432105.0, 'mean_token_accuracy': 0.7723089009523392, 'epoch': 0.36}
0: {'loss': 1.2454, 'grad_norm': 0.532615065574646, 'learning_rate': 6.292134831460674e-06, 'entropy': 1.2395145267248153, 'num_tokens': 2490481.0, 'mean_token_accuracy': 0.7758390367031097, 'epoch': 0.37}
0:           36%|███▋      | 420/1157 [21:22<36:46,  2.99s/it] 36%|███▋      | 421/1157 [21:25<38:58,  3.18s/it] 36%|███▋      | 422/1157 [21:28<37:24,  3.05s/it] 37%|███▋      | 423/1157 [21:31<36:52,  3.01s/it] 37%|███▋      | 424/1157 [21:34<37:54,  3.10s/it] 37%|███▋      | 425/1157 [21:37<36:28,  2.99s/it] 37%|███▋      | 426/1157 [21:40<36:53,  3.03s/it] 37%|███▋      | 427/1157 [21:43<37:25,  3.08s/it] 37%|███▋      | 428/1157 [21:46<36:08,  2.97s/it] 37%|███▋      | 429/1157 [21:49<36:42,  3.03s/it] 37%|███▋      | 430/1157 [21:52<37:05,  3.06s/it]                                                   37%|███▋      | 430/1157 [21:52<37:05,  3.06s/it] 37%|███▋      | 431/1157 [21:55<36:45,  3.04s/it] 37%|███▋      | 432/1157 [21:58<37:04,  3.07s/it] 37%|███▋      | 433/1157 [22:02<38:06,  3.16s/it] 38%|███▊      | 434/1157 [22:04<36:28,  3.03s/it] 38%|███▊
0: {'loss': 1.2459, 'grad_norm': 0.5441044569015503, 'learning_rate': 6.205704407951599e-06, 'entropy': 1.2308130428194999, 'num_tokens': 2548409.0, 'mean_token_accuracy': 0.7747642055153847, 'epoch': 0.38}
0:       | 435/1157 [22:07<36:47,  3.06s/it] 38%|███▊      | 436/1157 [22:11<37:46,  3.14s/it] 38%|███▊      | 437/1157 [22:14<36:19,  3.03s/it] 38%|███▊      | 438/1157 [22:17<36:34,  3.05s/it] 38%|███▊      | 439/1157 [22:20<37:35,  3.14s/it] 38%|███▊      | 440/1157 [22:23<36:10,  3.03s/it]                                                   38%|███▊      | 440/1157 [22:23<36:10,  3.03s/it] 38%|███▊      | 441/1157 [22:26<35:57,  3.01s/it] 38%|███▊      | 442/1157 [22:29<36:23,  3.05s/it] 38%|███▊      | 443/1157 [22:32<35:14,  2.96s/it] 38%|███▊      | 444/1157 [22:35<35:13,  2.96s/it] 38%|███▊      | 445/1157 [22:38<36:25,  3.07s/it] 39%|███▊      | 446/1157 [22:41<35:22,  2.98s/it] 39%|███▊      | 447/1157 [22:44<35:07,  2.97s/it] 39%|███▊      | 448/1157 [22:47<36:11,  3.06s/it] 39%|███▉      | 449/1157 [22:50<35:00,  2.97s/it] 39%|███▉      | 450/1157 [22:53<35:3
0: {'loss': 1.2556, 'grad_norm': 0.529537558555603, 'learning_rate': 6.119273984442524e-06, 'entropy': 1.2585561543703079, 'num_tokens': 2606783.0, 'mean_token_accuracy': 0.7746622711420059, 'epoch': 0.39}
0: {'loss': 1.2403, 'grad_norm': 0.540943443775177, 'learning_rate': 6.032843560933449e-06, 'entropy': 1.217828106880188, 'num_tokens': 2664366.0, 'mean_token_accuracy': 0.7783621251583099, 'epoch': 0.4}
0: 4,  3.02s/it]                                                   39%|███▉      | 450/1157 [22:53<35:34,  3.02s/it] 39%|███▉      | 451/1157 [22:56<37:17,  3.17s/it] 39%|███▉      | 452/1157 [22:59<36:05,  3.07s/it] 39%|███▉      | 453/1157 [23:02<36:16,  3.09s/it] 39%|███▉      | 454/1157 [23:05<36:16,  3.10s/it] 39%|███▉      | 455/1157 [23:08<34:55,  2.99s/it] 39%|███▉      | 456/1157 [23:11<35:19,  3.02s/it] 39%|███▉      | 457/1157 [23:15<36:30,  3.13s/it] 40%|███▉      | 458/1157 [23:17<35:07,  3.02s/it] 40%|███▉      | 459/1157 [23:20<34:48,  2.99s/it] 40%|███▉      | 460/1157 [23:24<36:08,  3.11s/it]                                                   40%|███▉      | 460/1157 [23:24<36:08,  3.11s/it] 40%|███▉      | 461/1157 [23:27<35:00,  3.02s/it] 40%|███▉      | 462/1157 [23:30<34:46,  3.00s/it] 40%|████      | 463/1157 [23:33<35:53,  3.10s/it] 40%|████    
0: {'loss': 1.2328, 'grad_norm': 0.6356871128082275, 'learning_rate': 5.946413137424374e-06, 'entropy': 1.2225349977612496, 'num_tokens': 2721977.0, 'mean_token_accuracy': 0.7796936854720116, 'epoch': 0.41}
0:   | 464/1157 [23:36<34:41,  3.00s/it] 40%|████      | 465/1157 [23:39<35:04,  3.04s/it] 40%|████      | 466/1157 [23:42<36:05,  3.13s/it] 40%|████      | 467/1157 [23:45<34:36,  3.01s/it] 40%|████      | 468/1157 [23:48<34:14,  2.98s/it] 41%|████      | 469/1157 [23:51<36:07,  3.15s/it] 41%|████      | 470/1157 [23:54<34:44,  3.03s/it]                                                   41%|████      | 470/1157 [23:54<34:44,  3.03s/it] 41%|████      | 471/1157 [23:57<35:06,  3.07s/it] 41%|████      | 472/1157 [24:01<35:57,  3.15s/it] 41%|████      | 473/1157 [24:03<34:28,  3.02s/it] 41%|████      | 474/1157 [24:06<34:12,  3.00s/it] 41%|████      | 475/1157 [24:10<35:16,  3.10s/it] 41%|████      | 476/1157 [24:12<33:58,  2.99s/it] 41%|████      | 477/1157 [24:15<34:21,  3.03s/it] 41%|████▏     | 478/1157 [24:19<34:42,  3.07s/it] 41%|████▏     | 479/1157 [24:21<33:2
0: {'loss': 1.2558, 'grad_norm': 0.5301116108894348, 'learning_rate': 5.859982713915299e-06, 'entropy': 1.2614181637763977, 'num_tokens': 2779903.0, 'mean_token_accuracy': 0.7747218921780586, 'epoch': 0.42}
0: {'loss': 1.2599, 'grad_norm': 0.5328614711761475, 'learning_rate': 5.773552290406224e-06, 'entropy': 1.254530268907547, 'num_tokens': 2838377.0, 'mean_token_accuracy': 0.7740677505731582, 'epoch': 0.42}
0: 4,  2.96s/it] 41%|████▏     | 480/1157 [24:24<33:54,  3.01s/it]                                                   41%|████▏     | 480/1157 [24:24<33:54,  3.01s/it] 42%|████▏     | 481/1157 [24:28<34:32,  3.07s/it] 42%|████▏     | 482/1157 [24:30<33:32,  2.98s/it] 42%|████▏     | 483/1157 [24:34<34:29,  3.07s/it] 42%|████▏     | 484/1157 [24:37<34:32,  3.08s/it] 42%|████▏     | 485/1157 [24:40<33:22,  2.98s/it] 42%|████▏     | 486/1157 [24:43<34:23,  3.07s/it] 42%|████▏     | 487/1157 [24:46<35:04,  3.14s/it] 42%|████▏     | 488/1157 [24:49<33:45,  3.03s/it] 42%|████▏     | 489/1157 [24:52<34:01,  3.06s/it] 42%|████▏     | 490/1157 [24:55<34:20,  3.09s/it]                                                   42%|████▏     | 490/1157 [24:55<34:20,  3.09s/it] 42%|████▏     | 491/1157 [24:58<33:04,  2.98s/it] 43%|████▎     | 492/1157 [25:01<33:59,  3
0: {'loss': 1.2987, 'grad_norm': 0.5555831789970398, 'learning_rate': 5.687121866897148e-06, 'entropy': 1.2772684454917909, 'num_tokens': 2897585.0, 'mean_token_accuracy': 0.766374634206295, 'epoch': 0.43}
0: .07s/it] 43%|████▎     | 493/1157 [25:04<34:00,  3.07s/it] 43%|████▎     | 494/1157 [25:07<32:48,  2.97s/it] 43%|████▎     | 495/1157 [25:10<33:45,  3.06s/it] 43%|████▎     | 496/1157 [25:13<33:52,  3.08s/it] 43%|████▎     | 497/1157 [25:16<32:36,  2.97s/it] 43%|████▎     | 498/1157 [25:19<33:45,  3.07s/it] 43%|████▎     | 499/1157 [25:23<33:50,  3.09s/it] 43%|████▎     | 500/1157 [25:25<32:49,  3.00s/it]                                                   43%|████▎     | 500/1157 [25:25<32:49,  3.00s/it] 43%|████▎     | 501/1157 [25:29<34:17,  3.14s/it] 43%|████▎     | 502/1157 [25:32<34:17,  3.14s/it] 43%|████▎     | 503/1157 [25:35<32:50,  3.01s/it] 44%|████▎     | 504/1157 [25:38<33:40,  3.09s/it] 44%|████▎     | 505/1157 [25:41<34:12,  3.15s/it] 44%|████▎     | 506/1157 [25:44<32:54,  3.03s/it] 44%|████▍     | 507/1157 [25:47<33:05
0: {'loss': 1.2188, 'grad_norm': 0.5103283524513245, 'learning_rate': 5.600691443388073e-06, 'entropy': 1.2191687136888505, 'num_tokens': 2955019.0, 'mean_token_accuracy': 0.7816592827439308, 'epoch': 0.44}
0: {'loss': 1.2852, 'grad_norm': 0.5554929971694946, 'learning_rate': 5.514261019878998e-06, 'entropy': 1.2783787935972213, 'num_tokens': 3013667.0, 'mean_token_accuracy': 0.7714379981160164, 'epoch': 0.45}
0: ,  3.05s/it] 44%|████▍     | 508/1157 [25:50<33:08,  3.06s/it] 44%|████▍     | 509/1157 [25:53<32:03,  2.97s/it] 44%|████▍     | 510/1157 [25:56<33:10,  3.08s/it]                                                   44%|████▍     | 510/1157 [25:56<33:10,  3.08s/it] 44%|████▍     | 511/1157 [26:00<33:52,  3.15s/it] 44%|████▍     | 512/1157 [26:02<32:25,  3.02s/it] 44%|████▍     | 513/1157 [26:05<32:48,  3.06s/it] 44%|████▍     | 514/1157 [26:09<33:01,  3.08s/it] 45%|████▍     | 515/1157 [26:11<31:46,  2.97s/it] 45%|████▍     | 516/1157 [26:15<32:55,  3.08s/it] 45%|████▍     | 517/1157 [26:18<33:07,  3.11s/it] 45%|████▍     | 518/1157 [26:20<31:53,  2.99s/it] 45%|████▍     | 519/1157 [26:24<33:02,  3.11s/it] 45%|████▍     | 520/1157 [26:27<32:25,  3.05s/it]                                                   45%|████▍     | 520/1157 [26:27<32:25,  3.
0: {'loss': 1.2023, 'grad_norm': 0.6233788728713989, 'learning_rate': 5.4278305963699225e-06, 'entropy': 1.190868392586708, 'num_tokens': 3070734.0, 'mean_token_accuracy': 0.7833366394042969, 'epoch': 0.46}
0: 05s/it] 45%|████▌     | 521/1157 [26:29<31:18,  2.95s/it] 45%|████▌     | 522/1157 [26:33<32:31,  3.07s/it] 45%|████▌     | 523/1157 [26:36<32:00,  3.03s/it] 45%|████▌     | 524/1157 [26:39<31:39,  3.00s/it] 45%|████▌     | 525/1157 [26:42<32:03,  3.04s/it] 45%|████▌     | 526/1157 [26:45<31:37,  3.01s/it] 46%|████▌     | 527/1157 [26:48<30:44,  2.93s/it] 46%|████▌     | 528/1157 [26:51<32:08,  3.07s/it] 46%|████▌     | 529/1157 [26:54<32:35,  3.11s/it] 46%|████▌     | 530/1157 [26:57<32:12,  3.08s/it]                                                   46%|████▌     | 530/1157 [26:57<32:12,  3.08s/it] 46%|████▌     | 531/1157 [27:00<32:56,  3.16s/it] 46%|████▌     | 532/1157 [27:03<32:11,  3.09s/it] 46%|████▌     | 533/1157 [27:06<31:41,  3.05s/it] 46%|████▌     | 534/1157 [27:10<32:24,  3.12s/it] 46%|████▌     | 535/1157 [27:13<31:54,
0: {'loss': 1.2403, 'grad_norm': 0.5927339196205139, 'learning_rate': 5.341400172860848e-06, 'entropy': 1.2448272913694383, 'num_tokens': 3129261.0, 'mean_token_accuracy': 0.7756788998842239, 'epoch': 0.47}
0:   3.08s/it] 46%|████▋     | 536/1157 [27:16<31:28,  3.04s/it] 46%|████▋     | 537/1157 [27:19<32:13,  3.12s/it] 46%|████▋     | 538/1157 [27:22<31:40,  3.07s/it] 47%|████▋     | 539/1157 [27:25<31:27,  3.05s/it] 47%|████▋     | 540/1157 [27:28<32:12,  3.13s/it]                                                   47%|████▋     | 540/1157 [27:28<32:12,  3.13s/it] 47%|████▋     | 541/1157 [27:31<31:30,  3.07s/it] 47%|████▋     | 542/1157 [27:34<31:10,  3.04s/it] 47%|████▋     | 543/1157 [27:38<32:35,  3.18s/it] 47%|████▋     | 544/1157 [27:40<31:43,  3.11s/it] 47%|████▋     | 545/1157 [27:43<31:12,  3.06s/it] 47%|████▋     | 546/1157 [27:47<32:25,  3.18s/it] 47%|████▋     | 547/1157 [27:50<32:10,  3.17s/it] 47%|████▋     | 548/1157 [27:53<31:36,  3.11s/it] 47%|████▋     | 549/1157 [27:56<32:15,  3.18s/it] 48%|████▊     | 550/1157 [28:00<31
0: {'loss': 1.2325, 'grad_norm': 0.5442695021629333, 'learning_rate': 5.254969749351773e-06, 'entropy': 1.2279221698641778, 'num_tokens': 3187159.0, 'mean_token_accuracy': 0.7778116077184677, 'epoch': 0.48}
0: {'loss': 1.2192, 'grad_norm': 0.545945405960083, 'learning_rate': 5.168539325842698e-06, 'entropy': 1.2061251640319823, 'num_tokens': 3244932.0, 'mean_token_accuracy': 0.7824768245220184, 'epoch': 0.48}
0: :59,  3.16s/it]                                                   48%|████▊     | 550/1157 [28:00<31:59,  3.16s/it] 48%|████▊     | 551/1157 [28:02<31:18,  3.10s/it] 48%|████▊     | 552/1157 [28:06<31:50,  3.16s/it] 48%|████▊     | 553/1157 [28:09<31:37,  3.14s/it] 48%|████▊     | 554/1157 [28:12<30:59,  3.08s/it] 48%|████▊     | 555/1157 [28:15<31:42,  3.16s/it] 48%|████▊     | 556/1157 [28:18<31:34,  3.15s/it] 48%|████▊     | 557/1157 [28:21<30:59,  3.10s/it] 48%|████▊     | 558/1157 [28:25<31:41,  3.17s/it] 48%|████▊     | 559/1157 [28:28<31:24,  3.15s/it] 48%|████▊     | 560/1157 [28:31<30:44,  3.09s/it]                                                   48%|████▊     | 560/1157 [28:31<30:44,  3.09s/it] 48%|████▊     | 561/1157 [28:34<30:51,  3.11s/it] 49%|████▊     | 562/1157 [28:37<30:50,  3.11s/it] 49%|████▊     | 563/1157 [28:40<30:20, 
0: {'loss': 1.2066, 'grad_norm': 0.555301308631897, 'learning_rate': 5.082108902333622e-06, 'entropy': 1.2008391082286836, 'num_tokens': 3302649.0, 'mean_token_accuracy': 0.7806542679667473, 'epoch': 0.49}
0:  3.07s/it] 49%|████▊     | 564/1157 [28:43<31:01,  3.14s/it] 49%|████▉     | 565/1157 [28:46<30:52,  3.13s/it] 49%|████▉     | 566/1157 [28:49<30:24,  3.09s/it] 49%|████▉     | 567/1157 [28:53<31:19,  3.18s/it] 49%|████▉     | 568/1157 [28:56<31:14,  3.18s/it] 49%|████▉     | 569/1157 [28:59<30:36,  3.12s/it] 49%|████▉     | 570/1157 [29:02<31:19,  3.20s/it]                                                   49%|████▉     | 570/1157 [29:02<31:19,  3.20s/it] 49%|████▉     | 571/1157 [29:05<31:12,  3.20s/it] 49%|████▉     | 572/1157 [29:08<30:30,  3.13s/it] 50%|████▉     | 573/1157 [29:12<31:04,  3.19s/it] 50%|████▉     | 574/1157 [29:15<30:48,  3.17s/it] 50%|████▉     | 575/1157 [29:18<30:14,  3.12s/it] 50%|████▉     | 576/1157 [29:21<30:51,  3.19s/it] 50%|████▉     | 577/1157 [29:24<30:45,  3.18s/it] 50%|████▉     | 578/1157 [29:27<30:
0: {'loss': 1.2537, 'grad_norm': 0.5453048944473267, 'learning_rate': 4.995678478824546e-06, 'entropy': 1.2335465505719185, 'num_tokens': 3361373.0, 'mean_token_accuracy': 0.7752545818686485, 'epoch': 0.5}
0: {'loss': 1.2352, 'grad_norm': 0.5899986028671265, 'learning_rate': 4.909248055315471e-06, 'entropy': 1.2277364403009414, 'num_tokens': 3419699.0, 'mean_token_accuracy': 0.7768565326929092, 'epoch': 0.51}
0: 07,  3.12s/it] 50%|█████     | 579/1157 [29:31<30:43,  3.19s/it] 50%|█████     | 580/1157 [29:34<30:32,  3.18s/it]                                                   50%|█████     | 580/1157 [29:34<30:32,  3.18s/it] 50%|█████     | 581/1157 [29:37<29:55,  3.12s/it] 50%|█████     | 582/1157 [29:40<31:02,  3.24s/it] 50%|█████     | 583/1157 [29:43<30:43,  3.21s/it] 50%|█████     | 584/1157 [29:47<30:27,  3.19s/it] 51%|█████     | 585/1157 [29:50<30:50,  3.23s/it] 51%|█████     | 586/1157 [29:53<30:45,  3.23s/it] 51%|█████     | 587/1157 [29:56<30:25,  3.20s/it] 51%|█████     | 588/1157 [30:00<31:12,  3.29s/it] 51%|█████     | 589/1157 [30:03<30:17,  3.20s/it] 51%|█████     | 590/1157 [30:06<29:40,  3.14s/it]                                                   51%|█████     | 590/1157 [30:06<29:40,  3.14s/it] 51%|█████     | 591/1157 [30:09<30:46,  
0: {'loss': 1.234, 'grad_norm': 0.554710865020752, 'learning_rate': 4.8228176318063965e-06, 'entropy': 1.2367228060960769, 'num_tokens': 3477744.0, 'mean_token_accuracy': 0.7764167368412018, 'epoch': 0.52}
0: 3.26s/it] 51%|█████     | 592/1157 [30:12<29:43,  3.16s/it] 51%|█████▏    | 593/1157 [30:15<29:38,  3.15s/it] 51%|█████▏    | 594/1157 [30:19<30:00,  3.20s/it] 51%|█████▏    | 595/1157 [30:22<29:23,  3.14s/it] 52%|█████▏    | 596/1157 [30:25<29:23,  3.14s/it] 52%|█████▏    | 597/1157 [30:28<29:59,  3.21s/it] 52%|█████▏    | 598/1157 [30:31<29:13,  3.14s/it] 52%|█████▏    | 599/1157 [30:34<28:37,  3.08s/it] 52%|█████▏    | 600/1157 [30:38<29:26,  3.17s/it]                                                   52%|█████▏    | 600/1157 [30:38<29:26,  3.17s/it] 52%|█████▏    | 601/1157 [30:41<29:23,  3.17s/it] 52%|█████▏    | 602/1157 [30:44<29:17,  3.17s/it] 52%|█████▏    | 603/1157 [30:47<29:43,  3.22s/it] 52%|█████▏    | 604/1157 [30:50<29:29,  3.20s/it] 52%|█████▏    | 605/1157 [30:53<28:56,  3.15s/it] 52%|████
0: {'loss': 1.2231, 'grad_norm': 0.6087484359741211, 'learning_rate': 4.7363872082973215e-06, 'entropy': 1.2191183596849442, 'num_tokens': 3536349.0, 'mean_token_accuracy': 0.779345241189003, 'epoch': 0.53}
0: ▏    | 606/1157 [30:57<29:52,  3.25s/it] 52%|█████▏    | 607/1157 [31:00<28:56,  3.16s/it] 53%|█████▎    | 608/1157 [31:03<28:26,  3.11s/it] 53%|█████▎    | 609/1157 [31:06<29:31,  3.23s/it] 53%|█████▎    | 610/1157 [31:09<28:40,  3.14s/it]                                                   53%|█████▎    | 610/1157 [31:09<28:40,  3.14s/it] 53%|█████▎    | 611/1157 [31:12<28:36,  3.14s/it] 53%|█████▎    | 612/1157 [31:16<29:30,  3.25s/it] 53%|█████▎    | 613/1157 [31:19<28:45,  3.17s/it] 53%|█████▎    | 614/1157 [31:22<28:39,  3.17s/it] 53%|█████▎    | 615/1157 [31:25<29:05,  3.22s/it] 53%|█████▎    | 616/1157 [31:28<28:26,  3.15s/it] 53%|█████▎    | 617/1157 [31:32<28:26,  3.16s/it] 53%|█████▎    | 618/1157 [31:35<28:45,  3.20s/it] 54%|█████▎    | 619/1157 [31:38<28:04,  3.13s/it] 54%|█████▎    | 620/1157 [31:41<2
0: {'loss': 1.2296, 'grad_norm': 0.5230302810668945, 'learning_rate': 4.649956784788246e-06, 'entropy': 1.22158342897892, 'num_tokens': 3595091.0, 'mean_token_accuracy': 0.7757170915603637, 'epoch': 0.54}
0: {'loss': 1.2505, 'grad_norm': 0.5831193923950195, 'learning_rate': 4.563526361279171e-06, 'entropy': 1.2215544939041139, 'num_tokens': 3653359.0, 'mean_token_accuracy': 0.7763343319296837, 'epoch': 0.54}
0: 8:38,  3.20s/it]                                                   54%|█████▎    | 620/1157 [31:41<28:38,  3.20s/it] 54%|█████▎    | 621/1157 [31:45<29:00,  3.25s/it] 54%|█████▍    | 622/1157 [31:48<28:13,  3.17s/it] 54%|█████▍    | 623/1157 [31:51<28:09,  3.16s/it] 54%|█████▍    | 624/1157 [31:54<29:09,  3.28s/it] 54%|█████▍    | 625/1157 [31:57<28:15,  3.19s/it] 54%|█████▍    | 626/1157 [32:00<28:04,  3.17s/it] 54%|█████▍    | 627/1157 [32:04<28:28,  3.22s/it] 54%|█████▍    | 628/1157 [32:07<27:43,  3.14s/it] 54%|█████▍    | 629/1157 [32:10<27:43,  3.15s/it] 54%|█████▍    | 630/1157 [32:13<28:18,  3.22s/it]                                                   54%|█████▍    | 630/1157 [32:13<28:18,  3.22s/it] 55%|█████▍    | 631/1157 [32:16<27:29,  3.14s/it] 55%|█████▍    | 632/1157 [32:19<27:29,  3.14s/it] 55%|█████
0: {'loss': 1.1995, 'grad_norm': 0.6418198943138123, 'learning_rate': 4.477095937770096e-06, 'entropy': 1.193996761739254, 'num_tokens': 3710784.0, 'mean_token_accuracy': 0.7845800161361695, 'epoch': 0.55}
0:     | 633/1157 [32:23<27:59,  3.21s/it] 55%|█████▍    | 634/1157 [32:25<26:49,  3.08s/it] 55%|█████▍    | 635/1157 [32:29<26:56,  3.10s/it] 55%|█████▍    | 636/1157 [32:32<26:56,  3.10s/it] 55%|█████▌    | 637/1157 [32:35<26:29,  3.06s/it] 55%|█████▌    | 638/1157 [32:38<27:05,  3.13s/it] 55%|█████▌    | 639/1157 [32:41<26:59,  3.13s/it] 55%|█████▌    | 640/1157 [32:44<26:30,  3.08s/it]                                                   55%|█████▌    | 640/1157 [32:44<26:30,  3.08s/it] 55%|█████▌    | 641/1157 [32:47<26:43,  3.11s/it] 55%|█████▌    | 642/1157 [32:50<26:43,  3.11s/it] 56%|█████▌    | 643/1157 [32:53<26:14,  3.06s/it] 56%|█████▌    | 644/1157 [32:56<26:22,  3.08s/it] 56%|█████▌    | 645/1157 [33:00<26:55,  3.16s/it] 56%|█████▌    | 646/1157 [33:03<26:15,  3.08s/it] 56%|█████▌    | 647/1157 [33:06<26:
0: {'loss': 1.2439, 'grad_norm': 0.5579596757888794, 'learning_rate': 4.39066551426102e-06, 'entropy': 1.2222268104553222, 'num_tokens': 3769409.0, 'mean_token_accuracy': 0.7762530997395516, 'epoch': 0.56}
0: {'loss': 1.2423, 'grad_norm': 0.559019148349762, 'learning_rate': 4.3042350907519444e-06, 'entropy': 1.2342982336878776, 'num_tokens': 3827342.0, 'mean_token_accuracy': 0.7762497454881668, 'epoch': 0.57}
0: 19,  3.10s/it] 56%|█████▌    | 648/1157 [33:09<26:46,  3.16s/it] 56%|█████▌    | 649/1157 [33:12<26:05,  3.08s/it] 56%|█████▌    | 650/1157 [33:15<26:10,  3.10s/it]                                                   56%|█████▌    | 650/1157 [33:15<26:10,  3.10s/it] 56%|█████▋    | 651/1157 [33:18<26:38,  3.16s/it] 56%|█████▋    | 652/1157 [33:21<25:59,  3.09s/it] 56%|█████▋    | 653/1157 [33:25<26:10,  3.12s/it] 57%|█████▋    | 654/1157 [33:28<26:05,  3.11s/it] 57%|█████▋    | 655/1157 [33:30<25:03,  2.99s/it] 57%|█████▋    | 656/1157 [33:34<25:53,  3.10s/it] 57%|█████▋    | 657/1157 [33:37<26:44,  3.21s/it] 57%|█████▋    | 658/1157 [33:40<25:38,  3.08s/it] 57%|█████▋    | 659/1157 [33:43<26:07,  3.15s/it] 57%|█████▋    | 660/1157 [33:46<26:04,  3.15s/it]                                                   57%|█████▋
0: {'loss': 1.2605, 'grad_norm': 0.5856860280036926, 'learning_rate': 4.2178046672428695e-06, 'entropy': 1.2623484522104262, 'num_tokens': 3885755.0, 'mean_token_accuracy': 0.7738258525729179, 'epoch': 0.58}
0:     | 660/1157 [33:46<26:04,  3.15s/it] 57%|█████▋    | 661/1157 [33:49<25:34,  3.09s/it] 57%|█████▋    | 662/1157 [33:53<25:40,  3.11s/it] 57%|█████▋    | 663/1157 [33:56<26:08,  3.18s/it] 57%|█████▋    | 664/1157 [33:59<25:30,  3.11s/it] 57%|█████▋    | 665/1157 [34:02<25:34,  3.12s/it] 58%|█████▊    | 666/1157 [34:05<25:58,  3.17s/it] 58%|█████▊    | 667/1157 [34:08<25:17,  3.10s/it] 58%|█████▊    | 668/1157 [34:11<24:54,  3.06s/it] 58%|█████▊    | 669/1157 [34:14<25:34,  3.15s/it] 58%|█████▊    | 670/1157 [34:17<24:58,  3.08s/it]                                                   58%|█████▊    | 670/1157 [34:17<24:58,  3.08s/it] 58%|█████▊    | 671/1157 [34:21<25:27,  3.14s/it] 58%|█████▊    | 672/1157 [34:24<26:00,  3.22s/it] 58%|█████▊    | 673/1157 [34:27<24:48,  3.07s/it] 58%|█████▊    | 674/1157 [34:30<25:27
0: {'loss': 1.2137, 'grad_norm': 0.5718375444412231, 'learning_rate': 4.131374243733795e-06, 'entropy': 1.20391393750906, 'num_tokens': 3944029.0, 'mean_token_accuracy': 0.7801462933421135, 'epoch': 0.59}
0: ,  3.16s/it] 58%|█████▊    | 675/1157 [34:33<25:19,  3.15s/it] 58%|█████▊    | 676/1157 [34:36<24:21,  3.04s/it] 59%|█████▊    | 677/1157 [34:39<25:10,  3.15s/it] 59%|█████▊    | 678/1157 [34:43<25:01,  3.13s/it] 59%|█████▊    | 679/1157 [34:45<24:26,  3.07s/it] 59%|█████▉    | 680/1157 [34:49<24:16,  3.05s/it]                                                   59%|█████▉    | 680/1157 [34:49<24:16,  3.05s/it] 59%|█████▉    | 681/1157 [34:52<24:51,  3.13s/it] 59%|█████▉    | 682/1157 [34:55<24:27,  3.09s/it] 59%|█████▉    | 683/1157 [34:58<24:35,  3.11s/it] 59%|█████▉    | 684/1157 [35:01<25:11,  3.20s/it] 59%|█████▉    | 685/1157 [35:04<24:28,  3.11s/it] 59%|█████▉    | 686/1157 [35:07<24:02,  3.06s/it] 59%|█████▉    | 687/1157 [35:11<24:35,  3.14s/it] 59%|█████▉    | 688/1157 [35:14<24:07,  3.09s/it] 60%|███
0: {'loss': 1.2094, 'grad_norm': 0.6064413189888, 'learning_rate': 4.04494382022472e-06, 'entropy': 1.2004014238715173, 'num_tokens': 4002000.0, 'mean_token_accuracy': 0.7810437738895416, 'epoch': 0.6}
0: {'loss': 1.2215, 'grad_norm': 0.605545163154602, 'learning_rate': 3.958513396715644e-06, 'entropy': 1.2168867617845536, 'num_tokens': 4060050.0, 'mean_token_accuracy': 0.7777155980467796, 'epoch': 0.61}
0: ██▉    | 689/1157 [35:17<24:35,  3.15s/it] 60%|█████▉    | 690/1157 [35:20<24:26,  3.14s/it]                                                   60%|█████▉    | 690/1157 [35:20<24:26,  3.14s/it] 60%|█████▉    | 691/1157 [35:23<23:57,  3.08s/it] 60%|█████▉    | 692/1157 [35:26<24:28,  3.16s/it] 60%|█████▉    | 693/1157 [35:29<24:20,  3.15s/it] 60%|█████▉    | 694/1157 [35:32<23:19,  3.02s/it] 60%|██████    | 695/1157 [35:35<23:53,  3.10s/it] 60%|██████    | 696/1157 [35:38<23:51,  3.11s/it] 60%|██████    | 697/1157 [35:41<23:23,  3.05s/it] 60%|██████    | 698/1157 [35:45<23:34,  3.08s/it] 60%|██████    | 699/1157 [35:47<23:09,  3.03s/it] 61%|██████    | 700/1157 [35:50<22:54,  3.01s/it]                                                   61%|██████    | 700/1157 [35:50<22:54,  3.01s/it] 61%|██████    | 701/1157 [35:54<23:17, 
0: {'loss': 1.2344, 'grad_norm': 0.5911006331443787, 'learning_rate': 3.872082973206569e-06, 'entropy': 1.2171385422348977, 'num_tokens': 4117670.0, 'mean_token_accuracy': 0.7806680500507355, 'epoch': 0.61}
0:  3.07s/it] 61%|██████    | 702/1157 [35:57<23:23,  3.08s/it] 61%|██████    | 703/1157 [36:00<22:59,  3.04s/it] 61%|██████    | 704/1157 [36:03<23:34,  3.12s/it] 61%|██████    | 705/1157 [36:06<23:28,  3.12s/it] 61%|██████    | 706/1157 [36:09<22:57,  3.05s/it] 61%|██████    | 707/1157 [36:12<23:52,  3.18s/it] 61%|██████    | 708/1157 [36:16<23:38,  3.16s/it] 61%|██████▏   | 709/1157 [36:18<22:38,  3.03s/it] 61%|██████▏   | 710/1157 [36:22<23:12,  3.11s/it]                                                   61%|██████▏   | 710/1157 [36:22<23:12,  3.11s/it] 61%|██████▏   | 711/1157 [36:25<23:13,  3.13s/it] 62%|██████▏   | 712/1157 [36:28<22:19,  3.01s/it] 62%|██████▏   | 713/1157 [36:31<23:10,  3.13s/it] 62%|██████▏   | 714/1157 [36:34<23:34,  3.19s/it] 62%|██████▏   | 715/1157 [36:37<22:30,  3.06s/it]
0: {'loss': 1.203, 'grad_norm': 0.6026169657707214, 'learning_rate': 3.7856525496974937e-06, 'entropy': 1.1913565874099732, 'num_tokens': 4175559.0, 'mean_token_accuracy': 0.782843416929245, 'epoch': 0.62}
0:  62%|██████▏   | 716/1157 [36:40<23:02,  3.14s/it] 62%|██████▏   | 717/1157 [36:43<22:58,  3.13s/it] 62%|██████▏   | 718/1157 [36:46<22:01,  3.01s/it] 62%|██████▏   | 719/1157 [36:49<22:19,  3.06s/it] 62%|██████▏   | 720/1157 [36:52<22:03,  3.03s/it]                                                   62%|██████▏   | 720/1157 [36:52<22:03,  3.03s/it] 62%|██████▏   | 721/1157 [36:55<21:53,  3.01s/it] 62%|██████▏   | 722/1157 [36:59<22:34,  3.11s/it] 62%|██████▏   | 723/1157 [37:02<22:53,  3.17s/it] 63%|██████▎   | 724/1157 [37:05<21:51,  3.03s/it] 63%|██████▎   | 725/1157 [37:08<22:25,  3.11s/it] 63%|██████▎   | 726/1157 [37:11<22:45,  3.17s/it] 63%|██████▎   | 727/1157 [37:14<21:44,  3.03s/it] 63%|██████▎   | 728/1157 [37:17<21:55,  3.07s/it] 63%|██████▎   | 729/1157 [37:20<21:58,  3.08s/i
0: {'loss': 1.2209, 'grad_norm': 0.6090083718299866, 'learning_rate': 3.6992221261884188e-06, 'entropy': 1.2160183638334274, 'num_tokens': 4233219.0, 'mean_token_accuracy': 0.7799803107976914, 'epoch': 0.63}
0: {'loss': 1.213, 'grad_norm': 0.5388221144676208, 'learning_rate': 3.6127917026793434e-06, 'entropy': 1.2093126475811005, 'num_tokens': 4290797.0, 'mean_token_accuracy': 0.7804305493831635, 'epoch': 0.64}
0: t] 63%|██████▎   | 730/1157 [37:23<21:15,  2.99s/it]                                                   63%|██████▎   | 730/1157 [37:23<21:15,  2.99s/it] 63%|██████▎   | 731/1157 [37:26<21:43,  3.06s/it] 63%|██████▎   | 732/1157 [37:29<21:21,  3.02s/it] 63%|██████▎   | 733/1157 [37:32<20:47,  2.94s/it] 63%|██████▎   | 734/1157 [37:35<21:20,  3.03s/it] 64%|██████▎   | 735/1157 [37:38<21:33,  3.06s/it] 64%|██████▎   | 736/1157 [37:41<20:49,  2.97s/it] 64%|██████▎   | 737/1157 [37:44<21:10,  3.03s/it] 64%|██████▍   | 738/1157 [37:47<21:28,  3.07s/it] 64%|██████▍   | 739/1157 [37:50<20:41,  2.97s/it] 64%|██████▍   | 740/1157 [37:54<21:31,  3.10s/it]                                                   64%|██████▍   | 740/1157 [37:54<21:31,  3.10s/it] 64%|██████▍   | 741/1157 [37:57<21:33,  3.11s/it] 64%|
0: {'loss': 1.1717, 'grad_norm': 0.5804914832115173, 'learning_rate': 3.5263612791702685e-06, 'entropy': 1.1700180798768998, 'num_tokens': 4347891.0, 'mean_token_accuracy': 0.7875325709581376, 'epoch': 0.65}
0: █████▍   | 742/1157 [37:59<20:43,  3.00s/it] 64%|██████▍   | 743/1157 [38:03<21:19,  3.09s/it] 64%|██████▍   | 744/1157 [38:06<21:21,  3.10s/it] 64%|██████▍   | 745/1157 [38:09<20:52,  3.04s/it] 64%|██████▍   | 746/1157 [38:12<21:02,  3.07s/it] 65%|██████▍   | 747/1157 [38:15<21:06,  3.09s/it] 65%|██████▍   | 748/1157 [38:18<21:04,  3.09s/it] 65%|██████▍   | 749/1157 [38:21<21:28,  3.16s/it] 65%|██████▍   | 750/1157 [38:25<21:24,  3.16s/it]                                                   65%|██████▍   | 750/1157 [38:25<21:24,  3.16s/it] 65%|██████▍   | 751/1157 [38:27<20:56,  3.09s/it] 65%|██████▍   | 752/1157 [38:31<20:58,  3.11s/it] 65%|██████▌   | 753/1157 [38:34<20:32,  3.05s/it] 65%|██████▌   | 754/1157 [38:36<20:12,  3.01s/it] 65%|██████▌   | 755/1157 [38:40<20:24,  3.05s/it] 65%
0: {'loss': 1.2105, 'grad_norm': 0.5589586496353149, 'learning_rate': 3.439930855661193e-06, 'entropy': 1.2086348563432694, 'num_tokens': 4405952.0, 'mean_token_accuracy': 0.7793382450938224, 'epoch': 0.66}
0: |██████▌   | 756/1157 [38:43<20:28,  3.06s/it] 65%|██████▌   | 757/1157 [38:46<20:06,  3.02s/it] 66%|██████▌   | 758/1157 [38:49<20:18,  3.05s/it] 66%|██████▌   | 759/1157 [38:52<20:25,  3.08s/it] 66%|██████▌   | 760/1157 [38:55<20:10,  3.05s/it]                                                   66%|██████▌   | 760/1157 [38:55<20:10,  3.05s/it] 66%|██████▌   | 761/1157 [38:58<20:15,  3.07s/it] 66%|██████▌   | 762/1157 [39:01<20:39,  3.14s/it] 66%|██████▌   | 763/1157 [39:04<20:14,  3.08s/it] 66%|██████▌   | 764/1157 [39:07<20:17,  3.10s/it] 66%|██████▌   | 765/1157 [39:11<20:36,  3.16s/it] 66%|██████▌   | 766/1157 [39:14<20:06,  3.09s/it] 66%|██████▋   | 767/1157 [39:17<20:05,  3.09s/it] 66%|██████▋   | 768/1157 [39:20<20:29,  3.16s/it] 66%|██████▋   | 769/1157 [39:23<20:04,  3.11s/it] 
0: {'loss': 1.211, 'grad_norm': 0.5979923009872437, 'learning_rate': 3.3535004321521183e-06, 'entropy': 1.1998766481876373, 'num_tokens': 4464261.0, 'mean_token_accuracy': 0.780114620923996, 'epoch': 0.67}
0: {'loss': 1.2277, 'grad_norm': 0.637244462966919, 'learning_rate': 3.2670700086430425e-06, 'entropy': 1.2117428317666055, 'num_tokens': 4522782.0, 'mean_token_accuracy': 0.7780997216701507, 'epoch': 0.67}
0: 67%|██████▋   | 770/1157 [39:26<19:48,  3.07s/it]                                                   67%|██████▋   | 770/1157 [39:26<19:48,  3.07s/it] 67%|██████▋   | 771/1157 [39:29<19:52,  3.09s/it] 67%|██████▋   | 772/1157 [39:32<19:53,  3.10s/it] 67%|██████▋   | 773/1157 [39:35<19:53,  3.11s/it] 67%|██████▋   | 774/1157 [39:38<19:52,  3.11s/it] 67%|██████▋   | 775/1157 [39:41<19:33,  3.07s/it] 67%|██████▋   | 776/1157 [39:45<19:35,  3.09s/it] 67%|██████▋   | 777/1157 [39:48<19:40,  3.11s/it] 67%|██████▋   | 778/1157 [39:51<19:22,  3.07s/it] 67%|██████▋   | 779/1157 [39:54<19:08,  3.04s/it] 67%|██████▋   | 780/1157 [39:57<19:16,  3.07s/it]                                                   67%|██████▋   | 780/1157 [39:57<19:16,  3.07s/it] 68%|██████▊   | 781/1157 [40:00<19:25,  3.10s/it] 68%|██
0: {'loss': 1.1831, 'grad_norm': 0.605413556098938, 'learning_rate': 3.180639585133967e-06, 'entropy': 1.181653168797493, 'num_tokens': 4580548.0, 'mean_token_accuracy': 0.7857388317584991, 'epoch': 0.68}
0: ████▊   | 782/1157 [40:03<19:03,  3.05s/it] 68%|██████▊   | 783/1157 [40:06<19:30,  3.13s/it] 68%|██████▊   | 784/1157 [40:09<19:35,  3.15s/it] 68%|██████▊   | 785/1157 [40:12<19:07,  3.08s/it] 68%|██████▊   | 786/1157 [40:16<19:33,  3.16s/it] 68%|██████▊   | 787/1157 [40:19<19:31,  3.17s/it] 68%|██████▊   | 788/1157 [40:22<19:05,  3.11s/it] 68%|██████▊   | 789/1157 [40:25<19:27,  3.17s/it] 68%|██████▊   | 790/1157 [40:28<19:20,  3.16s/it]                                                   68%|██████▊   | 790/1157 [40:28<19:20,  3.16s/it] 68%|██████▊   | 791/1157 [40:31<18:52,  3.09s/it] 68%|██████▊   | 792/1157 [40:35<19:15,  3.17s/it] 69%|██████▊   | 793/1157 [40:38<19:11,  3.16s/it] 69%|██████▊   | 794/1157 [40:41<18:46,  3.10s/it] 69%|██████▊   | 795/1157 [40:44<18:47,  3.11s/it] 69%|█
0: {'loss': 1.193, 'grad_norm': 0.6030633449554443, 'learning_rate': 3.0942091616248922e-06, 'entropy': 1.173830011487007, 'num_tokens': 4638273.0, 'mean_token_accuracy': 0.7837944194674492, 'epoch': 0.69}
0: █████▉   | 796/1157 [40:47<18:44,  3.12s/it] 69%|██████▉   | 797/1157 [40:50<19:01,  3.17s/it] 69%|██████▉   | 798/1157 [40:53<19:00,  3.18s/it] 69%|██████▉   | 799/1157 [40:57<18:51,  3.16s/it] 69%|██████▉   | 800/1157 [41:00<19:03,  3.20s/it]                                                   69%|██████▉   | 800/1157 [41:00<19:03,  3.20s/it] 69%|██████▉   | 801/1157 [41:03<18:53,  3.18s/it] 69%|██████▉   | 802/1157 [41:06<18:44,  3.17s/it] 69%|██████▉   | 803/1157 [41:09<18:14,  3.09s/it] 69%|██████▉   | 804/1157 [41:12<18:15,  3.10s/it] 70%|██████▉   | 805/1157 [41:15<18:16,  3.12s/it] 70%|██████▉   | 806/1157 [41:18<17:53,  3.06s/it] 70%|██████▉   | 807/1157 [41:21<17:59,  3.09s/it] 70%|██████▉   | 808/1157 [41:25<18:04,  3.11s/it] 70%|██████▉   | 809/1157 [41:28<17:43,  3.06s/it] 70%|
0: {'loss': 1.2617, 'grad_norm': 0.6110050082206726, 'learning_rate': 3.007778738115817e-06, 'entropy': 1.2456945717334746, 'num_tokens': 4696785.0, 'mean_token_accuracy': 0.7745682895183563, 'epoch': 0.7}
0: {'loss': 1.2284, 'grad_norm': 0.6413873434066772, 'learning_rate': 2.9213483146067416e-06, 'entropy': 1.2142901062965392, 'num_tokens': 4754715.0, 'mean_token_accuracy': 0.7812890127301216, 'epoch': 0.71}
0: ███████   | 810/1157 [41:31<17:48,  3.08s/it]                                                   70%|███████   | 810/1157 [41:31<17:48,  3.08s/it] 70%|███████   | 811/1157 [41:34<17:50,  3.09s/it] 70%|███████   | 812/1157 [41:37<17:55,  3.12s/it] 70%|███████   | 813/1157 [41:40<17:52,  3.12s/it] 70%|███████   | 814/1157 [41:43<17:48,  3.11s/it] 70%|███████   | 815/1157 [41:46<17:50,  3.13s/it] 71%|███████   | 816/1157 [41:49<17:46,  3.13s/it] 71%|███████   | 817/1157 [41:53<17:48,  3.14s/it] 71%|███████   | 818/1157 [41:56<17:46,  3.15s/it] 71%|███████   | 819/1157 [41:59<17:19,  3.07s/it] 71%|███████   | 820/1157 [42:02<17:22,  3.09s/it]                                                   71%|███████   | 820/1157 [42:02<17:22,  3.09s/it] 71%|███████   | 821/1157 [42:05<17:29,  3.12s/it] 71%|███
0: {'loss': 1.2025, 'grad_norm': 0.639958381652832, 'learning_rate': 2.8349178910976667e-06, 'entropy': 1.1961162865161896, 'num_tokens': 4812212.0, 'mean_token_accuracy': 0.7823101103305816, 'epoch': 0.72}
0: ███   | 822/1157 [42:08<17:24,  3.12s/it] 71%|███████   | 823/1157 [42:11<17:19,  3.11s/it] 71%|███████   | 824/1157 [42:14<17:18,  3.12s/it] 71%|███████▏  | 825/1157 [42:17<17:16,  3.12s/it] 71%|███████▏  | 826/1157 [42:21<17:35,  3.19s/it] 71%|███████▏  | 827/1157 [42:24<17:34,  3.20s/it] 72%|███████▏  | 828/1157 [42:27<17:03,  3.11s/it] 72%|███████▏  | 829/1157 [42:30<17:20,  3.17s/it] 72%|███████▏  | 830/1157 [42:33<17:13,  3.16s/it]                                                   72%|███████▏  | 830/1157 [42:33<17:13,  3.16s/it] 72%|███████▏  | 831/1157 [42:36<16:48,  3.09s/it] 72%|███████▏  | 832/1157 [42:40<17:17,  3.19s/it] 72%|███████▏  | 833/1157 [42:43<17:25,  3.23s/it] 72%|███████▏  | 834/1157 [42:46<16:50,  3.13s/it] 72%|███████▏  | 835/1157 [42:49<17:05,
0: {'loss': 1.2144, 'grad_norm': 0.6262013912200928, 'learning_rate': 2.7484874675885913e-06, 'entropy': 1.202684898674488, 'num_tokens': 4870236.0, 'mean_token_accuracy': 0.7802754312753677, 'epoch': 0.73}
0:   3.18s/it] 72%|███████▏  | 836/1157 [42:52<17:03,  3.19s/it] 72%|███████▏  | 837/1157 [42:56<16:46,  3.14s/it] 72%|███████▏  | 838/1157 [42:59<17:03,  3.21s/it] 73%|███████▎  | 839/1157 [43:02<16:51,  3.18s/it] 73%|███████▎  | 840/1157 [43:05<16:25,  3.11s/it]                                                   73%|███████▎  | 840/1157 [43:05<16:25,  3.11s/it] 73%|███████▎  | 841/1157 [43:08<16:48,  3.19s/it] 73%|███████▎  | 842/1157 [43:12<16:43,  3.19s/it] 73%|███████▎  | 843/1157 [43:14<16:20,  3.12s/it] 73%|███████▎  | 844/1157 [43:18<16:59,  3.26s/it] 73%|███████▎  | 845/1157 [43:21<16:44,  3.22s/it] 73%|███████▎  | 846/1157 [43:24<16:20,  3.15s/it] 73%|███████▎  | 847/1157 [43:28<16:51,  3.26s/it] 73%|███████▎  | 848/1157 [43:31<16:38,  3.23s/it] 73%|█████
0: {'loss': 1.2091, 'grad_norm': 0.63853919506073, 'learning_rate': 2.6620570440795164e-06, 'entropy': 1.2090046644210815, 'num_tokens': 4928131.0, 'mean_token_accuracy': 0.7819165974855423, 'epoch': 0.74}
0: {'loss': 1.1755, 'grad_norm': 0.6465792059898376, 'learning_rate': 2.575626620570441e-06, 'entropy': 1.1684613898396492, 'num_tokens': 4984893.0, 'mean_token_accuracy': 0.7878870978951454, 'epoch': 0.74}
0: █▎  | 849/1157 [43:34<16:25,  3.20s/it] 73%|███████▎  | 850/1157 [43:37<16:17,  3.18s/it]                                                   73%|███████▎  | 850/1157 [43:37<16:17,  3.18s/it] 74%|███████▎  | 851/1157 [43:40<16:08,  3.17s/it] 74%|███████▎  | 852/1157 [43:43<15:43,  3.09s/it] 74%|███████▎  | 853/1157 [43:47<16:02,  3.17s/it] 74%|███████▍  | 854/1157 [43:50<15:58,  3.16s/it] 74%|███████▍  | 855/1157 [43:53<15:40,  3.11s/it] 74%|███████▍  | 856/1157 [43:56<16:02,  3.20s/it] 74%|███████▍  | 857/1157 [43:59<15:51,  3.17s/it] 74%|███████▍  | 858/1157 [44:02<15:27,  3.10s/it] 74%|███████▍  | 859/1157 [44:05<15:46,  3.18s/it] 74%|███████▍  | 860/1157 [44:09<15:37,  3.16s/it]                                                   74%|███████▍  | 860/1157 [44:09<15:37,  3.16s/it] 74%
0: {'loss': 1.1863, 'grad_norm': 0.5679981112480164, 'learning_rate': 2.4891961970613657e-06, 'entropy': 1.1728198915719985, 'num_tokens': 5042544.0, 'mean_token_accuracy': 0.7859021812677384, 'epoch': 0.75}
0: |███████▍  | 861/1157 [44:12<15:18,  3.10s/it] 75%|███████▍  | 862/1157 [44:15<15:22,  3.13s/it] 75%|███████▍  | 863/1157 [44:18<15:22,  3.14s/it] 75%|███████▍  | 864/1157 [44:21<15:16,  3.13s/it] 75%|███████▍  | 865/1157 [44:24<15:16,  3.14s/it] 75%|███████▍  | 866/1157 [44:27<14:54,  3.07s/it] 75%|███████▍  | 867/1157 [44:30<14:55,  3.09s/it] 75%|███████▌  | 868/1157 [44:33<14:55,  3.10s/it] 75%|███████▌  | 869/1157 [44:36<14:54,  3.11s/it] 75%|███████▌  | 870/1157 [44:39<14:39,  3.06s/it]                                                   75%|███████▌  | 870/1157 [44:39<14:39,  3.06s/it] 75%|███████▌  | 871/1157 [44:43<15:01,  3.15s/it] 75%|███████▌  | 872/1157 [44:46<14:54,  3.14s/it] 75%|███████▌  | 873/1157 [44:49<14:33,  3.08s/it] 76%|███████▌  | 874/1
0: {'loss': 1.1695, 'grad_norm': 0.6795733571052551, 'learning_rate': 2.4027657735522904e-06, 'entropy': 1.1668111965060235, 'num_tokens': 5099733.0, 'mean_token_accuracy': 0.788085512816906, 'epoch': 0.76}
0: 157 [44:52<14:54,  3.16s/it] 76%|███████▌  | 875/1157 [44:55<14:35,  3.11s/it] 76%|███████▌  | 876/1157 [44:58<14:15,  3.04s/it] 76%|███████▌  | 877/1157 [45:01<14:35,  3.13s/it] 76%|███████▌  | 878/1157 [45:05<14:33,  3.13s/it] 76%|███████▌  | 879/1157 [45:07<14:13,  3.07s/it] 76%|███████▌  | 880/1157 [45:11<14:16,  3.09s/it]                                                   76%|███████▌  | 880/1157 [45:11<14:16,  3.09s/it] 76%|███████▌  | 881/1157 [45:14<14:17,  3.11s/it] 76%|███████▌  | 882/1157 [45:17<14:13,  3.10s/it] 76%|███████▋  | 883/1157 [45:20<14:14,  3.12s/it] 76%|███████▋  | 884/1157 [45:23<13:57,  3.07s/it] 76%|███████▋  | 885/1157 [45:26<14:00,  3.09s/it] 77%|███████▋  | 886/1157 [45:29<14:02,  3.11s/it] 77%|███████▋  | 887/1157 [45:32<13:44,  3.05s/it] 77%|
0: {'loss': 1.2211, 'grad_norm': 0.5763919353485107, 'learning_rate': 2.3163353500432155e-06, 'entropy': 1.1991613134741783, 'num_tokens': 5157524.0, 'mean_token_accuracy': 0.7795702174305916, 'epoch': 0.77}
0: ███████▋  | 888/1157 [45:35<13:34,  3.03s/it] 77%|███████▋  | 889/1157 [45:39<14:01,  3.14s/it] 77%|███████▋  | 890/1157 [45:42<13:50,  3.11s/it]                                                   77%|███████▋  | 890/1157 [45:42<13:50,  3.11s/it] 77%|███████▋  | 891/1157 [45:45<13:40,  3.08s/it] 77%|███████▋  | 892/1157 [45:48<14:00,  3.17s/it] 77%|███████▋  | 893/1157 [45:51<13:42,  3.12s/it] 77%|███████▋  | 894/1157 [45:54<13:29,  3.08s/it] 77%|███████▋  | 895/1157 [45:57<13:54,  3.19s/it] 77%|███████▋  | 896/1157 [46:00<13:45,  3.16s/it] 78%|███████▊  | 897/1157 [46:03<13:24,  3.09s/it] 78%|███████▊  | 898/1157 [46:07<13:42,  3.18s/it] 78%|███████▊  | 899/1157 [46:10<13:20,  3.10s/it] 78%|███████▊  | 900/1157 [46:13<13:19,  3.11s/it]                                       
0: {'loss': 1.2115, 'grad_norm': 0.6885516047477722, 'learning_rate': 2.22990492653414e-06, 'entropy': 1.2111503422260284, 'num_tokens': 5215522.0, 'mean_token_accuracy': 0.783514341711998, 'epoch': 0.78}
0: {'loss': 1.232, 'grad_norm': 0.6683444976806641, 'learning_rate': 2.1434745030250652e-06, 'entropy': 1.2246593594551087, 'num_tokens': 5273626.0, 'mean_token_accuracy': 0.777061602473259, 'epoch': 0.79}
0:             78%|███████▊  | 900/1157 [46:13<13:19,  3.11s/it] 78%|███████▊  | 901/1157 [46:16<13:50,  3.24s/it] 78%|███████▊  | 902/1157 [46:19<13:25,  3.16s/it] 78%|███████▊  | 903/1157 [46:22<13:20,  3.15s/it] 78%|███████▊  | 904/1157 [46:26<13:30,  3.20s/it] 78%|███████▊  | 905/1157 [46:29<13:21,  3.18s/it] 78%|███████▊  | 906/1157 [46:32<13:14,  3.16s/it] 78%|███████▊  | 907/1157 [46:35<13:21,  3.21s/it] 78%|███████▊  | 908/1157 [46:38<12:59,  3.13s/it] 79%|███████▊  | 909/1157 [46:41<12:54,  3.12s/it] 79%|███████▊  | 910/1157 [46:45<13:04,  3.18s/it]                                                   79%|███████▊  | 910/1157 [46:45<13:04,  3.18s/it] 79%|███████▊  | 911/1157 [46:48<12:57,  3.16s/it] 79%|███████▉  | 912/1157 [46:51<12:50,  3.15s/it] 79%|█████
0: {'loss': 1.2115, 'grad_norm': 0.6137633919715881, 'learning_rate': 2.05704407951599e-06, 'entropy': 1.2066847935318947, 'num_tokens': 5331679.0, 'mean_token_accuracy': 0.7802013829350471, 'epoch': 0.8}
0: █▉  | 913/1157 [46:54<13:01,  3.20s/it] 79%|███████▉  | 914/1157 [46:57<12:52,  3.18s/it] 79%|███████▉  | 915/1157 [47:01<12:44,  3.16s/it] 79%|███████▉  | 916/1157 [47:04<12:54,  3.21s/it] 79%|███████▉  | 917/1157 [47:07<12:43,  3.18s/it] 79%|███████▉  | 918/1157 [47:10<12:33,  3.15s/it] 79%|███████▉  | 919/1157 [47:13<12:42,  3.20s/it] 80%|███████▉  | 920/1157 [47:17<12:36,  3.19s/it]                                                   80%|███████▉  | 920/1157 [47:17<12:36,  3.19s/it] 80%|███████▉  | 921/1157 [47:20<12:29,  3.18s/it] 80%|███████▉  | 922/1157 [47:23<12:38,  3.23s/it] 80%|███████▉  | 923/1157 [47:26<12:30,  3.21s/it] 80%|███████▉  | 924/1157 [47:29<12:19,  3.17s/it] 80%|███████▉  | 925/1157 [47:33<12:25,  3.21s/it] 80%|████████  | 926/1157 [47:36<12:14,
0: {'loss': 1.2081, 'grad_norm': 0.5876899361610413, 'learning_rate': 1.9706136560069146e-06, 'entropy': 1.1883741736412048, 'num_tokens': 5389821.0, 'mean_token_accuracy': 0.7804202049970627, 'epoch': 0.8}
0:   3.18s/it] 80%|████████  | 927/1157 [47:39<11:54,  3.11s/it] 80%|████████  | 928/1157 [47:42<11:54,  3.12s/it] 80%|████████  | 929/1157 [47:45<11:50,  3.11s/it] 80%|████████  | 930/1157 [47:48<11:34,  3.06s/it]                                                   80%|████████  | 930/1157 [47:48<11:34,  3.06s/it] 80%|████████  | 931/1157 [47:51<11:37,  3.09s/it] 81%|████████  | 932/1157 [47:54<11:39,  3.11s/it] 81%|████████  | 933/1157 [47:57<11:36,  3.11s/it] 81%|████████  | 934/1157 [48:00<11:34,  3.12s/it] 81%|████████  | 935/1157 [48:04<11:33,  3.12s/it] 81%|████████  | 936/1157 [48:06<11:19,  3.08s/it] 81%|████████  | 937/1157 [48:10<11:31,  3.14s/it] 81%|████████  | 938/1157 [48:13<11:26,  3.13s/it] 81%|████████  | 939/1157 [48:16<11:10,  3.08s/it] 81%|█████
0: {'loss': 1.252, 'grad_norm': 0.6019028425216675, 'learning_rate': 1.8841832324978392e-06, 'entropy': 1.2312123730778695, 'num_tokens': 5448269.0, 'mean_token_accuracy': 0.777073273062706, 'epoch': 0.81}
0: {'loss': 1.2262, 'grad_norm': 0.6212778091430664, 'learning_rate': 1.797752808988764e-06, 'entropy': 1.2325501933693885, 'num_tokens': 5507141.0, 'mean_token_accuracy': 0.7780945718288421, 'epoch': 0.82}
0: ██  | 940/1157 [48:19<11:11,  3.10s/it]                                                   81%|████████  | 940/1157 [48:19<11:11,  3.10s/it] 81%|████████▏ | 941/1157 [48:22<11:10,  3.10s/it] 81%|████████▏ | 942/1157 [48:25<10:59,  3.07s/it] 82%|████████▏ | 943/1157 [48:28<11:00,  3.09s/it] 82%|████████▏ | 944/1157 [48:31<10:58,  3.09s/it] 82%|████████▏ | 945/1157 [48:34<10:44,  3.04s/it] 82%|████████▏ | 946/1157 [48:38<11:00,  3.13s/it] 82%|████████▏ | 947/1157 [48:41<10:55,  3.12s/it] 82%|████████▏ | 948/1157 [48:44<10:50,  3.11s/it] 82%|████████▏ | 949/1157 [48:47<11:04,  3.20s/it] 82%|████████▏ | 950/1157 [48:50<10:56,  3.17s/it]                                                   82%|████████▏ | 950/1157 [48:50<10:56,  3.17s/it] 82%|████████▏ | 951/1157 [48:5
0: {'loss': 1.1822, 'grad_norm': 0.6044135689735413, 'learning_rate': 1.711322385479689e-06, 'entropy': 1.1851858511567115, 'num_tokens': 5564910.0, 'mean_token_accuracy': 0.7845841079950333, 'epoch': 0.83}
0: 3<10:51,  3.16s/it] 82%|████████▏ | 952/1157 [48:57<11:10,  3.27s/it] 82%|████████▏ | 953/1157 [49:00<10:47,  3.17s/it] 82%|████████▏ | 954/1157 [49:03<10:29,  3.10s/it] 83%|████████▎ | 955/1157 [49:06<10:28,  3.11s/it] 83%|████████▎ | 956/1157 [49:09<10:28,  3.13s/it] 83%|████████▎ | 957/1157 [49:12<10:13,  3.07s/it] 83%|████████▎ | 958/1157 [49:15<10:26,  3.15s/it] 83%|████████▎ | 959/1157 [49:18<10:11,  3.09s/it] 83%|████████▎ | 960/1157 [49:22<10:22,  3.16s/it]                                                   83%|████████▎ | 960/1157 [49:22<10:22,  3.16s/it] 83%|████████▎ | 961/1157 [49:25<10:24,  3.19s/it] 83%|████████▎ | 962/1157 [49:28<10:07,  3.11s/it] 83%|████████▎ | 963/1157 [49:31<10:03,  3.11s/it] 83%|████████▎ | 964/1157 [49:34<10:1
0: {'loss': 1.2232, 'grad_norm': 0.6346288919448853, 'learning_rate': 1.6248919619706138e-06, 'entropy': 1.2067190244793893, 'num_tokens': 5622951.0, 'mean_token_accuracy': 0.7785845085978508, 'epoch': 0.84}
0: 1,  3.17s/it] 83%|████████▎ | 965/1157 [49:37<09:55,  3.10s/it] 83%|████████▎ | 966/1157 [49:40<09:42,  3.05s/it] 84%|████████▎ | 967/1157 [49:43<09:54,  3.13s/it] 84%|████████▎ | 968/1157 [49:46<09:40,  3.07s/it] 84%|████████▍ | 969/1157 [49:49<09:31,  3.04s/it] 84%|████████▍ | 970/1157 [49:53<09:45,  3.13s/it]                                                   84%|████████▍ | 970/1157 [49:53<09:45,  3.13s/it] 84%|████████▍ | 971/1157 [49:56<09:33,  3.08s/it] 84%|████████▍ | 972/1157 [49:59<09:23,  3.04s/it] 84%|████████▍ | 973/1157 [50:02<09:35,  3.13s/it] 84%|████████▍ | 974/1157 [50:05<09:20,  3.06s/it] 84%|████████▍ | 975/1157 [50:08<09:20,  3.08s/it] 84%|████████▍ | 976/1157 [50:11<09:19,  3.09s/it] 84%|████████▍ | 977/1157 [50:14<09:19,  3.
0: {'loss': 1.1895, 'grad_norm': 0.5851569771766663, 'learning_rate': 1.5384615384615387e-06, 'entropy': 1.185023857653141, 'num_tokens': 5680732.0, 'mean_token_accuracy': 0.7822600439190864, 'epoch': 0.85}
0: 11s/it] 85%|████████▍ | 978/1157 [50:17<09:17,  3.12s/it] 85%|████████▍ | 979/1157 [50:20<09:04,  3.06s/it] 85%|████████▍ | 980/1157 [50:23<09:06,  3.09s/it]                                                   85%|████████▍ | 980/1157 [50:23<09:06,  3.09s/it] 85%|████████▍ | 981/1157 [50:27<09:06,  3.10s/it] 85%|████████▍ | 982/1157 [50:30<09:14,  3.17s/it] 85%|████████▍ | 983/1157 [50:33<08:58,  3.10s/it] 85%|████████▌ | 984/1157 [50:36<08:57,  3.11s/it] 85%|████████▌ | 985/1157 [50:39<09:05,  3.17s/it] 85%|████████▌ | 986/1157 [50:42<08:49,  3.10s/it] 85%|████████▌ | 987/1157 [50:45<08:48,  3.11s/it] 85%|████████▌ | 988/1157 [50:49<08:57,  3.18s/it] 85%|████████▌ | 989/1157 [50:52<08:42,  3.11s/it] 86%|████████▌ | 990/1157 [50:55<08:43,  3.13s/it
0: {'loss': 1.1999, 'grad_norm': 0.6135293245315552, 'learning_rate': 1.4520311149524636e-06, 'entropy': 1.1890798181295394, 'num_tokens': 5738479.0, 'mean_token_accuracy': 0.7821270361542701, 'epoch': 0.86}
0: {'loss': 1.1908, 'grad_norm': 0.5905073881149292, 'learning_rate': 1.365600691443388e-06, 'entropy': 1.1874450519680977, 'num_tokens': 5796246.0, 'mean_token_accuracy': 0.7838544487953186, 'epoch': 0.86}
0: ]                                                   86%|████████▌ | 990/1157 [50:55<08:43,  3.13s/it] 86%|████████▌ | 991/1157 [50:58<08:51,  3.20s/it] 86%|████████▌ | 992/1157 [51:01<08:35,  3.13s/it] 86%|████████▌ | 993/1157 [51:04<08:32,  3.12s/it] 86%|████████▌ | 994/1157 [51:07<08:30,  3.13s/it] 86%|████████▌ | 995/1157 [51:11<08:26,  3.13s/it] 86%|████████▌ | 996/1157 [51:14<08:24,  3.13s/it] 86%|████████▌ | 997/1157 [51:17<08:30,  3.19s/it] 86%|████████▋ | 998/1157 [51:20<08:13,  3.10s/it] 86%|████████▋ | 999/1157 [51:23<08:13,  3.12s/it] 86%|████████▋ | 1000/1157 [51:26<08:11,  3.13s/it]                                                    86%|████████▋ | 1000/1157 [51:26<08:11,  3.13s/it] 87%|████████▋ | 1001/1157 [51:29<08:00,  3.08s/it] 87%|████
0: {'loss': 1.2242, 'grad_norm': 0.5739052891731262, 'learning_rate': 1.279170267934313e-06, 'entropy': 1.2209229648113251, 'num_tokens': 5854597.0, 'mean_token_accuracy': 0.777197639644146, 'epoch': 0.87}
0: ████▋ | 1002/1157 [51:32<08:00,  3.10s/it] 87%|████████▋ | 1003/1157 [51:35<08:00,  3.12s/it] 87%|████████▋ | 1004/1157 [51:38<07:48,  3.06s/it] 87%|████████▋ | 1005/1157 [51:42<07:49,  3.09s/it] 87%|████████▋ | 1006/1157 [51:45<07:50,  3.11s/it] 87%|████████▋ | 1007/1157 [51:48<07:40,  3.07s/it] 87%|████████▋ | 1008/1157 [51:51<07:41,  3.09s/it] 87%|████████▋ | 1009/1157 [51:54<07:49,  3.17s/it] 87%|████████▋ | 1010/1157 [51:57<07:36,  3.10s/it]                                                    87%|████████▋ | 1010/1157 [51:57<07:36,  3.10s/it] 87%|████████▋ | 1011/1157 [52:00<07:34,  3.11s/it] 87%|████████▋ | 1012/1157 [52:04<07:39,  3.17s/it] 88%|████████▊ | 1013/1157 [52:07<07:26,  3.10s/it] 88%|████████▊ | 1014/1157 [52:10<07:24,  3.11s/it] 88%|█
0: {'loss': 1.2198, 'grad_norm': 0.7206303477287292, 'learning_rate': 1.1927398444252378e-06, 'entropy': 1.2186476022005082, 'num_tokens': 5912950.0, 'mean_token_accuracy': 0.7791488647460938, 'epoch': 0.88}
0: ███████▊ | 1015/1157 [52:13<07:23,  3.12s/it] 88%|████████▊ | 1016/1157 [52:16<07:12,  3.07s/it] 88%|████████▊ | 1017/1157 [52:19<07:11,  3.08s/it] 88%|████████▊ | 1018/1157 [52:22<07:03,  3.05s/it] 88%|████████▊ | 1019/1157 [52:25<06:57,  3.02s/it] 88%|████████▊ | 1020/1157 [52:28<07:05,  3.10s/it]                                                    88%|████████▊ | 1020/1157 [52:28<07:05,  3.10s/it] 88%|████████▊ | 1021/1157 [52:31<07:02,  3.11s/it] 88%|████████▊ | 1022/1157 [52:34<06:51,  3.05s/it] 88%|████████▊ | 1023/1157 [52:37<06:57,  3.12s/it] 89%|████████▊ | 1024/1157 [52:41<07:03,  3.18s/it] 89%|████████▊ | 1025/1157 [52:44<06:48,  3.10s/it] 89%|████████▊ | 1026/1157 [52:47<06:46,  3.10s/it] 89%|████████▉ | 1027/1157 [52:50<06:52,  3.17s/it]
0: {'loss': 1.2101, 'grad_norm': 0.6108418703079224, 'learning_rate': 1.1063094209161627e-06, 'entropy': 1.2099035784602166, 'num_tokens': 5971351.0, 'mean_token_accuracy': 0.7812171205878258, 'epoch': 0.89}
0:  89%|████████▉ | 1028/1157 [52:53<06:40,  3.11s/it] 89%|████████▉ | 1029/1157 [52:56<06:34,  3.08s/it] 89%|████████▉ | 1030/1157 [52:59<06:42,  3.17s/it]                                                    89%|████████▉ | 1030/1157 [52:59<06:42,  3.17s/it] 89%|████████▉ | 1031/1157 [53:02<06:30,  3.10s/it] 89%|████████▉ | 1032/1157 [53:06<06:28,  3.11s/it] 89%|████████▉ | 1033/1157 [53:09<06:28,  3.14s/it] 89%|████████▉ | 1034/1157 [53:12<06:19,  3.08s/it] 89%|████████▉ | 1035/1157 [53:15<06:17,  3.10s/it] 90%|████████▉ | 1036/1157 [53:18<06:11,  3.07s/it] 90%|████████▉ | 1037/1157 [53:21<06:02,  3.02s/it] 90%|████████▉ | 1038/1157 [53:24<06:05,  3.07s/it] 90%|████████▉ | 1039/1157 [53:27<06:03,  3.08s/it] 90%|████████▉ | 1040/1157 [53:30<05:56,  
0: {'loss': 1.2157, 'grad_norm': 0.663541316986084, 'learning_rate': 1.0198789974070873e-06, 'entropy': 1.2004872485995293, 'num_tokens': 6029238.0, 'mean_token_accuracy': 0.7805823937058449, 'epoch': 0.9}
0: {'loss': 1.2343, 'grad_norm': 0.6239116787910461, 'learning_rate': 9.334485738980122e-07, 'entropy': 1.2145574808120727, 'num_tokens': 6087505.0, 'mean_token_accuracy': 0.7781067386269569, 'epoch': 0.91}
0: 3.04s/it]                                                    90%|████████▉ | 1040/1157 [53:30<05:56,  3.04s/it] 90%|████████▉ | 1041/1157 [53:33<05:51,  3.03s/it] 90%|█████████ | 1042/1157 [53:36<05:58,  3.12s/it] 90%|█████████ | 1043/1157 [53:39<05:48,  3.05s/it] 90%|█████████ | 1044/1157 [53:43<05:54,  3.13s/it] 90%|█████████ | 1045/1157 [53:46<05:51,  3.14s/it] 90%|█████████ | 1046/1157 [53:49<05:41,  3.07s/it] 90%|█████████ | 1047/1157 [53:52<05:40,  3.10s/it] 91%|█████████ | 1048/1157 [53:55<05:39,  3.11s/it] 91%|█████████ | 1049/1157 [53:58<05:30,  3.06s/it] 91%|█████████ | 1050/1157 [54:01<05:23,  3.02s/it]                                                    91%|█████████ | 1050/1157 [54:01<05:23,  3.02s/it] 91%|█████████ | 1051/1157 [54:04<05:29,  3.11s/it
0: {'loss': 1.1955, 'grad_norm': 0.6345438361167908, 'learning_rate': 8.47018150388937e-07, 'entropy': 1.1809655025601387, 'num_tokens': 6144756.0, 'mean_token_accuracy': 0.7855237305164338, 'epoch': 0.92}
0: ] 91%|█████████ | 1052/1157 [54:07<05:21,  3.06s/it] 91%|█████████ | 1053/1157 [54:10<05:22,  3.10s/it] 91%|█████████ | 1054/1157 [54:13<05:19,  3.10s/it] 91%|█████████ | 1055/1157 [54:16<05:12,  3.06s/it] 91%|█████████▏| 1056/1157 [54:20<05:17,  3.14s/it] 91%|█████████▏| 1057/1157 [54:23<05:14,  3.14s/it] 91%|█████████▏| 1058/1157 [54:26<05:04,  3.08s/it] 92%|█████████▏| 1059/1157 [54:29<05:03,  3.10s/it] 92%|█████████▏| 1060/1157 [54:32<05:01,  3.11s/it]                                                    92%|█████████▏| 1060/1157 [54:32<05:01,  3.11s/it] 92%|█████████▏| 1061/1157 [54:35<04:53,  3.06s/it] 92%|█████████▏| 1062/1157 [54:38<04:57,  3.13s/it] 92%|█████████▏| 1063/1157 [54:42<04:59,  3.18s/it] 92%|█████████▏| 1064
0: {'loss': 1.1766, 'grad_norm': 0.5903908610343933, 'learning_rate': 7.605877268798617e-07, 'entropy': 1.1793698400259018, 'num_tokens': 6202196.0, 'mean_token_accuracy': 0.7867465361952781, 'epoch': 0.93}
0: /1157 [54:44<04:50,  3.12s/it] 92%|█████████▏| 1065/1157 [54:48<04:52,  3.18s/it] 92%|█████████▏| 1066/1157 [54:51<04:52,  3.22s/it] 92%|█████████▏| 1067/1157 [54:54<04:43,  3.15s/it] 92%|█████████▏| 1068/1157 [54:57<04:40,  3.15s/it] 92%|█████████▏| 1069/1157 [55:01<04:40,  3.19s/it] 92%|█████████▏| 1070/1157 [55:03<04:31,  3.12s/it]                                                    92%|█████████▏| 1070/1157 [55:03<04:31,  3.12s/it] 93%|█████████▎| 1071/1157 [55:07<04:33,  3.18s/it] 93%|█████████▎| 1072/1157 [55:10<04:29,  3.17s/it] 93%|█████████▎| 1073/1157 [55:13<04:23,  3.13s/it] 93%|█████████▎| 1074/1157 [55:17<04:30,  3.26s/it] 93%|█████████▎| 1075/1157 [55:20<04:24,  3.22s/it] 93%|█████████▎| 1076/1157 [55:23<04:14,  3.14s/it] 93%
0: {'loss': 1.2121, 'grad_norm': 0.6575943231582642, 'learning_rate': 6.741573033707865e-07, 'entropy': 1.1964838445186614, 'num_tokens': 6260262.0, 'mean_token_accuracy': 0.7822529911994934, 'epoch': 0.93}
0: |█████████▎| 1077/1157 [55:26<04:16,  3.21s/it] 93%|█████████▎| 1078/1157 [55:29<04:11,  3.19s/it] 93%|█████████▎| 1079/1157 [55:32<04:02,  3.11s/it] 93%|█████████▎| 1080/1157 [55:35<04:00,  3.12s/it]                                                    93%|█████████▎| 1080/1157 [55:35<04:00,  3.12s/it] 93%|█████████▎| 1081/1157 [55:38<03:57,  3.12s/it] 94%|█████████▎| 1082/1157 [55:41<03:49,  3.06s/it] 94%|█████████▎| 1083/1157 [55:44<03:47,  3.08s/it] 94%|█████████▎| 1084/1157 [55:48<03:46,  3.10s/it] 94%|█████████▍| 1085/1157 [55:51<03:40,  3.06s/it] 94%|█████████▍| 1086/1157 [55:54<03:39,  3.10s/it] 94%|█████████▍| 1087/1157 [55:57<03:41,  3.17s/it] 94%|█████████▍| 1088/1157 [56:00<03:33,  3.10s/it] 94%|█████████▍| 10
0: {'loss': 1.2045, 'grad_norm': 0.6275418400764465, 'learning_rate': 5.877268798617114e-07, 'entropy': 1.1934127122163773, 'num_tokens': 6317537.0, 'mean_token_accuracy': 0.7819940060377121, 'epoch': 0.94}
0: {'loss': 1.2031, 'grad_norm': 0.6033765077590942, 'learning_rate': 5.012964563526362e-07, 'entropy': 1.1971251294016838, 'num_tokens': 6375264.0, 'mean_token_accuracy': 0.7839754953980446, 'epoch': 0.95}
0: 89/1157 [56:03<03:31,  3.11s/it] 94%|█████████▍| 1090/1157 [56:06<03:32,  3.18s/it]                                                    94%|█████████▍| 1090/1157 [56:06<03:32,  3.18s/it] 94%|█████████▍| 1091/1157 [56:09<03:25,  3.11s/it] 94%|█████████▍| 1092/1157 [56:13<03:30,  3.23s/it] 94%|█████████▍| 1093/1157 [56:16<03:24,  3.20s/it] 95%|█████████▍| 1094/1157 [56:19<03:16,  3.11s/it] 95%|█████████▍| 1095/1157 [56:22<03:20,  3.23s/it] 95%|█████████▍| 1096/1157 [56:26<03:15,  3.20s/it] 95%|█████████▍| 1097/1157 [56:29<03:07,  3.13s/it] 95%|█████████▍| 1098/1157 [56:32<03:07,  3.18s/it] 95%|█████████▍| 1099/1157 [56:35<03:04,  3.18s/it] 95%|█████████▌| 1100/1157 [56:38<02:57,  3.11s/it]                                                    95%|█████
0: {'loss': 1.2138, 'grad_norm': 0.6120225787162781, 'learning_rate': 4.148660328435609e-07, 'entropy': 1.2076628237962723, 'num_tokens': 6433863.0, 'mean_token_accuracy': 0.7809632793068886, 'epoch': 0.96}
0: ███▌| 1100/1157 [56:38<02:57,  3.11s/it] 95%|█████████▌| 1101/1157 [56:41<02:58,  3.18s/it] 95%|█████████▌| 1102/1157 [56:45<02:54,  3.18s/it] 95%|█████████▌| 1103/1157 [56:47<02:47,  3.10s/it] 95%|█████████▌| 1104/1157 [56:51<02:48,  3.18s/it] 96%|█████████▌| 1105/1157 [56:54<02:44,  3.17s/it] 96%|█████████▌| 1106/1157 [56:57<02:38,  3.11s/it] 96%|█████████▌| 1107/1157 [57:00<02:39,  3.18s/it] 96%|█████████▌| 1108/1157 [57:03<02:35,  3.18s/it] 96%|█████████▌| 1109/1157 [57:07<02:31,  3.15s/it] 96%|█████████▌| 1110/1157 [57:10<02:31,  3.21s/it]                                                    96%|█████████▌| 1110/1157 [57:10<02:31,  3.21s/it] 96%|█████████▌| 1111/1157 [57:13<02:27,  3.21s/it] 96%|█████████▌| 1112/1157 [57:16<02
0: {'loss': 1.1859, 'grad_norm': 0.6468026638031006, 'learning_rate': 3.284356093344858e-07, 'entropy': 1.186560322344303, 'num_tokens': 6491721.0, 'mean_token_accuracy': 0.7849791273474693, 'epoch': 0.97}
0: :23,  3.19s/it] 96%|█████████▌| 1113/1157 [57:20<02:22,  3.24s/it] 96%|█████████▋| 1114/1157 [57:23<02:17,  3.21s/it] 96%|█████████▋| 1115/1157 [57:26<02:11,  3.12s/it] 96%|█████████▋| 1116/1157 [57:29<02:12,  3.24s/it] 97%|█████████▋| 1117/1157 [57:32<02:08,  3.20s/it] 97%|█████████▋| 1118/1157 [57:35<02:03,  3.18s/it] 97%|█████████▋| 1119/1157 [57:39<02:00,  3.17s/it] 97%|█████████▋| 1120/1157 [57:42<01:56,  3.16s/it]                                                    97%|█████████▋| 1120/1157 [57:42<01:56,  3.16s/it] 97%|█████████▋| 1121/1157 [57:45<01:51,  3.09s/it] 97%|█████████▋| 1122/1157 [57:48<01:50,  3.17s/it] 97%|█████████▋| 1123/1157 [57:51<01:47,  3.16s/it] 97%|█████████▋| 1124/1157 [57:54<01:44,  3.15s/it] 97%|████
0: {'loss': 1.1953, 'grad_norm': 0.616382360458374, 'learning_rate': 2.4200518582541056e-07, 'entropy': 1.187356662750244, 'num_tokens': 6549405.0, 'mean_token_accuracy': 0.786673741042614, 'epoch': 0.98}
0: ████▋| 1125/1157 [57:58<01:42,  3.20s/it] 97%|█████████▋| 1126/1157 [58:01<01:38,  3.17s/it] 97%|█████████▋| 1127/1157 [58:04<01:34,  3.16s/it] 97%|█████████▋| 1128/1157 [58:07<01:31,  3.16s/it] 98%|█████████▊| 1129/1157 [58:10<01:27,  3.14s/it] 98%|█████████▊| 1130/1157 [58:13<01:24,  3.13s/it]                                                    98%|█████████▊| 1130/1157 [58:13<01:24,  3.13s/it] 98%|█████████▊| 1131/1157 [58:16<01:23,  3.20s/it] 98%|█████████▊| 1132/1157 [58:20<01:19,  3.18s/it] 98%|█████████▊| 1133/1157 [58:23<01:15,  3.16s/it] 98%|█████████▊| 1134/1157 [58:26<01:14,  3.22s/it] 98%|█████████▊| 1135/1157 [58:29<01:10,  3.19s/it] 98%|█████████▊| 1136/1157 [58:32<01:06,  3.17s/it] 98%|█████████▊| 1137/1157 [58:36<
0: {'loss': 1.2433, 'grad_norm': 0.6221012473106384, 'learning_rate': 1.5557476231633536e-07, 'entropy': 1.224706956744194, 'num_tokens': 6607924.0, 'mean_token_accuracy': 0.7763398081064224, 'epoch': 0.99}
0: 01:04,  3.21s/it] 98%|█████████▊| 1138/1157 [58:39<01:00,  3.17s/it] 98%|█████████▊| 1139/1157 [58:42<00:55,  3.10s/it] 99%|█████████▊| 1140/1157 [58:45<00:53,  3.12s/it]                                                    99%|█████████▊| 1140/1157 [58:45<00:53,  3.12s/it] 99%|█████████▊| 1141/1157 [58:48<00:49,  3.11s/it] 99%|█████████▊| 1142/1157 [58:51<00:46,  3.07s/it] 99%|█████████▉| 1143/1157 [58:54<00:43,  3.11s/it] 99%|█████████▉| 1144/1157 [58:57<00:40,  3.12s/it] 99%|█████████▉| 1145/1157 [59:00<00:37,  3.12s/it] 99%|█████████▉| 1146/1157 [59:03<00:34,  3.12s/it] 99%|█████████▉| 1147/1157 [59:07<00:31,  3.12s/it] 99%|█████████▉| 1148/1157 [59:10<00:28,  3.13s/it] 99%|█████████▉| 1149/1157 [59:13<00:24,  3.12s/it] 99%|████
0: {'loss': 1.1877, 'grad_norm': 0.6127839088439941, 'learning_rate': 6.914433880726017e-08, 'entropy': 1.182472288608551, 'num_tokens': 6665486.0, 'mean_token_accuracy': 0.7836533457040786, 'epoch': 0.99}
0: {'train_runtime': 3581.0225, 'train_samples_per_second': 20.663, 'train_steps_per_second': 0.323, 'train_loss': 1.3144078522585751, 'entropy': 1.1633694386482238, 'num_tokens': 6701074.0, 'mean_token_accuracy': 0.7874807333946228, 'epoch': 1.0}
0: █████▉| 1150/1157 [59:16<00:21,  3.13s/it]                                                    99%|█████████▉| 1150/1157 [59:16<00:21,  3.13s/it] 99%|█████████▉| 1151/1157 [59:19<00:19,  3.18s/it]100%|█████████▉| 1152/1157 [59:22<00:15,  3.17s/it]100%|█████████▉| 1153/1157 [59:25<00:12,  3.11s/it]100%|█████████▉| 1154/1157 [59:29<00:09,  3.18s/it]100%|█████████▉| 1155/1157 [59:32<00:06,  3.17s/it]100%|█████████▉| 1156/1157 [59:35<00:03,  3.10s/it]100%|██████████| 1157/1157 [59:36<00:00,  2.46s/it]                                                   100%|██████████| 1157/1157 [59:36<00:00,  2.46s/it]100%|██████████| 1157/1157 [59:36<00:00,  3.09s/it]
0: --- Training Finished. Saving Model... ---
0: Saved loss plot.
0: 
0: --- Starting Final Evaluation on Full Validation Set ---
0: Inference:   0%|          | 0/125 [00:00<?, ?it/s]Inference:   1%|          | 1/125 [00:00<00:44,  2.79it/s]Inference:   2%|▏         | 2/125 [00:00<00:45,  2.71it/s]Inference:   2%|▏         | 3/125 [00:01<00:45,  2.70it/s]Inference:   3%|▎         | 4/125 [00:01<00:44,  2.71it/s]Inference:   4%|▍         | 5/125 [00:01<00:43,  2.76it/s]Inference:   5%|▍         | 6/125 [00:02<00:42,  2.79it/s]Inference:   6%|▌         | 7/125 [00:02<00:42,  2.77it/s]Inference:   6%|▋         | 8/125 [00:02<00:42,  2.73it/s]Inference:   7%|▋         | 9/125 [00:03<00:42,  2.76it/s]Inference:   8%|▊         | 10/125 [00:03<00:39,  2.89it/s]Inference:   9%|▉         | 11/125 [00:03<00:39,  2.87it/s]Inference:  10%|▉         | 12/125 [00:04<00:41,  2.76it/s]Inference:  10%|█         | 13/125 [00:04<00:41,  2.68it/s]Inference:  11%|█         | 14/125 [00:05<00:39,  2.80it/s]Inference:  12%|█▏        | 15/125 [00:05<00:40,  2.71it/s]Inference:  13%|█▎        | 16/125 [00:05<00:42
0: ,  2.59it/s]Inference:  14%|█▎        | 17/125 [00:06<00:41,  2.63it/s]Inference:  14%|█▍        | 18/125 [00:06<00:39,  2.68it/s]Inference:  15%|█▌        | 19/125 [00:06<00:38,  2.72it/s]Inference:  16%|█▌        | 20/125 [00:07<00:38,  2.71it/s]Inference:  17%|█▋        | 21/125 [00:07<00:36,  2.81it/s]Inference:  18%|█▊        | 22/125 [00:08<00:37,  2.78it/s]Inference:  18%|█▊        | 23/125 [00:08<00:36,  2.80it/s]Inference:  19%|█▉        | 24/125 [00:08<00:36,  2.76it/s]Inference:  20%|██        | 25/125 [00:09<00:34,  2.86it/s]Inference:  21%|██        | 26/125 [00:09<00:35,  2.81it/s]Inference:  22%|██▏       | 27/125 [00:09<00:35,  2.76it/s]Inference:  22%|██▏       | 28/125 [00:10<00:33,  2.86it/s]Inference:  23%|██▎       | 29/125 [00:10<00:34,  2.76it/s]Inference:  24%|██▍       | 30/125 [00:10<00:36,  2.60it/s]Inference:  25%|██▍       | 31/125 [00:11<00:35,  2.62it/s]Inference:  26%|██▌       | 32/125 
0: [00:11<00:36,  2.58it/s]Inference:  26%|██▋       | 33/125 [00:12<00:37,  2.48it/s]Inference:  27%|██▋       | 34/125 [00:12<00:35,  2.57it/s]Inference:  28%|██▊       | 35/125 [00:12<00:34,  2.63it/s]Inference:  29%|██▉       | 36/125 [00:13<00:32,  2.78it/s]Inference:  30%|██▉       | 37/125 [00:13<00:30,  2.87it/s]Inference:  30%|███       | 38/125 [00:13<00:31,  2.76it/s]Inference:  31%|███       | 39/125 [00:14<00:31,  2.76it/s]Inference:  32%|███▏      | 40/125 [00:14<00:30,  2.76it/s]Inference:  33%|███▎      | 41/125 [00:15<00:30,  2.75it/s]Inference:  34%|███▎      | 42/125 [00:15<00:29,  2.84it/s]Inference:  34%|███▍      | 43/125 [00:15<00:28,  2.84it/s]Inference:  35%|███▌      | 44/125 [00:15<00:27,  2.94it/s]Inference:  36%|███▌      | 45/125 [00:16<00:27,  2.90it/s]Inference:  37%|███▋      | 46/125 [00:16<00:27,  2.83it/s]Inference:  38%|███▊      | 47/125 [00:17<00:28,  2.7
0: 4it/s]Inference:  38%|███▊      | 48/125 [00:17<00:27,  2.77it/s]Inference:  39%|███▉      | 49/125 [00:17<00:27,  2.80it/s]Inference:  40%|████      | 50/125 [00:18<00:25,  2.89it/s]Inference:  41%|████      | 51/125 [00:18<00:25,  2.86it/s]Inference:  42%|████▏     | 52/125 [00:18<00:25,  2.82it/s]Inference:  42%|████▏     | 53/125 [00:19<00:25,  2.82it/s]Inference:  43%|████▎     | 54/125 [00:19<00:26,  2.73it/s]Inference:  44%|████▍     | 55/125 [00:19<00:24,  2.88it/s]Inference:  45%|████▍     | 56/125 [00:20<00:24,  2.84it/s]Inference:  46%|████▌     | 57/125 [00:20<00:24,  2.81it/s]Inference:  46%|████▋     | 58/125 [00:21<00:24,  2.70it/s]Inference:  47%|████▋     | 59/125 [00:21<00:23,  2.82it/s]Inference:  48%|████▊     | 60/125 [00:21<00:22,  2.83it/s]Inference:  49%|████▉     | 61/125 [00:22<00:23,  2.72it/s]Inference:  50%|████▉     | 62/125 
0: [00:22<00:23,  2.66it/s]Inference:  50%|█████     | 63/125 [00:22<00:23,  2.67it/s]Inference:  51%|█████     | 64/125 [00:23<00:22,  2.74it/s]Inference:  52%|█████▏    | 65/125 [00:23<00:23,  2.55it/s]Inference:  53%|█████▎    | 66/125 [00:24<00:22,  2.59it/s]Inference:  54%|█████▎    | 67/125 [00:24<00:21,  2.65it/s]Inference:  54%|█████▍    | 68/125 [00:24<00:20,  2.78it/s]Inference:  55%|█████▌    | 69/125 [00:25<00:20,  2.76it/s]Inference:  56%|█████▌    | 70/125 [00:25<00:20,  2.74it/s]Inference:  57%|█████▋    | 71/125 [00:25<00:20,  2.58it/s]Inference:  58%|█████▊    | 72/125 [00:26<00:19,  2.66it/s]Inference:  58%|█████▊    | 73/125 [00:26<00:19,  2.62it/s]Inference:  59%|█████▉    | 74/125 [00:27<00:19,  2.65it/s]Inference:  60%|██████    | 75/125 [00:27<00:18,  2.77it/s]Inference:  61%|██████    | 76/125 [00:27<00:17,  2.73i
0: t/s]Inference:  62%|██████▏   | 77/125 [00:28<00:17,  2.67it/s]Inference:  62%|██████▏   | 78/125 [00:28<00:17,  2.63it/s]Inference:  63%|██████▎   | 79/125 [00:28<00:18,  2.53it/s]Inference:  64%|██████▍   | 80/125 [00:29<00:17,  2.62it/s]Inference:  65%|██████▍   | 81/125 [00:29<00:16,  2.68it/s]Inference:  66%|██████▌   | 82/125 [00:30<00:15,  2.71it/s]Inference:  66%|██████▋   | 83/125 [00:30<00:14,  2.87it/s]Inference:  67%|██████▋   | 84/125 [00:30<00:14,  2.82it/s]Inference:  68%|██████▊   | 85/125 [00:31<00:15,  2.62it/s]Inference:  69%|██████▉   | 86/125 [00:31<00:14,  2.68it/s]Inference:  70%|██████▉   | 87/125 [00:31<00:13,  2.85it/s]Inference:  70%|███████   | 88/125 [00:32<00:12,  2.96it/s]Inference:  71%|███████   | 89/125 [00:32<00:12,  2.91it/s]Inference:  72%|███████▏  | 90/125 [00:32
0: <00:12,  2.86it/s]Inference:  73%|███████▎  | 91/125 [00:33<00:12,  2.81it/s]Inference:  74%|███████▎  | 92/125 [00:33<00:11,  2.81it/s]Inference:  74%|███████▍  | 93/125 [00:33<00:10,  2.92it/s]Inference:  75%|███████▌  | 94/125 [00:34<00:10,  2.88it/s]Inference:  76%|███████▌  | 95/125 [00:34<00:10,  2.80it/s]Inference:  77%|███████▋  | 96/125 [00:34<00:10,  2.77it/s]Inference:  78%|███████▊  | 97/125 [00:35<00:10,  2.75it/s]Inference:  78%|███████▊  | 98/125 [00:35<00:09,  2.73it/s]Inference:  79%|███████▉  | 99/125 [00:36<00:09,  2.67it/s]Inference:  80%|████████  | 100/125 [00:36<00:08,  2.81it/s]Inference:  81%|████████  | 101/125 [00:36<00:08,  2.80it/s]Inference:  82%|████████▏ | 102/125 [00:37<00:08,  2.77it/s]Inference:  82%|████████▏ | 103/125 [00:37<00:07,  2.89it/s]Inference
0: :  83%|████████▎ | 104/125 [00:37<00:07,  2.69it/s]Inference:  84%|████████▍ | 105/125 [00:38<00:07,  2.70it/s]Inference:  85%|████████▍ | 106/125 [00:38<00:06,  2.80it/s]Inference:  86%|████████▌ | 107/125 [00:38<00:06,  2.82it/s]Inference:  86%|████████▋ | 108/125 [00:39<00:05,  2.90it/s]Inference:  87%|████████▋ | 109/125 [00:39<00:05,  2.81it/s]Inference:  88%|████████▊ | 110/125 [00:39<00:05,  2.95it/s]Inference:  89%|████████▉ | 111/125 [00:40<00:04,  2.92it/s]Inference:  90%|████████▉ | 112/125 [00:40<00:04,  2.84it/s]Inference:  90%|█████████ | 113/125 [00:41<00:04,  2.73it/s]Inference:  91%|█████████ | 114/125 [00:41<00:03,  2.77it/s]Inference:  92%|█████████▏| 115/125 [00:41<00:03,  2.75it/s]Inference:  93%|█████████▎| 116/125 [00:42<00:03,  2.67it/s]In
0: ference:  94%|█████████▎| 117/125 [00:42<00:03,  2.62it/s]Inference:  94%|█████████▍| 118/125 [00:42<00:02,  2.68it/s]Inference:  95%|█████████▌| 119/125 [00:43<00:02,  2.82it/s]Inference:  96%|█████████▌| 120/125 [00:43<00:01,  2.72it/s]Inference:  97%|█████████▋| 121/125 [00:43<00:01,  2.70it/s]Inference:  98%|█████████▊| 122/125 [00:44<00:01,  2.75it/s]Inference:  98%|█████████▊| 123/125 [00:44<00:00,  2.76it/s]Inference:  99%|█████████▉| 124/125 [00:45<00:00,  2.79it/s]Inference: 100%|██████████| 125/125 [00:45<00:00,  2.77it/s]Inference: 100%|██████████| 125/125 [00:45<00:00,  2.75it/s]
0: 
0: --- Final Evaluation Results ---
0: Overall Accuracy: 0.568
0: 
0: Classification Report:
0:               precision    recall  f1-score   support
0: 
0:     positive       0.51      0.83      0.63       277
0:     negative       0.64      0.78      0.71       266
0:      neutral       0.58      0.44      0.50       285
0:   irrelevant       0.40      0.03      0.06       172
0: 
0:     accuracy                           0.57      1000
0:    macro avg       0.53      0.52      0.48      1000
0: weighted avg       0.55      0.57      0.52      1000
0: 
0: 
0: Confusion Matrix (Labels: Pos, Neg, Neu, Irr):
0: [[230  22  24   1]
0:  [ 29 208  26   3]
0:  [106  50 124   5]
0:  [ 83  44  39   6]]
0: Saved predictions to twitter_predictions_12b.csv
0: slurmstepd: error: *** STEP 45374131.0 ON nid008201 CANCELLED AT 2025-11-19T12:06:28 DUE TO TIME LIMIT ***
slurmstepd: error: *** JOB 45374131 ON nid008201 CANCELLED AT 2025-11-19T12:06:28 DUE TO TIME LIMIT ***
